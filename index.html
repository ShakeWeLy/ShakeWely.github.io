<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Weakliy_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Weakliy_Blog">
<meta property="og:url" content="https://shakewely.github.io/index.html">
<meta property="og:site_name" content="Weakliy_Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Weakliy">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Weakliy_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>79</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>17</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main">
  
    <article id="post-2025年2月9日-轻量化神经网络2" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/" class="article-date">
  <time class="post-time" datetime="2025-02-09T07:21:36.000Z" itemprop="datePublished">
    <span class="post-month">2月</span><br/>
    <span class="post-day">09</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/">2025年2月9日 轻量化神经网络2</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="squeezenet"><a class="markdownIt-Anchor" href="#squeezenet"></a> SqueezeNet</h1>
<h3 id="fire-module"><a class="markdownIt-Anchor" href="#fire-module"></a> Fire Module</h3>
<p><strong>Fire Module</strong>：每个 Fire Module 由两个主要部分组成：</p>
<ul>
<li><strong>Squeeze层</strong>：一个1x1的卷积层，用来减少特征图的深度。</li>
<li><strong>Expand层</strong>：两个分支，一个是1x1卷积，另一个是3x3卷积，用来增加特征图的深度。</li>
</ul>
<p>通过这种结构，SqueezeNet能够有效地减少参数量，而不牺牲太多的准确度。</p>
<p><strong>减少全连接层的参数</strong>：SqueezeNet中没有传统的全连接层，而是使用全局平均池化（Global Average Pooling）来替代。这样大大减少了参数数量，且仍然保留了模型的表现力。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat([x1, x2], 1)</span><br></pre></td></tr></table></figure>
<h1 id="mobilenethttpsblogcsdnnetqq_37555071articledetails108393809"><a class="markdownIt-Anchor" href="#mobilenethttpsblogcsdnnetqq_37555071articledetails108393809"></a> [MobileNet][<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37555071/article/details/108393809">https://blog.csdn.net/qq_37555071/article/details/108393809</a>]</h1>
<h2 id="深度可分离卷积depthwise-separable-convolutions"><a class="markdownIt-Anchor" href="#深度可分离卷积depthwise-separable-convolutions"></a> 深度可分离卷积(Depthwise Separable Convolutions)</h2>
<p>（Depthwise Separable Convolutions）</p>
<p><strong>深度卷积（Depthwise Convolution）</strong>：对每个输入通道独立进行卷积操作，而不是像传统卷积那样对所有通道进行卷积。这大大减少了计算量。</p>
<p><strong>逐点卷积（Pointwise Convolution）</strong>：即1x1卷积，用于将深度卷积的输出进行线性组合，融合通道信息。</p>
<p><strong>宽度和分辨率的可调性</strong>： MobileNet引入了两个超参数，分别是<strong>宽度系数（Width Multiplier）**和**分辨率系数（Resolution Multiplier）</strong>，使得网络的大小和计算量可以根据实际需求进行调整。</p>
<ul>
<li><strong>宽度系数（α）</strong>：用于控制网络每一层的通道数。通过减小α的值，可以降低网络的复杂度和参数数量。</li>
<li><strong>分辨率系数（ρ）</strong>：用于控制输入图像的分辨率，通过减小分辨率来减少计算量。</li>
</ul>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209162740618.png" alt="image-20250209162740618"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, groups=in_channels, bias=<span class="literal">False</span>)</span><br><span class="line">// groups=in_channels</span><br></pre></td></tr></table></figure>
<h1 id="shufflenet"><a class="markdownIt-Anchor" href="#shufflenet"></a> ShuffleNet</h1>
<p><strong>深度可分离卷积（Depthwise Separable Convolution） 和</strong></p>
<h2 id="通道混洗channel-shuffle"><a class="markdownIt-Anchor" href="#通道混洗channel-shuffle"></a> <strong>通道混洗（Channel Shuffle）</strong></h2>
<p>通道混洗技术会在<strong>每个卷积层的输出中打乱通道的顺序</strong>，使得不同通道的特征能够进行更好的融合，从而提高模型的表达能力和准确率。</p>
<h2 id="分组卷积grouped-convolution"><a class="markdownIt-Anchor" href="#分组卷积grouped-convolution"></a> <strong>分组卷积（Grouped Convolution）</strong></h2>
<p>为了进一步提高网络的计算效率，ShuffleNet 采用了 <strong>分组卷积（Grouped Convolution）</strong>。分组卷积将输入通道分成多个组，每个组内的通道与一个独立的卷积核进行卷积，从而减少了卷积运算的计算量。</p>
<h1 id="googlenet"><a class="markdownIt-Anchor" href="#googlenet"></a> GoogLeNet</h1>
<h2 id="inception块"><a class="markdownIt-Anchor" href="#inception块"></a> Inception块</h2>
<p>各种模块全都要</p>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209172824970.png" alt="image-20250209172824970" style="zoom:50%;">
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209172918099.png" alt="image-20250209172918099" style="zoom:67%;">
<h2 id="xception-块"><a class="markdownIt-Anchor" href="#xception-块"></a> <strong>Xception 块</strong></h2>
<p>极限情况</p>
<h1 id="efficientnet"><a class="markdownIt-Anchor" href="#efficientnet"></a> EfficientNet</h1>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209173848541.png" alt="image-20250209173848541" style="zoom: 80%;"><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174104028.png" alt="image-20250209174104028" style="zoom: 67%;"></p>
<h2 id="原理"><a class="markdownIt-Anchor" href="#原理"></a> 原理</h2>
<h3 id="网络架构搜索nas"><a class="markdownIt-Anchor" href="#网络架构搜索nas"></a> <strong>网络架构搜索（NAS）</strong>：</h3>
<ul>
<li>EfficientNet 使用了 <strong>神经架构搜索</strong>（NAS）来自动化地找到最适合的卷积神经网络架构。在这个过程中，作者通过 NAS 来寻找一个 <strong>基础架构</strong>，该架构在计算效率和性能之间取得了最佳的平衡。</li>
</ul>
<h3 id="优化网络的宽度-深度和分辨率"><a class="markdownIt-Anchor" href="#优化网络的宽度-深度和分辨率"></a> <strong>优化网络的宽度、深度和分辨率</strong>：</h3>
<ul>
<li>EfficientNet 在进行网络扩展时，并不是简单地增加网络的层数或通道数，而是采用了更加 <strong>均衡的增长策略</strong>。通过在深度、宽度和输入图像分辨率上都进行扩展，模型能够获得更强的表达能力，同时保持较低的计算成本。</li>
</ul>
<h3 id="高效的卷积操作"><a class="markdownIt-Anchor" href="#高效的卷积操作"></a> <strong>高效的卷积操作</strong>：</h3>
<ul>
<li>EfficientNet 采用了高效的卷积操作，如 <strong>Depthwise Separable Convolution</strong>，以进一步减少计算量。</li>
</ul>
<p>通过结构搜索（NAS, Neural Architecture Search）和优化策略，在精度和计算效率之间找到最好的平衡。</p>
<h2 id="mbconvefficientnet块"><a class="markdownIt-Anchor" href="#mbconvefficientnet块"></a> MBConv/EfficientNet块</h2>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209180216944.png" alt="image-20250209180216944"></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174529781.png" alt="image-20250209174529781"></p>
<h3 id="倒残差结构inverted-residuals"><a class="markdownIt-Anchor" href="#倒残差结构inverted-residuals"></a> 倒残差结构（Inverted Residuals)</h3>
<p><img src="https://pic2.zhimg.com/v2-7c42cff2fa3c346d2e41be95848fc619_1440w.jpg" alt="img"></p>
<blockquote>
<p>使用逐通道卷积和逐点卷积来提高计算效率。</p>
</blockquote>
<h2 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制"></a> 注意力机制</h2>
<h3 id="se模块squeeze-and-excitation-block"><a class="markdownIt-Anchor" href="#se模块squeeze-and-excitation-block"></a> SE模块（Squeeze-and-Excitation Block）</h3>
<p>来源于人类视觉系统中的注意机制：大脑会根据不同的视觉刺激，<strong>自动聚焦于最重要的信息，并忽略不相关的部分</strong>。SE模块通过类似的机制，<strong>自动为每个通道分配不同的重要性</strong>，从而增强模型对重要特征的敏感度。</p>
<ul>
<li>
<p><strong>queeze-and-Excitation</strong>（SE）模块，提升了特征通道之间的依赖关系.仅在 <strong>通道维度</strong> 上进行加权</p>
</li>
<li>
<p>通过一个 <strong>“Squeeze”</strong> 操作来压缩空间维度信息，再通过 <strong>“Excitation”</strong> 操作生成通道权重</p>
</li>
</ul>
<p><strong>Squeeze（压缩）</strong>：</p>
<ul>
<li>输入是一个 <strong>H×W×C</strong> 的特征图，其中 H和 W 分别是空间维度的高度和宽度，C 是通道数。</li>
<li><strong>通过全局平均池化</strong>（Global Average Pooling）对每个通道进行压缩。即对每个通道的空间维度（H×W）求平均，得到一个 <strong>C</strong> 维的向量，表示每个通道的“全局特征”。</li>
</ul>
<p><strong>Excitation（激励）</strong>：</p>
<ul>
<li>对通道的全局特征向量进行<strong>两层全连接层操作</strong>，其中第二层是激活函数（通常是 <strong>Sigmoid</strong>），生成每个通道的 <strong>注意力系数</strong>。</li>
<li>第一个全连接层是 <strong>瓶颈层（bottleneck layer）</strong>，通常通过降低维度来减少计算量。然后通过第二个全连接层，将输出恢复到原始通道数，得到每个通道的权重。</li>
</ul>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174719710.png" alt="image-20250209174719710" style="zoom:67%;">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_se_block</span>(<span class="params">self, channels, se_ratio</span>):</span><br><span class="line">        reduction = <span class="built_in">int</span>(channels * se_ratio)</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">            nn.AdaptiveAvgPool2d(<span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(channels, reduction, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(reduction, channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h4 id="空间注意力机制"><a class="markdownIt-Anchor" href="#空间注意力机制"></a> 空间注意力机制</h4>
<p>对特征图的<strong>每个位置</strong>分配一个权重来决定哪些空间区域应该被网络更多关注</p>
<blockquote>
<p>人类的视觉注意力更多的是<strong>空间注意力</strong>，也就是对图片上不同区域赋予不同的权重</p>
</blockquote>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209183640934.png" alt="image-20250209183640934" style="zoom:67%;">
<h4 id="cbam注意力"><a class="markdownIt-Anchor" href="#cbam注意力"></a> CBAM注意力</h4>
<p>CBAM 通过融合 <strong>通道注意力机制</strong> 和 <strong>空间注意力机制</strong></p>
<h4 id="视觉自注意力non-local"><a class="markdownIt-Anchor" href="#视觉自注意力non-local"></a> 视觉自注意力(Non Local))</h4>
<p>用来在不引入过多计算量的基础上提高CNN网络的<strong>远程依赖</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209184403579.png" alt="image-20250209184403579"></p>
<blockquote>
<p>我可能先识别到篮球，然后在其周围找到人和篮筐，并根据他们的位置我们才能判断这个图是不是表达人在灌篮这个动作。其中，篮球位置可以理解为<strong>查询点</strong>，周边（可能离得较远）的人和篮筐就是<strong>查询点对应的关联区域</strong>。</p>
</blockquote>
<p>查询点到关联区域的对应可以加深CNN网络对场景<strong>从局部到整体</strong>的理解，因此可以有效提高CNN网络在视觉任务的效率。</p>
<ul>
<li>
<p>该模块建立了图像中<strong>每个像素/区域之间的关联</strong>，有效提升了CNN网络的感受野</p>
</li>
<li>
<p>对每个空间位置生成与所有其他位置的<strong>相似度</strong>。</p>
</li>
<li>
<p>基于<strong>相似度进行加权</strong>，使得每个位置可以融合其他位置的信息。</p>
</li>
</ul>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209184638406.png" alt="image-20250209184638406"></p>
<blockquote>
<p>其大概的运算过程是：</p>
<p>（1）为了降低运算量，采用三个不同1x1卷积层进行维度减半，即图上的 x→ϕ(x),θ(x),g(x) ;</p>
<p>（2）为 ϕ(x),θ(x),g(x) 按照w,h维度进行铺平，即图上三个flatten；</p>
<p>（3）利用铺平的 ϕ(x),θ(x) 进行矩阵乘法运算，并通过softmax获得各空间位置之间的<strong>关联图</strong>（即图中的 vc ），很明显这个关联图的大小为 (w×h,w×h) ，表征着各个像素点（区域）之间的联系；</p>
<p>（4）将铺平转置的 g(x) 与vc进行矩阵乘法，获得 y ；</p>
<p>（5）对y进行展开与特征提取（Conv4），获得注意力（refined）;</p>
<p>（6）利用注意力调整原始输入的分布，Over!!!</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/350760243">https://zhuanlan.zhihu.com/p/350760243</a></p>
</blockquote>
<h4 id="non-local改进版-gcnet"><a class="markdownIt-Anchor" href="#non-local改进版-gcnet"></a> Non Local改进版 — GCNet</h4>
<p>原因:<strong>不同查询点（区域）居然对应相同的attention map</strong></p>
<img src="https://pic4.zhimg.com/v2-31d05dfac01c6ae64bd5bf4e52ffc069_1440w.jpg" alt="img" style="zoom: 33%;">
<p>与查询（点）无关的依赖（query-independent dependency）。那么这是否意味着原始Non Local中<strong>query分支可以剪去不要</strong>呢</p>
<img src="https://pic4.zhimg.com/v2-dc2339ac78de452e286317dd259070f5_1440w.jpg" alt="img" style="zoom: 50%;">
<img src="https://pic3.zhimg.com/v2-104058d724746316b12298ec27fafe26_1440w.jpg" alt="img" style="zoom:50%;">
<h1 id="efficientdet"><a class="markdownIt-Anchor" href="#efficientdet"></a> EfficientDet</h1>
<h2 id="结构概述"><a class="markdownIt-Anchor" href="#结构概述"></a> <strong>结构概述</strong></h2>
<ol>
<li><strong>Backbone（EfficientNet）</strong>
<ul>
<li>EfficientDet 的 backbone 使用了 EfficientNet 作为特征提取器。EfficientNet 是一种使用<strong>复合缩放</strong>策略的高效网络，在目标检测任务中，EfficientDet 对 EfficientNet 进行调整和优化，使得其能更好地适应目标检测的要求。</li>
</ul>
</li>
<li><strong>BiFPN（双向特征金字塔网络）</strong>
<ul>
<li>BiFPN 通过对低层和高层特征的加权融合，使得低层和高层的特征能够互相补充，提升了多尺度特征的利用率。</li>
</ul>
</li>
<li><strong>Head</strong>
<ul>
<li><strong>分类头</strong>：用于对目标进行分类，预测每个框的类别。</li>
<li><strong>回归头</strong>：用于回归目标的边界框坐标。</li>
</ul>
</li>
<li><strong>复合缩放</strong>
<ul>
<li>EfficientDet 通过复合缩放策略调整模型的深度、宽度和输入分辨率，使得模型可以在不同的硬件环境下进行灵活的调整，同时提升了精度和效率。</li>
</ul>
</li>
</ol>
<h2 id="fpn到bifpn"><a class="markdownIt-Anchor" href="#fpn到bifpn"></a> FPN.到BiFPN</h2>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224653761.png" style="zoom: 80%;">
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209190732084.png" style="zoom: 80%;">
<blockquote>
<p>a. 网络只是针对某一特点的分辨率进行训练, 如果只是在测试和推理阶段使用图像金字塔的话, 可能导致训练和测试推理过程不匹配</p>
<p>b. 利用单个高层特征图(主干网络产生)进行物体的分类和bounding box的回归</p>
<p>c. 在 <strong>多个不同尺度的特征图（如 38×38、19×19、10×10）</strong> 上直接预测目标框。</p>
<p>d 尽管在SSD中我们已经使用了特征金字塔, 但该金字塔中的所有要素都处于不同的比例, 并且由于网络中层的深度不同而存在巨大的语义鸿沟. 高分辨率地图具有低级语义特征, 而低分辨率地图具有较高的语义特征, 这会损害其对象识别的表示能力.</p>
</blockquote>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209223353104.png" alt="image-20250209223353104" style="zoom:50%;">
<blockquote>
<p>先对高阶特征进行上采样, 然后使用横向连接将其与低阶特征进行组合, 该横向连接基本上是1x1卷积, 然后进行求和,</p>
</blockquote>
<h3 id="fully-connected-fpn-and-nas-fpn"><a class="markdownIt-Anchor" href="#fully-connected-fpn-and-nas-fpn"></a> Fully connected FPN and NAS-FPN</h3>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224903212.png" alt="image-20250209224903212"></p>
<blockquote>
<p>a. 传统fpn</p>
<p>b. 全连接网络</p>
<p>c. NAS</p>
</blockquote>
<h3 id="panet"><a class="markdownIt-Anchor" href="#panet"></a> PANet</h3>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224555819.png" alt="image-20250209224555819"></p>
<blockquote>
<p>添加<strong>自下而上的路径</strong>以增强FPN中的自上而下的路径</p>
</blockquote>
<h3 id="simplified-fpn-and-bifpn"><a class="markdownIt-Anchor" href="#simplified-fpn-and-bifpn"></a> Simplified FPN and BiFPN</h3>
<p><img src="https://pic4.zhimg.com/v2-faec285a27615d8829af43172d9d1385_1440w.jpg" alt="img"></p>
<blockquote>
<p>a. 如果一个节点只有一个输入边并且没有特征融合, 那么它对特征网络的融合贡献较小, 这个节点可以删除(Simplified PANET)</p>
<p>b. 添加一条额外的连接路径,融合更多功能(BiFPN). 这点其实跟skip connection很相似</p>
<p>c. 重复叠加相同的特征网络层 复合缩放</p>
</blockquote>
<h2 id="权重计算"><a class="markdownIt-Anchor" href="#权重计算"></a> 权重计算</h2>
<p>快速归一化融合特征网络.计算路径,计算出不同特征节点的输入最合适的权值</p>
<p><img src="https://pic4.zhimg.com/v2-a0f1319eae0571829c79b1a70d4fc1b9_1440w.jpg" alt="img"></p>
<h2 id="compound-scaling"><a class="markdownIt-Anchor" href="#compound-scaling"></a> Compound Scaling</h2>
<p>复合缩放的目标是在任何给定的资源约束下最大化模型精度, 因此可以表述为优化问题.</p>
<p><strong>对网络深度、宽度和分辨率中的任何尺度进行缩放都可以提高精度, 但是当模型足够大时, 这种放大的收益会减弱。</strong></p>
<p><strong>FLOPS</strong>是floating point operations per second的缩写, 意指每秒浮点运算次数, 理解为计算速度. 是一个衡量硬件性能的指标. 我们假设我们能使用的FLOPS是2.</p>
<p><img src="https://pic2.zhimg.com/v2-032dfea7e52345c3f26a543e3dbcc6fd_1440w.jpg" alt="img"></p>
<blockquote>
<p>a. 对于网络模型depth来说, 加倍深度会使得FLOPS加倍.</p>
</blockquote>
<p><img src="https://pic1.zhimg.com/v2-4f1414b59ea6700387f0dea2dac0d878_1440w.jpg" alt="img"></p>
<blockquote>
<p>b. 对于网络模型width来说, 由于width(#channel)的增加导致卷积计算的路径平方级增加, 因此加倍宽度会使得FLOPS加4倍.</p>
</blockquote>
<p><img src="https://pica.zhimg.com/v2-646a538d15c17d28145024953ff90eda_1440w.jpg" alt="img"></p>
<blockquote>
<p>c. 对于网络模型resolution来说, 和width的情况一样, 由于resolution的增加会导致feather map呈现平方级扩张, 因此加倍图像分辨率也会使得FLOPS加4倍.</p>
</blockquote>
<p><strong>复合缩放公式:</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209230157789.png" alt="image-20250209230157789"></p>
<p><strong>网格搜索</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209230342459.png" alt></p>
<p><strong>复合缩放的总结图:</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209231222947.png" alt="image-20250209231222947"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/" data-id="cm6yfcd2b0000mcv4hi073hzf" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年2月5日-轻量化神经网络" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="article-date">
  <time class="post-time" datetime="2025-02-05T08:28:10.000Z" itemprop="datePublished">
    <span class="post-month">2月</span><br/>
    <span class="post-day">05</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">2025年2月5日 轻量化神经网络1</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205162820154.png" alt="image-20250205162820154"></p>
<h1 id="知识蒸馏"><a class="markdownIt-Anchor" href="#知识蒸馏"></a> 知识蒸馏</h1>
<h2 id="soft-target"><a class="markdownIt-Anchor" href="#soft-target"></a> soft target</h2>
<img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205163735260.png" alt="image-20250205163735260" style="zoom:33%;">
<blockquote>
<p>更多信息+</p>
</blockquote>
<h4 id="蒸馏温度"><a class="markdownIt-Anchor" href="#蒸馏温度"></a> 蒸馏温度</h4>
<img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205164432943.png" alt="image-20250205164432943" style="zoom:50%;">
<img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205164308480.png" alt="image-20250205164308480" style="zoom:67%;">
<h4 id="训练"><a class="markdownIt-Anchor" href="#训练"></a> 训练</h4>
<img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205164454289.png" alt="image-20250205164454289" style="zoom:33%;">
<h1 id="量化"><a class="markdownIt-Anchor" href="#量化"></a> 量化</h1>
<h1 id="剪枝"><a class="markdownIt-Anchor" href="#剪枝"></a> 剪枝</h1>
<h2 id="定义"><a class="markdownIt-Anchor" href="#定义"></a> 定义</h2>
<h3 id="剪枝方法总结表"><a class="markdownIt-Anchor" href="#剪枝方法总结表"></a> <strong>剪枝方法总结表</strong></h3>
<table>
<thead>
<tr>
<th>剪枝方法</th>
<th>主要剪枝对象</th>
<th>优点</th>
<th>缺点</th>
<th>示例方法/应用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>权重剪枝（Weight Pruning）</strong></td>
<td>单个权重</td>
<td>剪枝率高，可应用于各种网络</td>
<td>需要稀疏矩阵优化，不适合硬件加速</td>
<td>TensorFlow <code>tf.sparsity</code>, PyTorch <code>torch.nn.utils.prune</code></td>
</tr>
<tr>
<td><strong>结构化剪枝（Structured Pruning）</strong></td>
<td>神经元、通道、卷积核</td>
<td>适合硬件加速</td>
<td>剪枝率受限，可能影响模型结构</td>
<td><code>Channel Pruning</code>, <code>Filter Pruning</code></td>
</tr>
<tr>
<td><strong>低秩分解剪枝（Low-Rank Approximation）</strong></td>
<td>整体权重矩阵</td>
<td>计算加速明显</td>
<td>需要额外的分解计算</td>
<td>SVD 分解, CP 分解, Tensor Train 分解</td>
</tr>
<tr>
<td><strong>剪枝 + 训练（Prune and Fine-tune）</strong></td>
<td>结合剪枝和微调</td>
<td>可恢复精度</td>
<td>训练时间增加</td>
<td>迭代剪枝（Iterative Pruning）, 一次性剪枝（One-shot Pruning）</td>
</tr>
<tr>
<td><strong>软剪枝（Soft Pruning）</strong></td>
<td>权重</td>
<td>更温和的剪枝方式</td>
<td>需要更多训练步骤</td>
<td>逐步缩小权重（Weight Decay），平滑剪枝（Gradual Magnitude Pruning）</td>
</tr>
<tr>
<td><strong>剪枝 + 蒸馏（Pruning with Distillation）</strong></td>
<td>剪枝后蒸馏</td>
<td>精度损失小</td>
<td>需要额外教师模型</td>
<td><code>Knowledge Distillation (KD)</code>, MobileBERT, TinyBERT</td>
</tr>
<tr>
<td><strong>幸运票剪枝（Lottery Ticket Hypothesis）</strong></td>
<td>子网络</td>
<td>保留重要子结构</td>
<td>训练步骤复杂</td>
<td>训练大模型后剪枝，重新初始化训练</td>
</tr>
<tr>
<td><strong>正则化剪枝（Regularization-based Pruning）</strong></td>
<td>L1/L2 约束</td>
<td>无需额外剪枝步骤</td>
<td>训练需额外超参数</td>
<td><code>L1 Regularization</code>, <code>Group Lasso Pruning</code></td>
</tr>
<tr>
<td><strong>动态剪枝（Movement Pruning）</strong></td>
<td>Transformer 模型</td>
<td>适合 NLP</td>
<td>计算复杂度高</td>
<td><code>BERT Pruning</code>, <code>MobileBERT</code></td>
</tr>
<tr>
<td><strong>自动剪枝（AutoML Pruning）</strong></td>
<td>NAS/强化学习</td>
<td>自动优化</td>
<td>计算成本高</td>
<td><code>AMC (AutoML for Model Compression)</code>, <code>Meta-Pruning</code></td>
</tr>
</tbody>
</table>
<img src="https://ucc.alicdn.com/yysinyik4knec/developer-article1644450/20241207/de25bb1591524da481677d9008ecc078.png?x-oss-process=image/resize,w_1400/format,webp" alt="image" style="zoom: 67%;">
<ul>
<li><strong>非结构化剪枝（Unstructured Pruning）</strong>：直接删除模型中的某些参数，通常基于参数的绝对值大小。这种方法可以实现较高的压缩比，但可能会破坏模型的整体结构。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 应用权重剪枝</span><br><span class="line">def apply_pruning(model, amount=0.2):</span><br><span class="line">    for name, module in model.named_modules():</span><br><span class="line">        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):</span><br><span class="line">            prune.l1_unstructured(module, name=&#x27;weight&#x27;, amount=amount)</span><br><span class="line">            print(f&quot;Applied pruning on &#123;name&#125;&quot;)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>结构化剪枝（Structured Pruning）</strong>：删除模型中的特定结构单元，如滤波器、通道或层。这种方法不会破坏模型的整体结构，更适合硬件加速。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">threshold = 0.01</span><br><span class="line">for name, module in model.named_modules():</span><br><span class="line">    if isinstance(module, nn.Conv2d):</span><br><span class="line">        # 计算每个卷积核的L2范数</span><br><span class="line">        kernel_norms = torch.norm(module.weight, dim=(1, 2, 3))</span><br><span class="line">        # 找到小于阈值的卷积核索引</span><br><span class="line">        prune_indices = torch.where(kernel_norms &lt; threshold)[0]</span><br><span class="line">        # 将这些卷积核的权重置零</span><br><span class="line">        module.weight[prune_indices] = 0</span><br></pre></td></tr></table></figure>
<ul>
<li>
<h4 id="基于梯度的剪枝"><a class="markdownIt-Anchor" href="#基于梯度的剪枝"></a> <strong>基于梯度的剪枝</strong></h4>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">def gradient_magnitude_pruning(weight, gradient, percentile=0.5):</span><br><span class="line">    &quot;&quot;&quot;基于梯度幅值剪枝权重&quot;&quot;&quot;</span><br><span class="line">    num_zeros = round(weight.numel() * percentile)  # 计算剪枝元素数量</span><br><span class="line">    threshold = gradient.abs().view(-1).kthvalue(num_zeros).values  # 计算剪枝阈值</span><br><span class="line">    mask = gradient.abs() &gt; threshold  # 生成掩码</span><br><span class="line">    weight.mul_(mask.to(weight.device))  # 应用掩码剪枝</span><br><span class="line">    return weight</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="注意力迁移"><a class="markdownIt-Anchor" href="#注意力迁移"></a> 注意力迁移</h1>
<p><a target="_blank" rel="noopener" href="https://github.com/szagoruyko/attention-transfer?tab=readme-ov-file">https://github.com/szagoruyko/attention-transfer?tab=readme-ov-file</a></p>
<h2 id="定义-2"><a class="markdownIt-Anchor" href="#定义-2"></a> 定义</h2>
<ul>
<li>注意力迁移的思想来源于知识蒸馏，但与<strong>传统知识蒸馏主要关注最后层的知识不同，注意力迁移关注训练过程中特征图中的知识</strong>。</li>
<li>其目的是通过将教师网络的注意力图迁移到学生网络，提升学生网络的性能，同时实现模型的轻量化。</li>
</ul>
<h2 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制"></a> 注意力机制</h2>
<ul>
<li><strong>空间域（Spatial Domain）</strong>：关注特征空间信息，决定空间中哪些区域重要。例如，通过动态注意力机制来选择性地关注图像中的特定区域。</li>
<li><strong>通道域（Channel Domain）</strong>：关注通道信息，如Squeeze-and-Excitation Networks（SENet）。SENet通过全局平均池化、降维再升维的方式为通道分配权重，增强重要通道的特征。</li>
<li><strong>混合域（Mixed Domain）</strong>：同时关注空间域和通道域，如CBAM等注意力机制，综合考虑特征空间和通道信息来生成注意力图。</li>
</ul>
<h2 id="算法部分"><a class="markdownIt-Anchor" href="#算法部分"></a> 算法部分</h2>
<ul>
<li><strong>基于激活的注意力迁移（Activation-based Attention Transfer）</strong>：
<ul>
<li>在前馈过程中，通过教师网络的激活特征图来引导学生网络的学习。</li>
<li>教师网络的激活特征图反映了输入数据在不同区域的重要性，<strong>学生网络通过模仿这些激活特征图</strong>来学习关注重要的区域。</li>
</ul>
</li>
<li><strong>基于梯度的注意力迁移（Gradient-based Attention Transfer）</strong>：
<ul>
<li>在反馈过程中，对教师网络和学生网络的交叉熵损失函数分别求梯度，<strong>将教师网络的梯度作为注意力图转移到学生网络</strong>。</li>
<li>关注那些对输出影响大的区域，通过构造损失函数，使得学生网络的梯度注意力图与教师网络的梯度注意力图接近，从而实现知识的迁移。</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" data-id="cm6rncay50000xgv42v0x1l8p" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年1月9日-语言模型" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time class="post-time" datetime="2025-01-07T16:22:05.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">08</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">2025年1月9日 语言模型</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li>预训练 浅层特征不变 高层改变
<ol>
<li>冻结</li>
<li>fine-tuning</li>
</ol>
</li>
</ol>
<h2 id="统计语言模型"><a class="markdownIt-Anchor" href="#统计语言模型"></a> 统计语言模型</h2>
<p><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250103124916040.png" alt="image-20250103124916040"></p>
<ol>
<li>马尔科夫链</li>
<li></li>
</ol>
<h2 id="神经网络语言模型"><a class="markdownIt-Anchor" href="#神经网络语言模型"></a> 神经网络语言模型</h2>
<p>word embedding 例子</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>word embedding 就是 预训练的frozen</p>
<p><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002222562.png" alt></p>
<p><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002349457.png" alt="image-20250108002349457" style="zoom:50%;"><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002355983.png" alt="image-20250108002355983"><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002359696.png" alt="image-20250108002359696" style="zoom:50%;"><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002402739.png" alt="image-20250108002402739" style="zoom:50%;"></p>
<h2 id="改进的注意力机制"><a class="markdownIt-Anchor" href="#改进的注意力机制"></a> 改进的注意力机制</h2>
<h3 id><a class="markdownIt-Anchor" href="#"></a> </h3>
<h3 id="1-lora-低秩近似在-transformer-中的应用"><a class="markdownIt-Anchor" href="#1-lora-低秩近似在-transformer-中的应用"></a> 1 LORA 低秩近似在 Transformer 中的应用</h3>
<p>在 Transformer 中，低秩近似主要应用于自注意力计算，特别是通过优化注意力矩阵的存储和计算来提高效率。以下是两种常见的实现方式：</p>
<ol>
<li>
<p><strong>Linformer</strong>：Linformer 是一种基于低秩近似的优化方法。Linformer 的核心思想是将标准自注意力中的注意力矩阵近似为低秩矩阵。Linformer 假设注意力矩阵可以用低秩矩阵来近似，因此将其从一个全连接矩阵（n×n）降为一个n×k  的矩阵（其中 kkk 是较小的值，通常比 nnn 小得多）。通过这种低秩近似，计算复杂度从</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>降低为</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo>⋅</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n \cdot k)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span></span></p>
<p>大大减少了计算量，特别是在长序列时效果显著。</p>
</li>
<li>
<p><strong>Performer</strong>：Performer 是另一种采用低秩近似的 Transformer 变种，它通过引入一种叫做 <strong>线性注意力</strong> 的方法，采用<strong>随机特征来近似注意力矩阵</strong>的乘积。这种方法能够将原本的</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>计算复杂度降低为</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span></span></p>
<p>，使得 Transformer 可以处理非常长的序列。</p>
</li>
</ol>
<h4 id="低秩近似的优点"><a class="markdownIt-Anchor" href="#低秩近似的优点"></a> 低秩近似的优点</h4>
<ul>
<li><strong>减少计算复杂度</strong>：通过将高秩矩阵分解为低秩矩阵，降低了计算复杂度，从而加快了训练和推理速度。</li>
<li><strong>节省内存</strong>：低秩矩阵的存储通常比原始矩阵所需的内存少，因此节省了计算过程中的内存消耗。</li>
<li><strong>适用于长序列</strong>：对于长序列，低秩近似可以大大提高 Transformer 的效率，使其能够处理更长的输入序列而不遇到内存瓶颈。</li>
</ul>
<h4 id="低秩近似的缺点"><a class="markdownIt-Anchor" href="#低秩近似的缺点"></a> 低秩近似的缺点</h4>
<ul>
<li><strong>性能损失</strong>：低秩近似虽然可以减少计算复杂度，但可能会带来一定的性能损失，尤其是在近似效果不佳时。较低的秩可能无法捕捉到原矩阵中的复杂关系，因此可能影响模型的精度。</li>
<li><strong>近似精度问题</strong>：低秩近似依赖于如何选择低秩矩阵的秩（rank）。如果选择的秩过小，可能会导致较大的误差，从而影响模型的效果。</li>
</ul>
<p>、</p>
<h3 id="lora-的应用步骤"><a class="markdownIt-Anchor" href="#lora-的应用步骤"></a> LoRA 的应用步骤</h3>
<h4 id="1-选择适当的层"><a class="markdownIt-Anchor" href="#1-选择适当的层"></a> 1. <strong>选择适当的层</strong></h4>
<ul>
<li>通常，LoRA 应用在 Transformer 中的关键层，如注意力层和前馈层。选择这些层是因为它们通常是最有影响力的层，影响模型的表达能力。</li>
</ul>
<h4 id="2-添加低秩矩阵"><a class="markdownIt-Anchor" href="#2-添加低秩矩阵"></a> 2. <strong>添加低秩矩阵</strong></h4>
<ul>
<li>对于每个需要修改的层（如注意力层中的权重矩阵），LoRA 在其上加上低秩矩阵。通常，这些低秩矩阵的秩较小，因此不会显著增加模型的复杂度。</li>
</ul>
<h4 id="3-训练低秩矩阵"><a class="markdownIt-Anchor" href="#3-训练低秩矩阵"></a> 3. <strong>训练低秩矩阵</strong></h4>
<ul>
<li>在微调过程中，仅训练低秩矩阵的参数，而保持原始的预训练权重不变。这意味着只有少量参数需要更新，从而加速训练并降低存储需求。</li>
</ul>
<h4 id="4-合成模型"><a class="markdownIt-Anchor" href="#4-合成模型"></a> 4. <strong>合成模型</strong></h4>
<ul>
<li>在微调结束后，最终的模型将包括原始的预训练权重和经过 LoRA 微调的低秩矩阵</li>
</ul>
<h3 id="代码实现"><a class="markdownIt-Anchor" href="#代码实现"></a> 代码实现</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="adapter"><a class="markdownIt-Anchor" href="#adapter"></a> Adapter</h2>
<p>适</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" data-id="cm6rncay70001xgv40x8a6tc6" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年1月9日-LLM-Fine-tuing" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-LLM-Fine-tuing/" class="article-date">
  <time class="post-time" datetime="2025-01-07T16:20:06.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">08</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-LLM-Fine-tuing/">2025年1月9日 LLM Fine-tuing</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="llm"><a class="markdownIt-Anchor" href="#llm"></a> LLM</h1>
<h1 id="adam"><a class="markdownIt-Anchor" href="#adam"></a> ADAM</h1>
<p>指数加权平均</p>
<p><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-LLM-Fine-tuing/image-20250107195607114.png" alt="image-20250107195607114" style="zoom:50%;"><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-LLM-Fine-tuing/image-20250107195610658.png" alt="image-20250107195610658" style="zoom:50%;"><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-LLM-Fine-tuing/image-20250107195613842.png" alt="image-20250107195613842" style="zoom:50%;"></p>
<img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-LLM-Fine-tuing/image-20250107195712397.png" alt="image-20250107195712397" style="zoom:67%;">

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-LLM-Fine-tuing/" data-id="cm5mohy3v0001r4v41c5v930d" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年1月8日-生成模型" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/01/08/2025%E5%B9%B41%E6%9C%888%E6%97%A5-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time class="post-time" datetime="2025-01-07T16:19:10.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">08</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/01/08/2025%E5%B9%B41%E6%9C%888%E6%97%A5-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/">2025年1月8日 生成模型</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="generate"><a class="markdownIt-Anchor" href="#generate"></a> Generate</h1>
<h2 id="gan"><a class="markdownIt-Anchor" href="#gan"></a> GAN</h2>
<h2 id="diffusion"><a class="markdownIt-Anchor" href="#diffusion"></a> diffusion</h2>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/01/08/2025%E5%B9%B41%E6%9C%888%E6%97%A5-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/" data-id="cm5mohy3t0000r4v4gwf1249u" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年1月2日-BERT论文" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/12/31/2025%E5%B9%B41%E6%9C%882%E6%97%A5-BERT%E8%AE%BA%E6%96%87/" class="article-date">
  <time class="post-time" datetime="2024-12-31T08:36:47.000Z" itemprop="datePublished">
    <span class="post-month">12月</span><br/>
    <span class="post-day">31</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/12/31/2025%E5%B9%B41%E6%9C%882%E6%97%A5-BERT%E8%AE%BA%E6%96%87/">2025年1月2日 BERT论文</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="bert论文"><a class="markdownIt-Anchor" href="#bert论文"></a> BERT论文</h1>
<p>不标号的预训练+有标号的微调</p>
<p>参数量</p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%882%E6%97%A5-BERT%E8%AE%BA%E6%96%87/image-20241231170330363.png" alt="image-20241231170330363"></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%882%E6%97%A5-BERT%E8%AE%BA%E6%96%87/image-20241231170937584.png" alt="image-20241231170937584"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/12/31/2025%E5%B9%B41%E6%9C%882%E6%97%A5-BERT%E8%AE%BA%E6%96%87/" data-id="cm5modkt90001xsv42g0098ex" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2024年12月31日-GAN论文" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/12/31/2024%E5%B9%B412%E6%9C%8831%E6%97%A5-GAN%E8%AE%BA%E6%96%87/" class="article-date">
  <time class="post-time" datetime="2024-12-31T07:20:05.000Z" itemprop="datePublished">
    <span class="post-month">12月</span><br/>
    <span class="post-day">31</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/12/31/2024%E5%B9%B412%E6%9C%8831%E6%97%A5-GAN%E8%AE%BA%E6%96%87/">2024年12月31日 GAN论文</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="gan论文"><a class="markdownIt-Anchor" href="#gan论文"></a> GAN论文</h1>
<p><img src="/2024/12/31/2024%E5%B9%B412%E6%9C%8831%E6%97%A5-GAN%E8%AE%BA%E6%96%87/image-20241231155018880.png" alt="image-20241231155018880"></p>
<p>更新辨别器和生成器</p>
<p><img src="/2024/12/31/2024%E5%B9%B412%E6%9C%8831%E6%97%A5-GAN%E8%AE%BA%E6%96%87/image-20241231155133303.png" alt="image-20241231155133303"></p>
<ul>
<li>可解释性不强</li>
<li>扩展性不强 保真好</li>
<li>两个网络不好训练</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/12/31/2024%E5%B9%B412%E6%9C%8831%E6%97%A5-GAN%E8%AE%BA%E6%96%87/" data-id="cm5modkt60000xsv4gyf1dcrv" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-视觉模型" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time class="post-time" datetime="2024-12-31T07:20:05.000Z" itemprop="datePublished">
    <span class="post-month">12月</span><br/>
    <span class="post-day">31</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/">2025年1月2日 视觉模型</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="视觉模型"><a class="markdownIt-Anchor" href="#视觉模型"></a> 视觉模型</h1>
<p>端到端单阶段</p>
<p>两阶段的</p>
<p>RCNN</p>
<h2 id="rcnn"><a class="markdownIt-Anchor" href="#rcnn"></a> RCNN</h2>
<h3 id="rcnn-2"><a class="markdownIt-Anchor" href="#rcnn-2"></a> RCNN</h3>
<h4 id="0-原理"><a class="markdownIt-Anchor" href="#0-原理"></a> 0 原理</h4>
<p><strong><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184356637.png" alt="image-20250104184356637" style="zoom: 33%;"></strong></p>
<h4 id="1-ss算法"><a class="markdownIt-Anchor" href="#1-ss算法"></a> 1 ss算法</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184501872.png" alt="image-20250104184501872" style="zoom: 33%;">
<h4 id="2-提取特征"><a class="markdownIt-Anchor" href="#2-提取特征"></a> 2 提取特征</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184859288.png" alt="image-20250104184859288" style="zoom: 33%;">
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184531836.png" alt="image-20250104184531836" style="zoom:50%;">
<h4 id="3-svm"><a class="markdownIt-Anchor" href="#3-svm"></a> 3 SVM</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184713372.png" alt="image-20250104184713372" style="zoom: 33%;">
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185007538.png" alt="image-20250104185007538" style="zoom: 33%;">
<p><strong>IOU</strong></p>
<blockquote>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185250090.png" alt="image-20250104185250090" style="zoom: 50%;"><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185256627.png" alt="image-20250104185256627" style="zoom: 25%;"></p>
</blockquote>
<blockquote>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185308808.png" alt="image-20250104185308808" style="zoom: 33%;"> <img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185322806.png" alt="image-20250104185322806" style="zoom:33%;"></p>
</blockquote>
<h4 id="4-回归分类器"><a class="markdownIt-Anchor" href="#4-回归分类器"></a> 4 回归分类器</h4>
<p>pass</p>
<h4 id="优缺"><a class="markdownIt-Anchor" href="#优缺"></a> 优缺</h4>
<ul>
<li>冗余</li>
<li>慢</li>
<li>空间大</li>
</ul>
<h3 id="fast-rcnn"><a class="markdownIt-Anchor" href="#fast-rcnn"></a> Fast RCNN</h3>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104190121582.png" alt="image-20250104190121582" style="zoom:50%;">
<h4 id="0-原理-2"><a class="markdownIt-Anchor" href="#0-原理-2"></a> 0 原理</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104190220974.png" alt="image-20250104190220974" style="zoom:50%;"> 
<h4 id="1-减少重复计算特征"><a class="markdownIt-Anchor" href="#1-减少重复计算特征"></a> 1 减少重复计算特征</h4>
<p>通过全连接层进行</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104191656317.png" alt="image-20250104191656317" style="zoom:33%;">
<p><strong>正负样本</strong></p>
<blockquote></blockquote>
<h4 id="2-分类器"><a class="markdownIt-Anchor" href="#2-分类器"></a> 2 分类器</h4>
<p>全连接层实现</p>
<h4 id="3-边界框回归器"><a class="markdownIt-Anchor" href="#3-边界框回归器"></a> 3 边界框回归器</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104192439278.png" alt="image-20250104192439278" style="zoom: 33%;">
<h4 id="4-损失计算"><a class="markdownIt-Anchor" href="#4-损失计算"></a> 4 损失计算</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104192659858.png" alt="image-20250104192659858" style="zoom:33%;">
<h3 id="faster-rcnn"><a class="markdownIt-Anchor" href="#faster-rcnn"></a> Faster RCNN</h3>
<h4 id="0-原理-3"><a class="markdownIt-Anchor" href="#0-原理-3"></a> 0 原理</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194051582.png" alt="image-20250104194051582" style="zoom:33%;"> 
<p><strong>就是用RPN替换SS算法</strong></p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194210537.png" alt="image-20250104194210537" style="zoom:33%;">  
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194406137.png" alt="image-20250104194406137" style="zoom: 33%;">  
<h4 id="1-rpn"><a class="markdownIt-Anchor" href="#1-rpn"></a> 1 RPN</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194441284.png" alt="image-20250104194441284" style="zoom: 50%;">	
<ul>
<li>3x3 卷积</li>
<li>在并联两个全连接层 生成:背景和前景 + 4个参数</li>
<li></li>
<li></li>
</ul>
<h4 id="2-anchor"><a class="markdownIt-Anchor" href="#2-anchor"></a> 2 anchor</h4>
<p><strong>实现原理</strong></p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194722542.png" alt="image-20250104194722542" style="zoom:33%;"><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194733782.png" alt="image-20250104194733782" style="zoom:33%;"></p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194922010.png" alt="image-20250104194922010" style="zoom: 25%;"> 
<p>anchor 个数</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104195441622.png" alt="image-20250104195441622" style="zoom: 25%;">  
<p><strong>小感受野也可以预测大特征</strong></p>
<blockquote>
 <img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104195137512.png" alt="image-20250104195137512" style="zoom:33%;">  
</blockquote>
<h4 id="3-损失计算"><a class="markdownIt-Anchor" href="#3-损失计算"></a> 3 损失计算</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104200305676.png" alt="image-20250104200305676" style="zoom:33%;">
<h2 id="ssd"><a class="markdownIt-Anchor" href="#ssd"></a> SSD</h2>
<h3 id="原理"><a class="markdownIt-Anchor" href="#原理"></a> 原理</h3>
<p>在六个不同的层上预测不同大小的目标[ 因为:卷积程度越深 感受野越大 抽象的特征越大 那么细节就越少]</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104171147389.png" alt="image-20250104171147389" style="zoom:33%;">
<ul>
<li>b预测小目标 🐱</li>
<li>C预测大目标 🐕</li>
</ul>
<h4 id="default-box"><a class="markdownIt-Anchor" href="#default-box"></a> default box</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104171745323.png" alt="image-20250104171745323" style="zoom:67%;">
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172055346.png" alt="image-20250104172055346" style="zoom:67%;">
<h3 id="训练"><a class="markdownIt-Anchor" href="#训练"></a> 训练</h3>
<h4 id="模型"><a class="markdownIt-Anchor" href="#模型"></a> 模型</h4>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104170756080.png" alt="image-20250104170756080"><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104170840590.png" alt="image-20250104170840590" style="zoom: 25%;"></p>
<h4 id="数据处理"><a class="markdownIt-Anchor" href="#数据处理"></a> 数据处理</h4>
<h4 id="损失计算"><a class="markdownIt-Anchor" href="#损失计算"></a> 损失计算</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172613364.png" alt="image-20250104172613364" style="zoom:50%;">
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172751053.png" alt="image-20250104172751053" style="zoom:33%;">
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172759925.png" alt="image-20250104172759925" style="zoom: 33%;">
<h4 id="预测"><a class="markdownIt-Anchor" href="#预测"></a> 预测</h4>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172201462.png" alt="image-20250104172201462"> ]</p>
<p>参数数目</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172401969.png" alt="image-20250104172401969" style="zoom: 33%;"> 
<h3 id="优缺-2"><a class="markdownIt-Anchor" href="#优缺-2"></a> 优缺</h3>
<h3 id="qa"><a class="markdownIt-Anchor" href="#qa"></a> QA</h3>
<h2 id="yolo"><a class="markdownIt-Anchor" href="#yolo"></a> YOLO</h2>
<h3 id="yolov1"><a class="markdownIt-Anchor" href="#yolov1"></a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43334693/article/details/129011644?spm=1001.2014.3001.5501">YOLOv1</a></h3>
<ul>
<li>端到端单阶段</li>
<li>目标检测问题看作回归问题</li>
</ul>
<h4 id="bounding-box"><a class="markdownIt-Anchor" href="#bounding-box"></a> bounding box</h4>
<ul>
<li>x——框中心的横坐标</li>
<li>y——框中心的纵坐标</li>
<li>w——框的宽度</li>
<li>h——框的高度</li>
<li>置信度（confidence）</li>
</ul>
<p>在YOLOV1中S = 7 , B = 2即将每个输入图片分成7 × 7 个网格，每个网格将生成2 个预测框，用来框出图片中的物体。 每个框会预测出5个变量值，所以一个网格生成两个框，一个框带有5个属性，所以一个格就需要预测出5 × 2 = 10 个变量值。<br>
在YOLOv1中有<strong>20个类别的物体的条件概率</strong>，所以输出结果的后20个值就表示每一个小网格（grid cell）对应每一类物体的概率，即由该网格生产的两个预测框对应每一类物体的概率。 由此，输出的7 × 7 × 30 向量的每一项含义便清楚了。<br>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104151446113.png" alt="image-20250104151446113" style="zoom: 67%;"></p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104154104316.png" alt="image-20250104154104316" style="zoom: 33%;">
<h4 id="训练-2"><a class="markdownIt-Anchor" href="#训练-2"></a> 训练</h4>
<h5 id="网络结构"><a class="markdownIt-Anchor" href="#网络结构"></a> 网络结构</h5>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/64c2116c3e9f6d55b5aa2a8fab982a26.png" alt="img"></p>
<p>YOLOV1的输入为448 × 448 × 3 图像，输出大小为7 × 7 × 30 向量</p>
<p>在网络结构的最后一层使用的是线性激活函数，其他层使用的是****leaky ReLU****激活函数，YOLOv1中采用的leaky ReLU定义公式如下</p>
<p><img src="https://i-blog.csdnimg.cn/direct/dba9296aa0d24233abe7b02e75e4b7e9.png" alt="img"></p>
<h5 id="数据处理-2"><a class="markdownIt-Anchor" href="#数据处理-2"></a> 数据处理</h5>
<h5 id="损失计算-2"><a class="markdownIt-Anchor" href="#损失计算-2"></a> 损失计算</h5>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104155000144.png" alt="image-20250104155000144" style="zoom:67%;">
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104155310820.png" alt="image-20250104155310820" style="zoom:33%;"> 大小目标对偏移影响不同</p>
<h5 id="预测极大值抑制"><a class="markdownIt-Anchor" href="#预测极大值抑制"></a> 预测–极大值抑制</h5>
<p>7X7X2个bounding box 进行 过滤与非极大值抑制</p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104152002611.png" alt></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/d358fa901b47a00baa710246af0ea197.gif" alt="img"></p>
<h4 id="优缺-3"><a class="markdownIt-Anchor" href="#优缺-3"></a> 优缺</h4>
<p>无法很好地处理小目标和重叠目标</p>
<h4 id="qa-2"><a class="markdownIt-Anchor" href="#qa-2"></a> QA</h4>
<ol>
<li>
<h5 id="为什么两个bounding-box"><a class="markdownIt-Anchor" href="#为什么两个bounding-box"></a> 为什么两个bounding box</h5>
</li>
</ol>
<p>每个 bounding box 都有一组独立的参数，包括中心坐标、宽度、高度和置信度，能够分别拟合不同的目标。</p>
<h3 id="yolov2"><a class="markdownIt-Anchor" href="#yolov2"></a> YOLOV2</h3>
<h4 id="1-bn-加入"><a class="markdownIt-Anchor" href="#1-bn-加入"></a> 1 BN 加入</h4>
<h4 id="2-anchor-2"><a class="markdownIt-Anchor" href="#2-anchor-2"></a> 2 anchor</h4>
<p>K-mean聚类实现</p>
<p>模型学习如何调整预定义的 anchor，而不是从零开始预测边界框的所有参数。</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104164542277.png" alt="image-20250104164542277" style="zoom: 67%;"> 
<h4 id="3-pass-through-layer"><a class="markdownIt-Anchor" href="#3-pass-through-layer"></a> 3 pass through layer</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104160704522.png" alt="image-20250104160704522" style="zoom:67%;"> 
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104160931404.png" alt="image-20250104160931404" style="zoom:50%;"> 
<h5 id="4-多尺度数据输入"><a class="markdownIt-Anchor" href="#4-多尺度数据输入"></a> 4 多尺度数据输入</h5>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104161259611.png" alt="image-20250104161259611" style="zoom:50%;"> 
<h4 id="faster"><a class="markdownIt-Anchor" href="#faster"></a> Faster</h4>
<p>1</p>
<h3 id="yolov3"><a class="markdownIt-Anchor" href="#yolov3"></a> YOLOV3</h3>
<h4 id="单标签分类改进为多标签分类"><a class="markdownIt-Anchor" href="#单标签分类改进为多标签分类"></a> 单标签分类改进为多标签分类</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105125615278.png" alt="image-20250105125615278" style="zoom:50%;"> 
<h4 id="pan"><a class="markdownIt-Anchor" href="#pan"></a> PAN</h4>
<h3 id="yolov4"><a class="markdownIt-Anchor" href="#yolov4"></a> YOLOV4</h3>
<h4 id="1-原理"><a class="markdownIt-Anchor" href="#1-原理"></a> 1 原理</h4>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105142450863.png" alt="image-20250105142450863"><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105142605476.png" alt="image-20250105142605476" style="zoom:67%;"></p>
<h4 id="2-输入端"><a class="markdownIt-Anchor" href="#2-输入端"></a> 2 输入端</h4>
<h5 id="sat自对抗训练"><a class="markdownIt-Anchor" href="#sat自对抗训练"></a> SAT自对抗训练</h5>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151656124.png" alt="image-20250105151656124" style="zoom:67%;">
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151712577.png" alt="image-20250105151712577" style="zoom:67%;">
<h5 id="label-smoothing类标签平滑"><a class="markdownIt-Anchor" href="#label-smoothing类标签平滑"></a> Label Smoothing类标签平滑</h5>
<h4 id="3-backbone"><a class="markdownIt-Anchor" href="#3-backbone"></a> 3 Backbone</h4>
<h5 id="csp"><a class="markdownIt-Anchor" href="#csp"></a> CSP</h5>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105130506026.png" alt="image-20250105130506026" style="zoom:50%;"> 
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105152215756.png" alt="image-20250105152215756" style="zoom:50%;"> 
<h4 id="4-neck"><a class="markdownIt-Anchor" href="#4-neck"></a> 4 Neck</h4>
<p>一个颈部neck由几个自下而上的路径和几个自上而下的路径组成。具有该机制的网络包括特征金字塔网络(FPN)、路径汇聚网络(PAN)、BiFPN和NAS-FPN。</p>
<h5 id="1-fpn"><a class="markdownIt-Anchor" href="#1-fpn"></a> 1 FPN</h5>
<p>引入了自底向上的路径，使得底层信息更容易传到顶部</p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150718121.png" alt="image-20250105150718121"></p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150726295.png" alt="image-20250105150726295"></p>
<h5 id="2-pan"><a class="markdownIt-Anchor" href="#2-pan"></a> 2 PAN</h5>
<p>特征层之间融合时是直接通过addition的方式进行融合的，而Yolov4中则采用在通道方向concat拼接操作融合的</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150948205.png" alt="image-20250105150948205" style="zoom:67%;">
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150823004.png" alt="image-20250105150823004"></p>
<h5 id="3-spp"><a class="markdownIt-Anchor" href="#3-spp"></a> 3 SPP</h5>
<p>来解决不同尺寸的特征图如何进入全连接层的，在网络的最后一层concat所有特征图，后面能够继续接CNN模块。</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150606229.png" alt="image-20250105150606229" style="zoom:50%;">
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150638919.png" style="zoom: 67%;">
<h4 id="bof"><a class="markdownIt-Anchor" href="#bof"></a> BoF</h4>
<p>我们把这些只会改变培训策略或只增加培训成本的方法称为“bag of freebies”。</p>
<h5 id="1-数据增强"><a class="markdownIt-Anchor" href="#1-数据增强"></a> 1 数据增强</h5>
<h5 id="2-解决数据集中语义分布偏差问题"><a class="markdownIt-Anchor" href="#2-解决数据集中语义分布偏差问题"></a> 2 解决数据集中语义分布偏差问题</h5>
<p>不同类之间存在数据不平衡的问题</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143153315.png" alt="image-20250105143153315" style="zoom: 67%;"> 
<h5 id="3-边界框bbox回归的目标函数"><a class="markdownIt-Anchor" href="#3-边界框bbox回归的目标函数"></a> 3 边界框(BBox)回归的目标函数 ??</h5>
<p>直接估计BBox中每个点的坐标值是要将这些点作为自变量来处理，但实际上并没有考虑对象本身的完整性</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143449548.png" alt="image-20250105143449548" style="zoom:67%;">
<h4 id="bos"><a class="markdownIt-Anchor" href="#bos"></a> BoS</h4>
<p>对于那些只增加少量推理成本但又能显著提高目标检测精度的插件模块和后处理方法，我们称它们为“bag of specials&quot;</p>
<h5 id="1-增强感受野"><a class="markdownIt-Anchor" href="#1-增强感受野"></a> 1 增强感受野</h5>
<p><strong>①改进的SPP模块</strong></p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143750945.png" alt="image-20250105143750945"></p>
<p><strong>②ASPP模块</strong></p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143836518.png" alt="image-20250105143836518"></p>
<p><strong>③RFB模块</strong></p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143846925.png" alt="image-20250105143846925"></p>
<h5 id="2-注意力机制"><a class="markdownIt-Anchor" href="#2-注意力机制"></a> 2 注意力机制</h5>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143912123.png" alt="image-20250105143912123" style="zoom:50%;"> 
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143920723.png" alt="image-20250105143920723" style="zoom: 50%;"> 
<h5 id="3-特征融合"><a class="markdownIt-Anchor" href="#3-特征融合"></a> 3 特征融合</h5>
<p><strong>①SFAM：</strong> 主要思想是利用SE模块在多尺度的拼接特征图上进行信道级重加权。</p>
<p><strong>②ASFF：</strong> 使用softmax对多尺度拼接特征图在点维度进行加权。</p>
<p><strong>③BiFPN：</strong> 提出了多输入加权剩余连接来执行按比例的水平重加权，然后添加不同比例的特征图。</p>
<h5 id="4-激活函数"><a class="markdownIt-Anchor" href="#4-激活函数"></a> 4 激活函数</h5>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105144012738.png" alt="image-20250105144012738" style="zoom:50%;"> 
<h4 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制"></a> 注意力机制</h4>
<h5 id="cbamconvolutional-block-attention-module注意力机制"><a class="markdownIt-Anchor" href="#cbamconvolutional-block-attention-module注意力机制"></a> **CBAM(Convolutional Block Attention Module)**注意力机制</h5>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151035854.png" alt="image-20250105151035854" style="zoom: 50%;">
<h5 id="channel-attention-module通道注意力模块"><a class="markdownIt-Anchor" href="#channel-attention-module通道注意力模块"></a> <strong>Channel attention module(通道注意力模块)</strong></h5>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151238032.png" alt="image-20250105151238032"></p>
<h5 id="attention-module空间注意力模块"><a class="markdownIt-Anchor" href="#attention-module空间注意力模块"></a> <strong>attention module(空间注意力模块)</strong></h5>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151404902.png" alt="image-20250105151404902" style="zoom:80%;">
<h4 id="dropblock正则化"><a class="markdownIt-Anchor" href="#dropblock正则化"></a> Dropblock正则化</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105130645146.png" alt="image-20250105130645146" style="zoom: 50%;"> 
<blockquote>
<p>Q：全连接层上效果很好的Dropout在卷积层上效果并不好？</p>
<pre><code>中间Dropout的方式会随机的删减丢弃一些信息，但Dropblock的研究者认为，卷积层对于这种随机丢弃并不敏感，因为卷积层通常是三层连用：卷积+激活+池化层，池化层本身就是对相邻单元起作用。

而且即使随机丢弃，卷积层仍然可以从相邻的激活单元学习到相同的信息。因此，在全连接层上效果很好的Dropout在卷积层上效果并不好。所以右图Dropblock的研究者则干脆整个局部区域进行删减丢弃。
</code></pre>
</blockquote>
<h3 id="yolov5"><a class="markdownIt-Anchor" href="#yolov5"></a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43334693/article/details/129312409">YOLOV5</a></h3>
<h4 id="1-原理-2"><a class="markdownIt-Anchor" href="#1-原理-2"></a> 1 原理</h4>
<img src="https://i-blog.csdnimg.cn/blog_migrate/a573a17c82a6a1e3d23469541d3b4afc.jpeg" alt="img" style="zoom: 80%;">
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105140339482.png" alt="image-20250105140339482" style="zoom: 80%;"> 
<h4 id="2-输入"><a class="markdownIt-Anchor" href="#2-输入"></a> 2 输入</h4>
<h5 id="数据增强"><a class="markdownIt-Anchor" href="#数据增强"></a> 数据增强</h5>
<h4 id="3-backbone-2"><a class="markdownIt-Anchor" href="#3-backbone-2"></a> 3 Backbone</h4>
<h5 id="focus"><a class="markdownIt-Anchor" href="#focus"></a> Focus</h5>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141242384.png" alt="image-20250105141242384"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/009d2d69aae2b1cb6ecede41530f82bf.png" alt="img"></p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141341837.png" alt="image-20250105141341837"></p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141346413.png" alt="image-20250105141346413"></p>
<h5 id="csp-2"><a class="markdownIt-Anchor" href="#csp-2"></a> CSP</h5>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141515679.png" alt="image-20250105141515679"></p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141525595.png" alt="image-20250105141525595" style="zoom:50%;"> 
<h4 id="4-neck-2"><a class="markdownIt-Anchor" href="#4-neck-2"></a> 4 Neck</h4>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141614203.png" alt="image-20250105141614203"></p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141619565.png" alt="image-20250105141619565" style="zoom: 50%;">
<h4 id="5-训练策略"><a class="markdownIt-Anchor" href="#5-训练策略"></a> 5 训练策略</h4>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105123929037.png" alt="image-20250105123929037" style="zoom: 50%;"> 
<h1 id="segmentation"><a class="markdownIt-Anchor" href="#segmentation"></a> Segmentation</h1>
<h2 id="unet"><a class="markdownIt-Anchor" href="#unet"></a> UNET</h2>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105155647634.png" alt="image-20250105155647634" style="zoom:33%;"> 
<h3 id="u2net"><a class="markdownIt-Anchor" href="#u2net"></a> U2NET</h3>
<p>SOD任务</p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105155624697.png" alt="image-20250105155624697" style="zoom:50%;"> 整体</p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105155734798.png" alt="image-20250105155734798" style="zoom: 33%;"> 小块</p>
<h2 id="sam"><a class="markdownIt-Anchor" href="#sam"></a> SAM</h2>
<p><img src="https://github.com/facebookresearch/segment-anything/raw/main/assets/model_diagram.png?raw=true" alt="SAM design"></p>
<p><img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250107134550384.png" alt="image-20250107134550384"></p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250107134129164.png" alt="image-20250107134129164" style="zoom: 50%;">
<h1 id="lvm"><a class="markdownIt-Anchor" href="#lvm"></a> LVM</h1>
<h3 id="vit"><a class="markdownIt-Anchor" href="#vit"></a> VIT</h3>
<h4 id="原理-2"><a class="markdownIt-Anchor" href="#原理-2"></a> 原理</h4>
<p><strong>图像分块</strong>：</p>
<p>小块16*16</p>
<img src="/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105171232310.png" alt="image-20250105171232310" style="zoom:50%;">
<p><strong>线性嵌入</strong>：<br>
使用线性投影将每个图像块映射到固定长度的向量（称为 Patch Embedding），然后通过添加位置编码（Positional Encoding）表示块的位置信息。</p>
<p><strong>Transformer 编码器</strong>：<br>
利用标准的 Transformer 编码器（多头自注意力和前馈网络）对这些嵌入进行处理，学习全局的图像特征</p>
<p><strong>分类头</strong>：<br>
引入一个特殊的 [CLS] token，用于整合所有块的信息。最后通过 MLP（多层感知机）对 [CLS] token 进行分类。</p>
<img src="https://i-blog.csdnimg.cn/blog_migrate/3360fc9f03a84f99067859e2db20ffb5.gif" alt="img" style="zoom:60%;">
<h3 id="swin-transformer"><a class="markdownIt-Anchor" href="#swin-transformer"></a> Swin Transformer</h3>
<h4 id="核心原理"><a class="markdownIt-Anchor" href="#核心原理"></a> 核心原理：</h4>
<ol>
<li><strong>分层架构</strong>：<br>
Swin Transformer 的结构是分层的，类似于卷积神经网络（CNN）的金字塔设计。随着层数的增加，特征图的分辨率逐渐降低，通道数逐渐增加。</li>
<li><strong>滑动窗口注意力 (Shifted Window Attention)</strong>：
<ul>
<li>将图像划分为多个固定大小的窗口（如 7×77 \times 77×7），在每个窗口内计算自注意力，降低计算复杂度。</li>
<li>在不同层之间引入“滑动窗口”机制，使窗口之间的信息可以交互，增加全局建模能力。</li>
</ul>
</li>
<li><strong>线性复杂度</strong>：<br>
通过限制注意力计算在窗口内完成，避免了 ViT 的全局注意力计算带来的高时间和空间复杂度问题。</li>
<li><strong>Patch 合并</strong>：<br>
在分层过程中，通过 Patch 合并操作减少特征图分辨率，同时增加通道维度。</li>
</ol>
<h4 id="滑动窗口注意力"><a class="markdownIt-Anchor" href="#滑动窗口注意力"></a> 滑动窗口注意力</h4>
<img src="https://i-blog.csdnimg.cn/blog_migrate/4835528644ffcb483732678807ab00b6.png#pic_center" alt="在这里插入图片描述" style="zoom:33%;">
<h4 id="patch-merging"><a class="markdownIt-Anchor" href="#patch-merging"></a> <strong>Patch Merging</strong></h4>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/a3b29d89bad938bc2475dfca1df80501.png" alt="img"></p>
<h4 id="w-msa"><a class="markdownIt-Anchor" href="#w-msa"></a> W-MSA</h4>
<img src="https://i-blog.csdnimg.cn/blog_migrate/08dfc09f92ff3766608490fcbcd355b2.png#pic_center" alt="在这里插入图片描述" style="zoom:50%;">
<h4 id="sw-msa"><a class="markdownIt-Anchor" href="#sw-msa"></a> SW-MSA</h4>
<img src="https://i-blog.csdnimg.cn/blog_migrate/05a8fc43e0f99856f885fd489388136b.png#pic_center" alt="在这里插入图片描述" style="zoom:33%;">
<h3 id="mae"><a class="markdownIt-Anchor" href="#mae"></a> MAE</h3>
<h4 id="核心原理-2"><a class="markdownIt-Anchor" href="#核心原理-2"></a> 核心原理：</h4>
<ol>
<li><strong>随机掩码（Masking）</strong>：
<ul>
<li>将输入图像划分为一系列 Patch（例如 16×1616 \times 1616×16），并随机遮掩一定比例的 Patch（如 75%）。</li>
<li>遮掩的部分从输入中移除，剩余的 Patch 作为输入特征。</li>
</ul>
</li>
<li><strong>编码器（Encoder）</strong>：
<ul>
<li>使用 ViT（Vision Transformer）作为编码器，仅处理未被遮掩的 Patch，提取高效的全局特征。</li>
</ul>
</li>
<li><strong>解码器（Decoder）</strong>：
<ul>
<li>一个轻量级的解码器负责重建被遮掩的 Patch。</li>
<li>解码器接受编码器的输出和位置编码，并尝试还原完整的图像。</li>
</ul>
</li>
<li><strong>重建目标（Reconstruction Loss）</strong>：
<ul>
<li>模型通过最小化重建误差（通常是均方误差，MSE）来优化，从而学习有意义的图像特征。</li>
</ul>
</li>
</ol>
<img src="https://pic2.zhimg.com/v2-e6a970e23f0b03371047a6014a25a175_1440w.jpg" alt="img" style="zoom: 50%;">
<h3 id="igpt"><a class="markdownIt-Anchor" href="#igpt"></a> IGPT</h3>
<h4 id="核心原理-3"><a class="markdownIt-Anchor" href="#核心原理-3"></a> 核心原理：</h4>
<ol>
<li><strong>图像像素序列化</strong>：
<ul>
<li>将二维图像展平为一维像素序列，类似于自然语言处理中的文本序列。</li>
<li>每个像素值被表示为一个离散的类别（如颜色索引或灰度值）。</li>
</ul>
</li>
<li><strong>Transformer 架构</strong>：
<ul>
<li>使用标准的 Transformer 模型，将图像像素序列作为输入，学习序列中各像素值之间的依赖关系。</li>
<li>通过<strong>自回归方式</strong>预测下一个像素值，实现图像生成任务。</li>
</ul>
</li>
<li><strong>无监督学习</strong>：
<ul>
<li>模型通过最大化训练数据的对数似然估计进行优化，学习如何生成与训练图像分布一致的新图像。</li>
</ul>
</li>
</ol>
<img src="https://pic1.zhimg.com/v2-56d15a5487853b70a504d7e330f9d074_1440w.jpg" alt="img" style="zoom:33%;">

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/12/31/%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/" data-id="cm5modkti0005xsv40rukfvai" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-深度学习问题总结" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/06/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="post-time" datetime="2024-06-07T08:37:27.321Z" itemprop="datePublished">
    <span class="post-month">6月</span><br/>
    <span class="post-day">07</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="交叉熵为什么常用于机器学习中的分类问题"><a class="markdownIt-Anchor" href="#交叉熵为什么常用于机器学习中的分类问题"></a> 交叉熵为什么常用于机器学习中的分类问题</h3>
<p>交叉熵在机器学习中的分类问题中广泛使用，尤其是在多分类和二分类任务中，这是由于交叉熵具有以下几个重要特性和优势：</p>
<h4 id="1-衡量真实分布和预测分布之间的差异"><a class="markdownIt-Anchor" href="#1-衡量真实分布和预测分布之间的差异"></a> 1. 衡量真实分布和预测分布之间的差异</h4>
<p>交叉熵能够很好地度量模型的预测概率分布与真实概率分布之间的差异。其定义为：</p>
<p class="katex-block katex-error" title="ParseError: KaTeX parse error: Undefined control sequence: \[ at position 1: \̲[̲ H(p, q) = - \s…">\[ H(p, q) = - \sum_{x} p(x) \log q(x) \]
</p>
<p>其中，( p(x) ) 是真实标签的概率分布，通常是one-hot编码（对于正确类别概率为1，其余类别概率为0），( q(x) ) 是模型的预测概率分布。</p>
<h4 id="2-对错误分类有较大惩罚"><a class="markdownIt-Anchor" href="#2-对错误分类有较大惩罚"></a> 2. 对错误分类有较大惩罚</h4>
<p>交叉熵损失函数对错误分类的惩罚较大，能够更有效地引导模型进行优化。举个例子，对于一个二分类问题，假设真实标签 ( p = 1 )，而模型预测的概率 ( q ) 很接近0（完全错误的预测），则交叉熵损失值会非常高。这种特性使得交叉熵在训练过程中能够更快速地减少错误分类的概率。</p>
<h4 id="3-可微性"><a class="markdownIt-Anchor" href="#3-可微性"></a> 3. 可微性</h4>
<p>交叉熵损失函数是可微的，这使得它非常适合梯度下降等优化算法。通过计算损失函数相对于模型参数的梯度，模型可以逐步更新参数以最小化损失，从而提高分类性能。</p>
<h4 id="4-与softmax结合良好"><a class="markdownIt-Anchor" href="#4-与softmax结合良好"></a> 4. 与Softmax结合良好</h4>
<p>在多分类问题中，交叉熵损失函数通常与Softmax激活函数一起使用。Softmax函数将模型的输出转化为一个概率分布：</p>
<p class="katex-block katex-error" title="ParseError: KaTeX parse error: Undefined control sequence: \[ at position 1: \̲[̲ \sigma(z_i) = …">\[ \sigma(z_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}} \]
</p>
<p>结合Softmax和交叉熵，损失函数的梯度计算更为简便，优化过程更稳定。</p>
<h4 id="5-适合概率解释"><a class="markdownIt-Anchor" href="#5-适合概率解释"></a> 5. 适合概率解释</h4>
<p>交叉熵损失函数直接基于概率，因此它能够提供一种自然的方式来解释模型的输出。例如，输出值可以直接解释为某个类别的概率，这在很多实际应用中是非常有用的，如图像分类、自然语言处理等。</p>
<h4 id="6-数学上的凸性"><a class="markdownIt-Anchor" href="#6-数学上的凸性"></a> 6. 数学上的凸性</h4>
<p>在二分类问题中，交叉熵损失函数是凸的，这意味着它有唯一的全局最优解。尽管在多分类问题中，交叉熵损失函数可能不是严格凸的，但在实践中通过适当的优化方法（如SGD，Adam等）依然能有效地找到较优解。</p>
<h3 id="实际例子"><a class="markdownIt-Anchor" href="#实际例子"></a> 实际例子</h3>
<p>以二分类问题为例，假设真实标签 ( y ) 为1（即正类），模型预测正类的概率为 ( \hat{y} )。交叉熵损失函数为：</p>
<p class="katex-block katex-error" title="ParseError: KaTeX parse error: Undefined control sequence: \[ at position 1: \̲[̲ L = -[y \log(\…">\[ L = -[y \log(\hat{y}) + (1 - y) \log(1 - \hat{y})] \]
</p>
<p>当 ( y = 1 ) 时，损失函数简化为 ( L = -\log(\hat{y}) )。如果模型预测 ( \hat{y} ) 很小，则损失会非常大，从而迫使模型在训练过程中提高对正类的预测概率。</p>
<p>总的来说，交叉熵损失函数由于其良好的数学性质和对分类问题的适用性，成为机器学习中分类问题的标准选择。</p>
<h2 id="高维而带来的数据稀疏性问题"><a class="markdownIt-Anchor" href="#高维而带来的数据稀疏性问题"></a> 高维而带来的数据稀疏性问题</h2>
<p><strong>距离度量失效</strong>：在高维空间中，数据点之间的距离度量（如欧氏距离）可能失去区分性。随着维度增加，不同数据点之间的距离变得越来越相似，从而导致传统的距离度量方法失效。这对基于距离的算法（如K近邻算法、聚类算法等）影响尤为显著。</p>
<p><strong>计算复杂度增加</strong>：高维数据需要处理的特征数增多，计算复杂度随之增加。这对存储和计算资源都是巨大的挑战，尤其是在处理大规模数据集时。</p>
<p><strong>维度诅咒</strong>：高维数据通常伴随着“维度诅咒”问题，即随着维度增加，数据点需要的样本量指数级增长，才能维持同样的统计显著性和精度。这导致在高维空间中进行数据建模和分析变得困难，模型容易过拟合。</p>
<p><strong>模型解释性降低</strong>：高维数据中的特征较多，模型的解释性会降低。人类难以理解和解释高维空间中的特征关系，从而影响决策和分析的透明度。</p>
<h3 id="解决办法"><a class="markdownIt-Anchor" href="#解决办法"></a> 解决办法：</h3>
<p><strong>特征选择</strong>：通过选择与目标变量高度相关的特征，去除冗余或不相关的特征，从而降低数据的维度，提高模型的性能。</p>
<p><strong>特征提取</strong>：通过技术如主成分分析（PCA）、线性判别分析（LDA）和非负矩阵分解（NMF）等方法，将原始高维数据映射到低维空间，同时尽可能保留数据的主要信息。</p>
<p><strong>稀疏表示</strong>：利用稀疏编码、L1正则化等方法，使得数据在较少的特征上具有较大的表示，从而减少模型的复杂度和过拟合风险。</p>
<p><strong>核方法</strong>：如支持向量机（SVM）的核技巧，通过在高维空间中进行操作而不显式地计算高维特征，来处理非线性问题。</p>
<p><strong>深度学习</strong>：深度神经网络，尤其是自动编码器（Autoencoder），可以有效地学习数据的低维表示，从而在高维数据处理中表现出色</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/06/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/" data-id="cly1c03750000wwv438464fxl" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2024年4月18日-深度学习自制框架" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/" class="article-date">
  <time class="post-time" datetime="2024-04-18T12:15:29.000Z" itemprop="datePublished">
    <span class="post-month">4月</span><br/>
    <span class="post-day">18</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/">2024年4月18日 深度学习自制框架</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>b</p>
<p>本书结构</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418201605770.png" alt="image-20240418201605770" style="zoom:67%;">
<h1 id="第一阶段-自动微分"><a class="markdownIt-Anchor" href="#第一阶段-自动微分"></a> 第一阶段 自动微分</h1>
<h2 id="1-变量"><a class="markdownIt-Anchor" href="#1-变量"></a> 1 变量</h2>
<p>pass</p>
<h2 id="2-函数"><a class="markdownIt-Anchor" href="#2-函数"></a> 2 函数</h2>
<p>pass</p>
<h2 id="3-函数连续调用"><a class="markdownIt-Anchor" href="#3-函数连续调用"></a> 3 函数连续调用</h2>
<p>pass</p>
<h2 id="4-数值微分"><a class="markdownIt-Anchor" href="#4-数值微分"></a> 4 数值微分</h2>
<h3 id="1-导数"><a class="markdownIt-Anchor" href="#1-导数"></a> 1 导数</h3>
<p>导数表示</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235609679.png" alt="image-20240418235609679"></p>
<h3 id="2-数值微分"><a class="markdownIt-Anchor" href="#2-数值微分"></a> 2 数值微分</h3>
<p>计算机不能处理极限值 。 因此，这里的 h 表示一个近似值来计算 式 4. 1 就叫做数值微分</p>
<h4 id="21前向差分近似"><a class="markdownIt-Anchor" href="#21前向差分近似"></a> 2.1前向差分近似</h4>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235758166.png" alt="image-20240418235758166"></p>
<h4 id="22中心差分近似"><a class="markdownIt-Anchor" href="#22中心差分近似"></a> 2.2中心差分近似</h4>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235805977.png" alt="image-20240418235805977"></p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235810650.png" alt="image-20240418235810650" style="zoom:67%;">
<h2 id="5-反向传播"><a class="markdownIt-Anchor" href="#5-反向传播"></a> 5 反向传播</h2>
<p>y 对 z 的导数 11J 以用式子 5.1 表示：</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235920234.png" alt="image-20240418235920234"></p>
<p>也可写成：</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235944251.png" alt="image-20240418235944251"></p>
<p>求导流程</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419000026551.png" alt="image-20240419000026551" style="zoom:50%;">
<p>求导过程：</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418214342085.png" alt="image-20240418214342085" style="zoom:80%;">
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418212406502.png" alt="image-20240418212406502" style="zoom:80%;">
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418214212099.png" alt="image-20240418214212099"></p>
<p>正向传播</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418213741377.png" alt="image-20240418213741377"></p>
<p>反向传播</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418214157026.png" alt="image-20240418214157026"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418220753163.png" alt="image-20240418220753163"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418221125070.png" alt="image-20240418221125070"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418221120878.png" alt="image-20240418221120878"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418221115733.png" alt="image-20240418221115733"></p>
<p>\</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235104955.png" alt="image-20240418235104955"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419220559301.png" alt="image-20240419220559301"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419224326395.png" alt="image-20240419224326395"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419224320883.png" alt="image-20240419224320883"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419224730866.png" alt="image-20240419224730866"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419225947503.png" alt="image-20240419225947503"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420153251259.png" alt="image-20240420153251259"></p>
<h1 id="2"><a class="markdownIt-Anchor" href="#2"></a> 2</h1>
<h2 id="217-内存管理和循环引用"><a class="markdownIt-Anchor" href="#217-内存管理和循环引用"></a> 2.17 内存管理和循环引用</h2>
<h3 id="1-内存管理"><a class="markdownIt-Anchor" href="#1-内存管理"></a> 1 内存管理</h3>
<ul>
<li>
<p>一种是引用计数</p>
</li>
<li>
<p>一种是分代垃圾凹收</p>
</li>
</ul>
<h3 id="2-计数方式"><a class="markdownIt-Anchor" href="#2-计数方式"></a> 2 计数方式</h3>
<p>​	每个对象在被创建时的引用计数为0，当它被另一个对象引用时引用计数加1，当引用停止时，引用计数减1。最终，当引用计数变为0时 python解释器会回收该对象。</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420155229195.png" alt="image-20240420155229195" style="zoom:67%;">
<p>当a = b = c = None时，对象之间的关系发生变化 此时a的引用计数变为O(b和c的引用计数为1) 对此. a立即被删除 删除 a 导致b的引用计数从1变成O. 所以b也被删除。</p>
<h3 id="3-循环引用"><a class="markdownIt-Anchor" href="#3-循环引用"></a> 3 循环引用</h3>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420155157415.png" alt="image-20240420155157415" style="zoom:67%;">
<p>采用 <code>分代垃圾回收</code>处理</p>
<h3 id="4-弱引用"><a class="markdownIt-Anchor" href="#4-弱引用"></a> 4 弱引用</h3>
<p>​	用weakref.ref函数来创建弱引用</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420155447235.png" alt="image-20240420155447235" style="zoom:67%;">
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420155452283.png" alt="image-20240420155452283" style="zoom:67%;">
<p>a=None 时，b虽然用了这个对象，但由于是弱引用，所以对引用计数没有影响</p>
<h3 id="5修改"><a class="markdownIt-Anchor" href="#5修改"></a> 5修改</h3>
<p><strong>对比：</strong></p>
<p>之前：</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420160208866.png" alt="image-20240420160208866"></p>
<p>之后：</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420160154381.png" alt="image-20240420160154381" style="zoom:67%;">
<h2 id="218减少内存使用量的模式"><a class="markdownIt-Anchor" href="#218减少内存使用量的模式"></a> 2.18减少内存使用量的模式</h2>
<p>第1项改进是减少反向传播消耗的内存使用址， 这项改进提供了立即清除元用导数的机制。</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420160709236.png" alt="image-20240420160709236"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420161151386.png" alt="image-20240420161151386"></p>
<p>第2项改进是提供&quot;不需要反向 传播时的模式&quot;</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420161534975.png" alt="image-20240420161534975"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420161630351.png" alt="image-20240420161630351"></p>
<p>是否 <code>creator</code>也不需要了呢？</p>
<p>Constant</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154131602.png" alt="image-20240420154131602"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154150170.png" alt="image-20240420154150170"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154244033.png" alt="image-20240420154244033"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154246451.png" alt="image-20240420154246451"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154312677.png" alt="image-20240420154312677"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154416108.png" alt="image-20240420154416108"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154432668.png" alt="image-20240420154432668"></p>
<h1 id="3-高阶导数"><a class="markdownIt-Anchor" href="#3-高阶导数"></a> 3 高阶导数</h1>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/" data-id="clx4fkxnj000dn0v43cmx8t28" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/">next &amp;raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Weakliy_Blog</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>79</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>17</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="Github">
          Github
        </a>
      
    </div>

    <div class="friend-link">
      <h2>联系我</h2>
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2024 - 2025 Weakliy<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">首页</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">总览</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">xxx</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">xxxx</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>