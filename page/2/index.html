<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Weakliy_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Weakliy_Blog">
<meta property="og:url" content="https://shakewely.github.io/page/2/index.html">
<meta property="og:site_name" content="Weakliy_Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Weakliy">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Weakliy_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>110</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>32</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main">
  
    <article id="post-2025年6月20日-huggingface" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/06/20/2025%E5%B9%B46%E6%9C%8820%E6%97%A5-huggingface/" class="article-date">
  <time class="post-time" datetime="2025-06-20T02:44:42.000Z" itemprop="datePublished">
    <span class="post-month">6月</span><br/>
    <span class="post-day">20</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/06/20/2025%E5%B9%B46%E6%9C%8820%E6%97%A5-huggingface/">2025年6月20日 huggingface</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/06/20/2025%E5%B9%B46%E6%9C%8820%E6%97%A5-huggingface/" data-id="cmc9s779v00002ov4g96ba50c" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年6月5日-后处理" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/06/05/2025%E5%B9%B46%E6%9C%885%E6%97%A5-%E5%90%8E%E5%A4%84%E7%90%86/" class="article-date">
  <time class="post-time" datetime="2025-06-05T03:36:49.000Z" itemprop="datePublished">
    <span class="post-month">6月</span><br/>
    <span class="post-day">05</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/06/05/2025%E5%B9%B46%E6%9C%885%E6%97%A5-%E5%90%8E%E5%A4%84%E7%90%86/">2025年6月5日 后处理</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="2-基于空间位置关系的计数逻辑"><a class="markdownIt-Anchor" href="#2-基于空间位置关系的计数逻辑"></a> 2. <strong>基于空间位置关系的计数逻辑</strong></h3>
<h4 id="技术含义"><a class="markdownIt-Anchor" href="#技术含义"></a> 技术含义</h4>
<ul>
<li>
<p><strong>定义</strong>：基于空间位置关系的计数逻辑利用目标边界框的空间分布特性（如位置、距离、方向等），对检测结果进行后处理，以减少误报并优化计数准确性。</p>
</li>
<li>
<p><strong>应用场景</strong>：在流水线检测中，目标（如零件、包裹）通常具有特定的空间分布规律（如沿传送带排列、在固定区域内出现）。通过分析边界框的空间关系，可以过滤不符合场景逻辑的误报。</p>
</li>
<li>
<p>实现方式</p>
<p>：</p>
<ol>
<li>
<p>空间聚类</p>
<p>：</p>
<ul>
<li>对检测到的边界框进行聚类（如DBSCAN算法），根据空间距离合并或过滤重叠框。</li>
<li>示例：若两个边界框中心距离过近（&lt;某个阈值），则认为是同一目标，保留置信度较高的框。</li>
</ul>
</li>
<li>
<p>轨迹约束</p>
<p>：</p>
<ul>
<li>在视频或连续帧中，利用目标的空间运动轨迹（如流水线上的线性移动）过滤异常框。</li>
<li>示例：若检测框的位置偏离预期轨迹（如传送带路径），则视为误报。</li>
</ul>
</li>
<li>
<p>计数规则</p>
<p>：</p>
<ul>
<li>根据空间分布规律（如目标在图像中的网格区域），统计目标数量。</li>
<li>示例：在流水线场景中，只计数位于传送带区域的检测框。</li>
</ul>
</li>
</ol>
</li>
</ul>
<p>‘’</p>
<h3 id="3-关键区域roi检测"><a class="markdownIt-Anchor" href="#3-关键区域roi检测"></a> 3. <strong>关键区域ROI检测</strong></h3>
<h4 id="技术含义-2"><a class="markdownIt-Anchor" href="#技术含义-2"></a> 技术含义</h4>
<ul>
<li>
<p><strong>定义</strong>：ROI（Region of Interest，感兴趣区域）检测是指在图像中预定义关键区域，仅对这些区域内的检测结果进行处理，忽略其他区域的预测框，从而过滤误报。</p>
</li>
<li>
<p><strong>应用场景</strong>：在流水线检测中，目标通常出现在特定区域（如传送带中心、固定工作台）。通过定义ROI，可以聚焦于关键区域，减少背景区域的误报。</p>
</li>
<li>
<p>实现方式</p>
<p>：</p>
<ol>
<li>
<p>定义ROI</p>
<p>：</p>
<ul>
<li>手动指定ROI区域（如矩形坐标[x, y, w, h]）或通过图像分割算法自动提取（如基于颜色、纹理）。</li>
<li>示例：传送带区域为图像中部，定义为[x1, y1, x2, y2] = [100, 50, 540, 590]（基于640x640分辨率）。</li>
</ul>
</li>
<li>
<p>过滤检测框</p>
<p>：</p>
<ul>
<li>仅保留中心点位于ROI内的边界框，或IoU与ROI区域大于某个阈值（如0.5）的框。</li>
</ul>
</li>
<li>
<p>计数优化</p>
<p>：</p>
<ul>
<li>在ROI内进行目标计数，忽略ROI外的检测结果。</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><strong>Soft-NMS（Soft Non-Maximum Suppression）</strong>：</p>
<ul>
<li>
<p><strong>定义</strong>：传统NMS通过IoU阈值直接丢弃重叠框，Soft-NMS通过降低重叠框的置信度（而非直接丢弃）保留更多潜在目标。</p>
</li>
<li>
<p><strong>优势</strong>：提升召回率（约2%-5%），尤其适合密集目标场景。</p>
</li>
<li>
<p>实现</p>
<p>：</p>
<ul>
<li>
<p>修改YOLOv5/v8的utils/general.py中的non_max_suppression函数，添加Soft-NMS逻辑。</p>
</li>
<li>
<p>示例（伪代码）：</p>
</li>
</ul>
</li>
<li>
<p><strong>适用场景</strong>：密集目标检测（如流水线上的零件堆叠）。</p>
</li>
</ul>
<p><strong>时序平滑（Temporal Smoothing）</strong>：</p>
<ul>
<li>
<p><strong>定义</strong>：在视频或连续帧中，利用多帧检测结果的时序一致性，平滑边界框位置和置信度，过滤抖动或瞬时误报。</p>
</li>
<li>
<p>实现</p>
<p>：</p>
<ul>
<li>使用卡尔曼滤波或均值滤波对边界框坐标进行平滑。</li>
<li>示例：对连续5帧的检测框取平均值，过滤异常框。</li>
</ul>
</li>
<li>
<p><strong>适用场景</strong>：流水线视频检测，目标运动轨迹可预测。</p>
</li>
</ul>
<h3 id="2-智能抽帧的实现方法"><a class="markdownIt-Anchor" href="#2-智能抽帧的实现方法"></a> 2. <strong>智能抽帧的实现方法</strong></h3>
<p>智能抽帧算法通常结合<strong>帧间差异分析</strong>、<strong>目标跟踪</strong>和<strong>场景上下文</strong>，动态决定哪些帧需要处理。以下是实现步骤和关键技术：</p>
<h4 id="步骤1帧间差异分析"><a class="markdownIt-Anchor" href="#步骤1帧间差异分析"></a> 步骤1：帧间差异分析</h4>
<ul>
<li>
<p><strong>目的</strong>：通过比较连续帧的差异，识别内容变化显著的帧作为关键帧。</p>
</li>
<li>
<p>方法</p>
<p>：</p>
<ol>
<li>
<p>像素级差异</p>
<p>：</p>
<ul>
<li>
<p>计算相邻帧的像素差异（如灰度差值的均方误差MSE）。</p>
</li>
<li>
<p>如果差异超过阈值，则认为当前帧为关键帧。</p>
</li>
<li>
<p>示例代码：</p>
<p>python</p>
<p>收起自动换行运行</p>
<p>复制</p>
<p><code>import cv2 import numpy as np def frame_diff(prev_frame, curr_frame, thres=0.1):    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)    diff = np.mean((prev_gray - curr_gray) ** 2)    return diff &gt; thres</code></p>
</li>
</ul>
</li>
<li>
<p>特征级差异</p>
<p>：</p>
<ul>
<li>
<p>提取帧的特征（如HOG、SIFT或深度特征），比较特征向量距离。</p>
</li>
<li>
<p>使用预训练模型（如ResNet提取特征）计算余弦相似度或L2距离。</p>
</li>
<li>
<p>示例代码：</p>
<p>python</p>
<p>收起自动换行运行</p>
<p>复制</p>
<p><code>from torchvision.models import resnet18 import torch model = resnet18(pretrained=True).eval().cuda() def feature_diff(prev_frame, curr_frame, thres=0.5):    prev_feat = model(preprocess(prev_frame).cuda())    curr_feat = model(preprocess(curr_frame).cuda())    dist = torch.norm(prev_feat - curr_feat, p=2)    return dist &gt; thres</code></p>
</li>
</ul>
</li>
<li>
<p>光流分析</p>
<p>：</p>
<ul>
<li>
<p>使用光流算法（如Farneback光流）检测帧间运动变化，识别目标移动或场景变化。</p>
</li>
<li>
<p>示例代码：</p>
<p>python</p>
<p>收起自动换行运行</p>
<p>复制</p>
<p><code>def optical_flow_diff(prev_frame, curr_frame, thres=1.0):    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)    flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)    mag = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)    return np.mean(mag) &gt; thres</code></p>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h4 id="步骤2目标跟踪辅助抽帧"><a class="markdownIt-Anchor" href="#步骤2目标跟踪辅助抽帧"></a> 步骤2：目标跟踪辅助抽帧</h4>
<ul>
<li>
<p><strong>目的</strong>：利用目标跟踪算法（如DeepSORT、ByteTrack）减少对YOLO模型的调用频率，仅在目标状态变化时触发检测。</p>
</li>
<li>
<p>方法</p>
<p>：</p>
<ol>
<li>
<p>初始化检测</p>
<p>：</p>
<ul>
<li>在首帧或关键帧上运行YOLO模型，获取目标边界框。</li>
</ul>
</li>
<li>
<p>跟踪目标</p>
<p>：</p>
<ul>
<li>使用跟踪算法（如DeepSORT）预测目标在后续帧中的位置。</li>
<li>如果跟踪置信度下降（如目标丢失或位置偏移过大），触发YOLO检测。</li>
</ul>
</li>
<li>
<p>动态抽帧</p>
<p>：</p>
<ul>
<li>若跟踪结果稳定（目标位置变化小），跳过若干帧，仅进行跟踪。</li>
<li>若目标发生显著变化（如新目标进入、目标离开ROI），立即运行YOLO检测。</li>
</ul>
</li>
</ol>
</li>
<li>
<p>实现</p>
<p>：</p>
<ul>
<li>
<p>使用ByteTrack（轻量、高效）结合YOLOv5/v8：</p>
<p>python</p>
<p>收起自动换行运行</p>
<p>复制</p>
<p><code>from yolov5 import YOLOv5 from byte_tracker import BYTETracker model = YOLOv5('yolov5s.pt') tracker = BYTETracker(track_thresh=0.5, match_thresh=0.8) def process_frame(frame, prev_tracks):    # YOLO检测    results = model(frame)    dets = results.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2, conf, cls]    # 跟踪更新    tracks = tracker.update(dets)    # 判断是否需要再次检测    if len(tracks) != len(prev_tracks) or significant_change(tracks, prev_tracks):        return tracks, True  # 需要检测    return tracks, False  # 跳过检测</code></p>
</li>
</ul>
</li>
<li>
<p><strong>效果</strong>：减少50%-80%的YOLO调用，吞吐量提升2-5倍。</p>
</li>
</ul>
<h4 id="步骤3基于场景上下文的抽帧"><a class="markdownIt-Anchor" href="#步骤3基于场景上下文的抽帧"></a> 步骤3：基于场景上下文的抽帧</h4>
<ul>
<li>
<p><strong>目的</strong>：结合流水线场景的上下文（如传送带速度、目标出现频率），动态调整抽帧间隔。</p>
</li>
<li>
<p>方法</p>
<p>：</p>
<ol>
<li>
<p>ROI监控</p>
<p>：</p>
<ul>
<li>定义关键区域（如传送带区域），仅对ROI内发生变化的帧运行YOLO检测。</li>
<li>示例：结合前述ROI检测，仅处理ROI内像素变化显著的帧。</li>
</ul>
</li>
<li>
<p>时间间隔预测</p>
<p>：</p>
<ul>
<li>根据流水线速度（如传送带每秒移动1米）估算目标出现频率，动态调整抽帧间隔。</li>
<li>示例：若目标每2秒出现一次，抽帧间隔可设为1秒。</li>
</ul>
</li>
<li>
<p>异常检测触发</p>
<p>：</p>
<ul>
<li>使用轻量级异常检测（如像素变化、光流异常）触发关键帧检测。</li>
<li>示例：若光流幅度异常增大（如零件掉落），立即运行YOLO。</li>
</ul>
</li>
</ol>
</li>
<li>
<p>实现</p>
<p>：</p>
<p>python</p>
<p>收起自动换行运行</p>
<p>复制</p>
<p><code>def dynamic_frame_skip(frame, prev_frame, roi, speed=1.0, base_interval=5):    if frame_diff(frame, prev_frame, thres=0.1) or roi_change(frame, roi):        return True  # 处理当前帧    interval = int(base_interval / speed)  # 根据速度调整间隔    return False if frame_idx % interval == 0 else True</code></p>
</li>
</ul>
<h4 id="步骤4后处理优化"><a class="markdownIt-Anchor" href="#步骤4后处理优化"></a> 步骤4：后处理优化</h4>
<ul>
<li>
<p><strong>目的</strong>：结合前述后处理规则（如空间位置计数、ROI检测）过滤误报，确保关键事件不被漏检。</p>
</li>
<li>
<p>方法</p>
<p>：</p>
<ul>
<li>空间位置计数：对检测到的目标进行聚类，过滤异常框。</li>
<li>ROI检测：仅保留ROI内的检测结果。</li>
<li>时序平滑：利用多帧结果平滑目标位置和置信度，减少抖动。</li>
</ul>
</li>
<li>
<p><strong>效果</strong>：精度提升约5%-10%，召回率保持高水平。</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/06/05/2025%E5%B9%B46%E6%9C%885%E6%97%A5-%E5%90%8E%E5%A4%84%E7%90%86/" data-id="cmbpr6lmp000034v4495x3tvb" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年6月2日-pandas" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/06/02/2025%E5%B9%B46%E6%9C%882%E6%97%A5-pandas/" class="article-date">
  <time class="post-time" datetime="2025-06-02T06:52:17.000Z" itemprop="datePublished">
    <span class="post-month">6月</span><br/>
    <span class="post-day">02</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/06/02/2025%E5%B9%B46%E6%9C%882%E6%97%A5-pandas/">2025年6月2日 pandas</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><code>header=None</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/06/02/2025%E5%B9%B46%E6%9C%882%E6%97%A5-pandas/" data-id="cmbhxnxbk000igov4bu0o8y1r" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年6月2日-RAG" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/06/02/2025%E5%B9%B46%E6%9C%882%E6%97%A5-RAG/" class="article-date">
  <time class="post-time" datetime="2025-06-02T00:57:10.000Z" itemprop="datePublished">
    <span class="post-month">6月</span><br/>
    <span class="post-day">02</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/06/02/2025%E5%B9%B46%E6%9C%882%E6%97%A5-RAG/">2025年6月2日 RAG</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/infiniflow/ragflow">https://github.com/infiniflow/ragflow</a></p>
</blockquote>
<h1 id="llamaindex"><a class="markdownIt-Anchor" href="#llamaindex"></a> llamaindex</h1>
<h3 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/run-llama/llama_index.git</span><br><span class="line">pip intall poetry</span><br><span class="line">pip install -e llama-index-core</span><br><span class="line">pip install -e .</span><br></pre></td></tr></table></figure>
<p><strong>ollama</strong>本地</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install llama-index-llms-ollama llama-index-embeddings-huggingface</span><br></pre></td></tr></table></figure>
<h1 id="agentic-applications"><a class="markdownIt-Anchor" href="#agentic-applications"></a> Agentic Applications</h1>
<p>当 LLM 在应用程序中使用时，它通常用于做出决策、采取行动和/或与世界交互。这是<strong>代理应用程序</strong>的核心定义。</p>
<p>虽然代理应用程序的定义很宽泛，但定义代理应用程序的几个关键特征是：</p>
<ul>
<li><strong>LLM 增强</strong>：LLM 通过工具（即代码中的任意可调用函数）、内存和/或动态提示进行增强。</li>
<li><strong>Prompt Chaining</strong>：使用多个相互构建的 LLM 调用，一个 LLM 调用的输出用作下一个 LLM 调用的输入。</li>
<li><strong>路由</strong>：LLM 用于将应用程序路由到应用程序中的下一个适当步骤或状态。</li>
<li><strong>并行度</strong>：应用程序可以并行执行多个步骤或作。</li>
<li><strong>编排</strong>：LLM 的层次结构用于编排较低级别的作和 LLM。</li>
<li><strong>反射</strong>：LLM 用于反射和验证先前步骤或 LLM 调用的输出，可用于指导应用程序进入下一个适当的步骤或状态。</li>
</ul>
<h1 id="rag"><a class="markdownIt-Anchor" href="#rag"></a> RAG</h1>
<h2 id="1-介绍"><a class="markdownIt-Anchor" href="#1-介绍"></a> 1 介绍</h2>
<blockquote>
<h4 id="是什么rag"><a class="markdownIt-Anchor" href="#是什么rag"></a> 是什么RAG:</h4>
<p><strong>引入外部知识库</strong>，使模型在回答问题前先去“查资料”</p>
</blockquote>
<blockquote>
<h4 id="rag-的流程一般如下"><a class="markdownIt-Anchor" href="#rag-的流程一般如下"></a> RAG 的流程一般如下：</h4>
<ol>
<li><strong>用户提问</strong><br>
👉 输入一个自然语言问题，如：“介绍一下 RAG 是怎么工作的？”</li>
<li><strong>检索（Retrieval）</strong><br>
👉 使用向量搜索引擎（如 FAISS、Weaviate、Milvus）从外部知识库中检索相关文档段落。</li>
<li><strong>增强上下文（Augmentation）</strong><br>
👉 将这些检索到的文档作为“额外上下文”拼接到用户的问题后面。</li>
<li><strong>生成（Generation）</strong><br>
👉 使用语言模型（如 GPT、LLaMA）基于这个增强上下文进行回答。</li>
<li><strong>输出答案</strong><br>
👉 返回包含事实依据的自然语言回答。</li>
</ol>
</blockquote>
<blockquote>
<h4 id="技术组件工具链"><a class="markdownIt-Anchor" href="#技术组件工具链"></a> 🔧 技术组件（工具链）:</h4>
<ul>
<li><strong>Embedding 模型</strong>：将文本转为向量（如 <code>text-embedding-3-small</code>）</li>
<li><strong>向量数据库</strong>：存储与检索文档（如 FAISS、Chroma、Weaviate）</li>
<li><strong>语言模型</strong>：生成答案（如 OpenAI GPT, Mistral, Claude）</li>
<li><strong>框架支持</strong>：LangChain、LlamaIndex、Haystack 等</li>
</ul>
</blockquote>
<h2 id="2-rag_test"><a class="markdownIt-Anchor" href="#2-rag_test"></a> 2 RAG_Test</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">处理文档时出错: No files found in f:\.Work\test_llm\data</span><br><span class="line">使用这个.&quot;F:\data\paul_graham_essay.txt&quot;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>(llama_new) PS F:.Work\test_llm\llama_index&gt; &amp; D:/Pydata/anacondai/envs/llama_new/python.exe f:/.Work/test_llm/test_ollama_rag.py<br>
INFO:<strong>main</strong>:数据文件路径: F:\data\paul_graham_essay.txt<br>
INFO:<strong>main</strong>:数据目录: F:\data<br>
INFO:<strong>main</strong>:找到数据文件: F:\data\paul_graham_essay.txt<br>
INFO:<strong>main</strong>:数据目录中的文本文件列表: [‘F:\data\paul_graham_essay.txt’]<br>
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5<br>
INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: [‘query’, ‘text’]<br>
INFO:<strong>main</strong>:开始加载文档…<br>
INFO:<strong>main</strong>:成功加载 1 个文档<br>
INFO:<strong>main</strong>:开始创建索引…<br>
INFO:<strong>main</strong>:索引创建完成<br>
INFO:<strong>main</strong>:查询引擎创建完成<br>
INFO:<strong>main</strong>:开始运行查询…<br>
INFO:httpx:HTTP Request: POST <a target="_blank" rel="noopener" href="http://localhost:11434/api/chat">http://localhost:11434/api/chat</a> “HTTP/1.1 200 OK”<br>
INFO:httpx:HTTP Request: POST <a target="_blank" rel="noopener" href="http://localhost:11434/api/chat">http://localhost:11434/api/chat</a> “HTTP/1.1 200 OK”<br>
INFO:httpx:HTTP Request: POST <a target="_blank" rel="noopener" href="http://localhost:11434/api/chat">http://localhost:11434/api/chat</a> “HTTP/1.1 200 OK”</p>
<p>查询结果:<br>
The output from the tool calls will be used to format an answer to the original user question.</p>
<p>The author took classes in fundamental subjects like drawing, color, and design as part of a foundation program. They were counted as a transfer sophomore at RISD.</p>
<p>The result of 7 * 8 is 56.<br>
INFO:<strong>main</strong>:查询完成</p>
</blockquote>
<h1 id="reader"><a class="markdownIt-Anchor" href="#reader"></a> READER</h1>
<h2 id="1-介绍-2"><a class="markdownIt-Anchor" href="#1-介绍-2"></a> 1 介绍</h2>
<blockquote>
<h4 id="什么是-llamaindex-readers"><a class="markdownIt-Anchor" href="#什么是-llamaindex-readers"></a> 什么是 LlamaIndex Readers:</h4>
<p><strong>LlamaIndex Readers</strong> 是 LlamaIndex 框架中的数据加载模块，用于从各种数据源（如网页、文件、数据库、API 等）提取和加载数据，转化为可用于索引和检索的格式。它们是 LlamaIndex 数据管道的核心组件，支持 <strong>RAG（Retrieval-Augmented Generation）</strong> 系统通过外部数据增强语言模型的能力。</p>
</blockquote>
<blockquote>
<h4 id="llamaindex-readers-的流程一般如下"><a class="markdownIt-Anchor" href="#llamaindex-readers-的流程一般如下"></a> LlamaIndex Readers 的流程一般如下：</h4>
<ol>
<li><strong>数据源选择</strong> 👉 用户指定数据源（如 PDF 文件、网页、数据库、社交媒体等）。</li>
<li><strong>数据加载</strong> 👉 使用特定的 Reader（如 PDFReader、SimpleWebPageReader）从数据源提取原始内容（如文本、表格、元数据）。</li>
<li><strong>数据解析</strong> 👉 将提取的内容解析为结构化或非结构化数据，通常以 Document 对象的形式输出，包含文本和元数据。</li>
<li><strong>索引准备</strong> 👉 加载的数据可直接用于 LlamaIndex 的索引模块（如 VectorStoreIndex），将文本转为向量存储到向量数据库。</li>
<li><strong>检索与生成</strong> 👉 在 RAG 流程中，加载的数据作为知识库内容，供检索和生成答案使用。</li>
</ol>
</blockquote>
<blockquote>
<h4 id="技术组件工具链-2"><a class="markdownIt-Anchor" href="#技术组件工具链-2"></a> 🔧 技术组件（工具链）:</h4>
<ul>
<li><strong>数据源支持</strong>：支持多种数据源，包括文件（PDF、CSV、DOCX）、网页（HTML、RSS）、数据库（MongoDB、Snowflake）、社交媒体（Twitter、Slack）、云服务（Google Drive、S3）等。</li>
<li><strong>核心库</strong>：依赖 unstructured、BeautifulSoup、PyMuPDF 等库来解析不同格式的数据。</li>
<li><strong>集成框架</strong>：与 LlamaIndex 的索引和查询模块无缝集成，支持向量数据库（如 FAISS、Weaviate、Chroma）以及语言模型（OpenAI GPT、HuggingFace 模型等）。</li>
<li><strong>扩展性</strong>：提供大量社区贡献的 Reader（如 WikipediaReader、YoutubeTranscriptReader），支持特定场景的数据加载。</li>
</ul>
</blockquote>
<h2 id="2-reader_use"><a class="markdownIt-Anchor" href="#2-reader_use"></a> 2 Reader_use</h2>
<blockquote>
<ol>
<li>文件加载器
<ul>
<li><strong>PDFReader</strong> (ravi03071991): 解析 PDF 文件，提取文本和元数据，支持简单文本和复杂表格。</li>
<li><strong>DocxReader</strong> (thejessezhang, Verified): 解析 Microsoft Word (.docx) 文件，提取格式化文本。</li>
<li><strong>CSVReader</strong> (llama-index): 加载 CSV 文件，适合结构化数据处理。</li>
<li><strong>PyMuPDFReader</strong> (iamarunbrahma): 使用 PyMuPDF 高效解析 PDF，适合大规模文档处理。</li>
<li><strong>SmartPDFLoader</strong> (ansukla): 智能解析 PDF，提取复杂结构如表格和图像。</li>
</ul>
</li>
<li>网页加载器
<ul>
<li><strong>SimpleWebPageReader</strong> (thejessezhang, Verified): 加载网页内容，适合简单 HTML 页面。</li>
<li><strong>BeautifulSoupWebReader</strong> (thejessezhang, Verified): 使用 BeautifulSoup 解析网页，提取结构化内容。</li>
<li><strong>FireCrawlWebReader</strong> (llama-index): 通过 FireCrawl 工具高效抓取动态网页。</li>
<li><strong>TrafilaturaWebReader</strong> (na): 使用 Trafilatura 提取网页核心内容，去除无关元素。</li>
</ul>
</li>
<li>社交媒体与通信加载器
<ul>
<li><strong>TwitterTweetReader</strong> (ravi03071991): 加载 Twitter/X 推文及元数据。</li>
<li><strong>SlackReader</strong> (jerryjliu, Verified): 从 Slack 频道提取消息和文件。</li>
<li><strong>YoutubeTranscriptReader</strong> (ravi03071991): 提取 YouTube 视频字幕或转录内容。</li>
<li><strong>GmailReader</strong> (llama-index): 加载 Gmail 邮件内容及附件。</li>
</ul>
</li>
<li>数据库加载器
<ul>
<li><strong>SimpleMongoReader</strong> (jerryjliu, Verified): 从 MongoDB 数据库加载数据。</li>
<li><strong>QdrantReader</strong> (kacperlukawski): 从 Qdrant 向量数据库加载向量数据。</li>
<li><strong>DatabaseReader</strong> (kevinqz): 通用 SQL 数据库加载器。</li>
</ul>
</li>
<li>学术与研究加载器
<ul>
<li><strong>WikipediaReader</strong> (jerryjliu, Verified): 从维基百科加载文章内容。</li>
<li><strong>ArxivReader</strong> (thejessezhang, Verified): 从 arXiv 加载学术论文。</li>
<li><strong>SemanticScholarReader</strong> (shauryr): 从 Semantic Scholar 提取研究数据。</li>
</ul>
</li>
<li>云服务与生产力工具加载器
<ul>
<li><strong>NotionPageReader</strong> (jerryjliu, Verified): 从 Notion 页面和数据库加载内容。</li>
<li><strong>GoogleDocsReader</strong> (jerryjliu, Verified): 加载 Google Docs 文档。</li>
<li><strong>S3Reader</strong> (thejessezhang, Verified): 从 AWS S3 存储桶加载文件。</li>
</ul>
</li>
</ol>
</blockquote>
<blockquote>
<p>config_sentence_transformers.json: 100%|█████████████████████████████████████████████████████████████████████████████████████| 124/124 [00:00&lt;00:00, 18.8kB/s]<br>
<a target="_blank" rel="noopener" href="http://README.md">README.md</a>: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 30.4k/30.4k [00:00&lt;00:00, 2.40MB/s]<br>
sentence_bert_config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 52.0/52.0 [00:00&lt;00:00, 11.3kB/s]<br>
config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.00k/1.00k [00:00&lt;00:00, 332kB/s]<br>
pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1.30G/1.30G [00:16&lt;00:00, 77.5MB/s]<br>
tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 394/394 [00:00&lt;00:00, 69.1kB/s]<br>
vocab.txt: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 110k/110k [00:00&lt;00:00, 5.40MB/s]<br>
tokenizer.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 439k/439k [00:00&lt;00:00, 1.05MB/s]<br>
special_tokens_map.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:00&lt;00:00, 27.4kB/s]<br>
config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 191/191 [00:00&lt;00:00, 39.4kB/s]<br>
2025-06-04 08:28:35,589 - INFO - 2 prompts are loaded, with the keys: [‘query’, ‘text’]<br>
2025-06-04 08:28:35,593 - INFO - 开始加载文档…</p>
</blockquote>
<h1 id="embeddings"><a class="markdownIt-Anchor" href="#embeddings"></a> Embeddings</h1>
<h2 id="1-介绍-3"><a class="markdownIt-Anchor" href="#1-介绍-3"></a> 1 介绍</h2>
<blockquote>
<h4 id="什么是-llamaindex-embeddings"><a class="markdownIt-Anchor" href="#什么是-llamaindex-embeddings"></a> 什么是 LlamaIndex Embeddings:</h4>
<p><strong>LlamaIndex Embeddings</strong> 是 LlamaIndex 框架中的嵌入模型模块，用于将文本、图像或其他数据转换为高维向量表示（embeddings），以支持语义搜索、检索增强生成（RAG）等应用。这些嵌入模型将输入数据映射到向量空间，便于存储到向量数据库（如 FAISS、Weaviate）并进行相似性检索。</p>
</blockquote>
<blockquote>
<h4 id="llamaindex-embeddings-的流程一般如下"><a class="markdownIt-Anchor" href="#llamaindex-embeddings-的流程一般如下"></a> LlamaIndex Embeddings 的流程一般如下：</h4>
<ol>
<li><strong>输入数据</strong> 👉 用户提供文本、图像或其他数据（如文档、查询）。</li>
<li><strong>嵌入生成</strong> 👉 使用嵌入模型（如 OpenAIEmbedding、HuggingFaceEmbedding）将数据转换为固定维度的向量。</li>
<li><strong>存储向量</strong> 👉 将生成的向量存储到向量数据库，供后续检索使用。</li>
<li><strong>语义检索</strong> 👉 在 RAG 流程中，基于查询生成嵌入向量，与存储的向量进行相似性匹配，检索相关内容。</li>
<li><strong>生成答案</strong> 👉 结合检索到的内容，使用语言模型生成最终答案。</li>
</ol>
</blockquote>
<blockquote>
<h4 id="技术组件工具链-3"><a class="markdownIt-Anchor" href="#技术组件工具链-3"></a> 🔧 技术组件（工具链）:</h4>
<ul>
<li><strong>嵌入模型</strong>：支持多种嵌入模型，包括开源模型（如 HuggingFace、Ollama）、云服务（如 OpenAI、AWS Bedrock、Google）、专用模型（如 CLIP、MistralAI）。</li>
<li><strong>向量数据库</strong>：与 FAISS、Chroma、Weaviate 等向量存储集成，用于高效存储和检索嵌入向量。</li>
<li><strong>框架支持</strong>：无缝集成 LlamaIndex 的索引和查询模块，适用于 RAG、语义搜索和知识库构建。</li>
<li><strong>扩展性</strong>：支持多种云服务和本地模型，覆盖广泛的部署场景。</li>
</ul>
</blockquote>
<h2 id="2-主要-embeddings-分类与功能"><a class="markdownIt-Anchor" href="#2-主要-embeddings-分类与功能"></a> 2 <strong>主要 Embeddings 分类与功能</strong></h2>
<blockquote>
<p>以下是一些典型 LlamaIndex Embeddings 的介绍（基于您提供的列表）：</p>
<ol>
<li>
<p>云服务嵌入模型</p>
<ul>
<li><strong>BedrockEmbedding</strong> (llama-index): 使用 AWS Bedrock 平台的嵌入模型，支持多种预训练模型。<br>
下载量：309,490 | 1 个月前更新</li>
<li><strong>OpenAIEmbedding</strong> (llama-index): 基于 OpenAI 的嵌入模型（如 text-embedding-3-small），适合高质量文本嵌入。<br>
下载量：0 | 1 个月前更新</li>
</ul>
</li>
<li>
<p>开源与本地嵌入模型</p>
<ul>
<li><strong>HuggingFaceEmbedding</strong> (llama-index): 使用 HuggingFace 模型（如 sentence-transformers）生成嵌入，支持本地运行。<br>
下载量：0 | 25 天前更新</li>
<li><strong>OllamaEmbedding</strong> (llama-index): 基于 Ollama 框架的本地嵌入模型，适合隐私敏感场景。<br>
下载量：0 | 1 个月前更新</li>
<li><strong>ClipEmbedding</strong> (llama-index): 使用 CLIP 模型生成文本和图像的多模态嵌入。<br>
下载量：8,031 | 1 个月前更新</li>
<li><strong>FastEmbedEmbedding</strong> (llama-index): 轻量级嵌入模型，优化速度和资源占用。<br>
下载量：0 | 22 天前更新</li>
</ul>
</li>
<li>
<p><strong>适配器与增强嵌入模型</strong></p>
<ul>
<li>
<p><strong>AdapterEmbeddingModel</strong> (llama-index): 通用适配器模型，允许在预训练嵌入模型上添加微调层。<br>
下载量：8,925 | 1 个月前更新</p>
</li>
<li>
<p><strong>LinearAdapterEmbeddingModel</strong> (llama-index): 使用线性适配器增强嵌入模型，适合特定任务优化。</p>
<p>下载量：8,925 | 1 个月前更新</p>
</li>
</ul>
</li>
<li>
<p>特定平台与服务嵌入模型</p>
<ul>
<li><strong>DatabricksEmbedding</strong> (enrico-stauss): 基于 Databricks 平台的嵌入模型，适合大数据环境。<br>
下载量：2,679 | 1 个月前更新</li>
</ul>
</li>
<li>
<p>其他嵌入模型</p>
<ul>
<li><strong>DashScopeEmbedding</strong> (liuyhwangyh): 基于阿里云 DashScope 的嵌入模型，适合中文场景。<br>
下载量：0 | 1 个月前更新</li>
</ul>
</li>
</ol>
</blockquote>
<h3 id="21-适配器与增强adapterembeddingmodel-linearadapterembeddingmodel介绍"><a class="markdownIt-Anchor" href="#21-适配器与增强adapterembeddingmodel-linearadapterembeddingmodel介绍"></a> 2.1 适配器与增强（AdapterEmbeddingModel &amp; LinearAdapterEmbeddingModel）介绍</h3>
<blockquote>
<h4 id="什么是适配器与增强"><a class="markdownIt-Anchor" href="#什么是适配器与增强"></a> 什么是适配器与增强:</h4>
<p>在 LlamaIndex 框架中，<strong>适配器与增强</strong>（Adapter Embedding Models）是指通过在预训练嵌入模型（如 HuggingFace 的 sentence-transformers 或 OpenAI 的 text-embedding-3-small）的基础上添加轻量级适配器层（Adapter Layers）来优化或定制嵌入生成的技术。这些适配器通过微调或增强现有模型，使其更适合特定任务或领域，而无需从头训练整个模型。<strong>AdapterEmbeddingModel</strong> 和 <strong>LinearAdapterEmbeddingModel</strong> 是 LlamaIndex 提供的两种适配器嵌入模型，用于增强嵌入向量的性能。</p>
</blockquote>
<blockquote>
<h4 id="适配器与增强的流程一般如下"><a class="markdownIt-Anchor" href="#适配器与增强的流程一般如下"></a> 适配器与增强的流程一般如下：</h4>
<ol>
<li><strong>选择基础嵌入模型</strong> 👉 选用预训练嵌入模型（如 HuggingFaceEmbedding 或 OpenAIEmbedding）作为基础。</li>
<li><strong>添加适配器层</strong> 👉 在基础模型的输出层后添加轻量级神经网络层（如线性层或其他结构），用于调整嵌入向量。</li>
<li><strong>微调适配器</strong> 👉 对适配器层进行微调，优化特定任务（如领域特定语义搜索、文本分类），保持基础模型参数不变。</li>
<li><strong>生成嵌入</strong> 👉 使用增强后的模型将文本或其他数据转换为向量，适用于 RAG、语义检索等场景。</li>
<li><strong>存储与检索</strong> 👉 将生成的嵌入向量存储到向量数据库（如 FAISS、Weaviate），用于后续查询和生成。</li>
</ol>
</blockquote>
<blockquote>
<h4 id="技术组件工具链-4"><a class="markdownIt-Anchor" href="#技术组件工具链-4"></a> 🔧 技术组件（工具链）:</h4>
<ul>
<li><strong>基础嵌入模型</strong>：依赖现有嵌入模型（如 HuggingFaceEmbedding、OpenAIEmbedding）提供初始向量表示。</li>
<li><strong>适配器层</strong>：轻量级神经网络模块（如线性层、Transformer 层），用于调整嵌入向量。</li>
<li><strong>向量数据库</strong>：与 FAISS、Chroma、Weaviate 等集成，存储增强后的嵌入向量。</li>
<li><strong>框架支持</strong>：LlamaIndex 提供统一接口，简化适配器模型的集成和使用。</li>
</ul>
</blockquote>
<p><strong>实现</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.embeddings.adapter <span class="keyword">import</span> AdapterEmbeddingModel</span><br><span class="line">base_model = HuggingFaceEmbedding(model_name=<span class="string">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span>)</span><br><span class="line">adapter_model = AdapterEmbeddingModel(base_model, adapter_config=&#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;linear&quot;</span>&#125;)</span><br><span class="line">embeddings = adapter_model.get_text_embedding(<span class="string">&quot;Hello, world!&quot;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="llamaindex-indexes"><a class="markdownIt-Anchor" href="#llamaindex-indexes"></a> LlamaIndex Indexes</h1>
<h2 id="1-介绍-4"><a class="markdownIt-Anchor" href="#1-介绍-4"></a> 1 介绍</h2>
<blockquote>
<h4 id="什么是-llamaindex-indexes"><a class="markdownIt-Anchor" href="#什么是-llamaindex-indexes"></a> 什么是 LlamaIndex Indexes:</h4>
<p><strong>LlamaIndex Indexes</strong> 是 LlamaIndex 框架中的核心模块，用于组织、存储和检索数据，以便在 <strong>RAG（Retrieval-Augmented Generation）</strong> 或其他数据驱动任务中高效访问外部知识。索引将原始数据（如文档、文本）转换为结构化表示（通常是向量或关键词形式），支持快速检索和语义搜索。<strong>VectorStoreIndex</strong> 是其中最常用的索引类型，基于向量嵌入存储数据，广泛用于语义相似性检索。</p>
</blockquote>
<blockquote>
<h4 id="llamaindex-indexes-的流程一般如下"><a class="markdownIt-Anchor" href="#llamaindex-indexes-的流程一般如下"></a> LlamaIndex Indexes 的流程一般如下：</h4>
<ol>
<li><strong>数据加载</strong> 👉 使用 LlamaIndex Readers（如 PDFReader、SimpleWebPageReader）加载原始数据（如文档、网页）。</li>
<li><strong>数据预处理</strong> 👉 将数据分块（chunking）、提取元数据，并使用嵌入模型（如 OpenAIEmbedding）生成向量表示。</li>
<li><strong>索引构建</strong> 👉 将向量或关键词存储到索引结构（如向量数据库、关键词表），支持高效查询。</li>
<li><strong>查询执行</strong> 👉 用户输入查询，索引将查询转为嵌入向量，检索最相关的文档或数据片段。</li>
<li><strong>上下文提供</strong> 👉 检索结果作为上下文，供语言模型（LLM）生成答案或进一步处理。</li>
</ol>
</blockquote>
<blockquote>
<h4 id="技术组件工具链-5"><a class="markdownIt-Anchor" href="#技术组件工具链-5"></a> 🔧 技术组件（工具链）:</h4>
<ul>
<li><strong>嵌入模型</strong>：将文本转为向量（如 HuggingFaceEmbedding、OpenAIEmbedding）。</li>
<li><strong>向量数据库</strong>：存储嵌入向量（如 FAISS、Weaviate、Pinecone）。</li>
<li><strong>存储后端</strong>：支持多种存储方式，包括本地文件、云服务（如 AWS、Google）、数据库（如 Postgres）。</li>
<li><strong>框架支持</strong>：与 LlamaIndex 的 Readers、Agents 和 LLMs 无缝集成，构建 RAG 管道。</li>
</ul>
</blockquote>
<h1 id="llamaindex-retrievers检索器"><a class="markdownIt-Anchor" href="#llamaindex-retrievers检索器"></a> LlamaIndex Retrievers/检索器</h1>
<h2 id="1-介绍-5"><a class="markdownIt-Anchor" href="#1-介绍-5"></a> 1 介绍</h2>
<blockquote>
<h4 id="什么是-llamaindex-retrievers"><a class="markdownIt-Anchor" href="#什么是-llamaindex-retrievers"></a> 什么是 LlamaIndex Retrievers:</h4>
<p><strong>LlamaIndex Retrievers</strong> 是 LlamaIndex 框架中的检索模块，用于从索引（如 VectorStoreIndex）或外部数据源（如数据库、知识库）中提取与用户查询最相关的文档或数据片段。它们是 <strong>RAG（Retrieval-Augmented Generation）</strong> 流程中的核心组件，通过语义搜索、关键词匹配或其他检索策略，提供高质量的外部上下文，供语言模型（LLM）生成答案。Retrievers 通常与索引和嵌入模型（如 OpenAIEmbedding）配合使用，以实现高效的语义或关键词检索。</p>
</blockquote>
<blockquote>
<h4 id="llamaindex-retrievers-的流程一般如下"><a class="markdownIt-Anchor" href="#llamaindex-retrievers-的流程一般如下"></a> LlamaIndex Retrievers 的流程一般如下：</h4>
<ol>
<li><strong>接收用户查询</strong> 👉 用户输入自然语言查询（如“什么是 AI？”）。</li>
<li><strong>查询转换</strong> 👉 将查询转为嵌入向量（语义检索）或关键词（关键词检索），具体取决于 Retriever 类型。</li>
<li><strong>检索数据</strong> 👉 从索引或外部数据源（如向量数据库、知识库）中查找最相关的文档或数据片段。</li>
<li><strong>后处理（可选）</strong> 👉 结合 Post Processors（如 CohereRerank）对检索结果进行排序、过滤或优化。</li>
<li><strong>返回结果</strong> 👉 输出相关文档或数据片段，作为上下文供 LLM 生成答案。</li>
</ol>
</blockquote>
<blockquote>
<h4 id="技术组件工具链-6"><a class="markdownIt-Anchor" href="#技术组件工具链-6"></a> 🔧 技术组件（工具链）:</h4>
<ul>
<li><strong>检索策略</strong>：支持语义检索（基于嵌入向量）、关键词检索（如 BM25）、混合检索等。</li>
<li><strong>嵌入模型</strong>：用于生成查询和文档的向量表示（如 HuggingFaceEmbedding）。</li>
<li><strong>索引支持</strong>：与 LlamaIndex 的索引模块（如 VectorStoreIndex）或外部数据源（如 AWS Kendra）集成。</li>
<li><strong>框架支持</strong>：与 LlamaIndex 的 Agents、Post Processors 和 LLMs 无缝集成，构建 RAG 管道。</li>
</ul>
</blockquote>
<hr>
<h2 id="2-具体-retrievers-介绍"><a class="markdownIt-Anchor" href="#2-具体-retrievers-介绍"></a> 2 <strong>具体 Retrievers 介绍</strong></h2>
<blockquote>
<ol>
<li>BM25Retriever (llama-index)
<ul>
<li><strong>功能</strong>：基于 BM25 算法的关键词检索器，优化文本的关键词匹配。</li>
<li>特点：
<ul>
<li>使用经典信息检索算法 BM25，基于词频和文档长度计算相关性。</li>
<li>不依赖嵌入模型，适合轻量级、快速的关键词检索。</li>
</ul>
</li>
</ul>
</li>
<li>PathwayRetriever (llama-index)
<ul>
<li><strong>功能</strong>：基于 Pathway 框架的检索器，优化语义搜索和复杂查询处理。</li>
<li>特点：
<ul>
<li>支持语义检索，结合嵌入模型和向量索引。</li>
<li>适合处理复杂查询和多模态数据。</li>
</ul>
</li>
</ul>
</li>
</ol>
</blockquote>
<h2 id="3-分解复杂查询"><a class="markdownIt-Anchor" href="#3-分解复杂查询"></a> 3 分解复杂查询</h2>
<h1 id="reranking"><a class="markdownIt-Anchor" href="#reranking"></a> Reranking</h1>
<h2 id="1-介绍-6"><a class="markdownIt-Anchor" href="#1-介绍-6"></a> 1 介绍</h2>
<blockquote>
<h4 id="什么是-reranking"><a class="markdownIt-Anchor" href="#什么是-reranking"></a> 什么是 Reranking:</h4>
<p><strong>Reranking</strong>（重新排序）是 RAG（Retrieval-Augmented Generation）流程中的一种后处理技术，用于优化初始检索结果的相关性。它通过`<strong>对检索到的文档或数据片段重新评分和排序</strong>，确保返回的结果更符合用户查询的语义或上下文需求。Reranking 通常在初始检索（Retrieval）阶段之后，通过更精细的模型（如嵌入模型或 LLM）或算法（如 ColBERT、Cohere）来提升结果质量。</p>
</blockquote>
<blockquote>
<h4 id="reranking-的流程一般如下"><a class="markdownIt-Anchor" href="#reranking-的流程一般如下"></a> Reranking 的流程一般如下：</h4>
<ol>
<li><strong>初始检索</strong> 👉 使用 Retriever（如 BM25Retriever 或 VectorStoreIndex）从索引或数据源中获取一组候选文档（通常 top-k 个）。</li>
<li><strong>重新评分</strong> 👉 应用 reranking 模型（如 CohereRerank、ColbertRerank）或算法，基于查询与文档的语义相关性重新计算分数。</li>
<li><strong>排序优化</strong> 👉 根据新分数对文档重新排序，优先保留最相关的文档。</li>
<li><strong>过滤（可选）</strong> 👉 移除低相关性文档或限制返回数量（如 top-5）。</li>
<li><strong>返回结果</strong> 👉 输出优化后的文档列表，供 RAG 的生成阶段或直接使用。</li>
</ol>
</blockquote>
<blockquote>
<h4 id="技术组件工具链-7"><a class="markdownIt-Anchor" href="#技术组件工具链-7"></a> 🔧 技术组件（工具链）:</h4>
<ul>
<li><strong>Reranking 模型</strong>：包括嵌入模型（如 SentenceTransformerRerank）、专用 reranking 模型（如 ColbertRerank）、LLM-based reranking（如 RankGPTRerank）或云服务（如 CohereRerank）。</li>
<li><strong>初始检索</strong>：依赖 LlamaIndex Retrievers（如 BM25Retriever、PathwayRetriever）提供候选文档。</li>
<li><strong>索引支持</strong>：与 LlamaIndex 的索引（如 VectorStoreIndex）和嵌入模型（如 OpenAIEmbedding）集成。</li>
<li><strong>框架支持</strong>：作为 LlamaIndex Post Processors 的一部分，与查询引擎和 Agents 无缝协作。</li>
</ul>
</blockquote>
<h1 id="storage"><a class="markdownIt-Anchor" href="#storage"></a> Storage</h1>
<h1 id="llamaindex-agents"><a class="markdownIt-Anchor" href="#llamaindex-agents"></a> LlamaIndex Agents</h1>
<h2 id="1-介绍-7"><a class="markdownIt-Anchor" href="#1-介绍-7"></a> 1 介绍</h2>
<blockquote>
<h4 id="什么是-llamaindex-agents"><a class="markdownIt-Anchor" href="#什么是-llamaindex-agents"></a> 什么是 LlamaIndex Agents:</h4>
<p><strong>LlamaIndex Agents</strong> 是 LlamaIndex 框架中的智能代理模块，设计用于结合语言模型、工具和外部数据源（如知识库、API）来执行复杂任务。这些代理能够自主推理、调用工具、检索数据并生成响应，广泛应用于 <strong>RAG（Retrieval-Augmented Generation）</strong>、任务自动化和多步骤推理场景。它们通过与 LlamaIndex 的索引和嵌入模块集成，提供智能化的数据处理和交互能力。</p>
</blockquote>
<blockquote>
<h4 id="llamaindex-agents-的流程一般如下"><a class="markdownIt-Anchor" href="#llamaindex-agents-的流程一般如下"></a> LlamaIndex Agents 的流程一般如下：</h4>
<ol>
<li><strong>接收任务</strong> 👉 用户输入任务或查询（如“分析文档并回答问题”或“调用 API 获取数据”）。</li>
<li><strong>任务分解与规划</strong> 👉 代理根据任务分解为子步骤，可能涉及检索数据、调用工具或推理。</li>
<li><strong>数据检索</strong> 👉 使用 LlamaIndex 的索引模块（如 VectorStoreIndex）从知识库检索相关数据。</li>
<li><strong>工具调用</strong> 👉 调用外部工具（如 API、计算函数）或内部工具（如数据查询）以补充信息。</li>
<li><strong>生成响应</strong> 👉 结合检索数据和工具输出，使用语言模型生成最终答案。</li>
</ol>
</blockquote>
<blockquote>
<h4 id="技术组件工具链-8"><a class="markdownIt-Anchor" href="#技术组件工具链-8"></a> 🔧 技术组件（工具链）:</h4>
<ul>
<li><strong>语言模型</strong>：支持 OpenAI、Mistral、HuggingFace 等模型，用于推理和生成。</li>
<li><strong>索引与嵌入</strong>：与 LlamaIndex 的嵌入模型（如 OpenAIEmbedding）和向量数据库（如 FAISS、Weaviate）集成。</li>
<li><strong>工具集成</strong>：支持外部工具（如 API、计算函数）和内部工具（如查询引擎）。</li>
<li><strong>框架支持</strong>：LlamaIndex 提供统一接口，简化代理的配置和使用。</li>
</ul>
</blockquote>
<p>2</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">index = VectorStoreIndex.from_documents(</span><br><span class="line">    documents,</span><br><span class="line">    embed_model=Settings.embed_model,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="2-详细流程"><a class="markdownIt-Anchor" href="#2-详细流程"></a> 2 详细流程</h2>
<p>LlamaIndex Agents 的运作可以分为以下核心步骤，适用于大多数代理（如 OpenAIAgent、ContextRetrieverOpenAIAgent 等）：</p>
<p><strong>接收用户输入</strong></p>
<ul>
<li>用户通过自然语言提出任务或查询（如“分析文档并回答问题”或“调用 API 获取天气数据”）。</li>
<li>代理解析输入，识别任务目标和所需资源。</li>
</ul>
<p><strong>任务分解与规划</strong></p>
<ul>
<li>代理分析任务复杂度，决定是否需要分解为子任务。</li>
<li>使用语言模型（LLM）进行推理，生成执行计划（如“先检索文档，再调用工具”）。</li>
<li>高级代理（如 LLMCompilerAgentWorker）可能使用编译式推理或抽象链（Chain-of-Abstraction）优化规划。</li>
</ul>
<p><strong>数据检索（Retrieval）</strong></p>
<ul>
<li>若任务需要外部知识，代理调用 LlamaIndex 的索引模块（如 VectorStoreIndex）。</li>
<li>将用户查询转为嵌入向量（使用嵌入模型，如 OpenAIEmbedding）。</li>
<li>在向量数据库（如 FAISS、Weaviate）中检索与查询语义最相关的文档或数据片段。</li>
</ul>
<p><strong>工具调用（Tool Interaction）</strong></p>
<ul>
<li>代理根据任务需求调用外部工具（如 API、计算函数）或内部工具（如查询引擎）。</li>
<li>工具调用可能涉及动态函数选择（如 FnRetrieverOpenAIAgent）或多步骤工具交互（如 ToolInteractiveReflectionAgentWorker）。</li>
<li>工具输出作为额外上下文，补充检索到的数据。</li>
</ul>
<p><strong>推理与上下文增强（Augmentation）</strong></p>
<ul>
<li>代理整合检索到的文档、工具输出和用户输入，形成增强上下文。</li>
<li>高级代理（如 IntrospectiveAgentWorker、SelfReflectionAgentWorker）可能进行自我反思，评估上下文质量并优化推理。</li>
</ul>
<p><strong>生成响应（Generation）</strong></p>
<ul>
<li>使用语言模型（LLM，如 OpenAI GPT-4、Mistral）基于增强上下文生成最终答案。</li>
<li>输出可以是自然语言回答、结构化数据或其他形式，视任务而定。</li>
</ul>
<p><strong>反馈与迭代（可选）</strong></p>
<ul>
<li>部分代理（如 SelfReflectionAgentWorker）会对输出进行反思，检查是否需要重新检索或调整工具调用。</li>
<li>迭代优化直到满足任务要求或达到预设条件。</li>
</ul>
<blockquote>
<h3 id="运作机制"><a class="markdownIt-Anchor" href="#运作机制"></a> <strong>运作机制</strong></h3>
<ul>
<li>核心组件：
<ul>
<li><strong>语言模型（LLM）</strong>：负责任务规划、推理和生成（如 OpenAI GPT、HuggingFace 模型）。</li>
<li><strong>嵌入模型</strong>：将文本转为向量，用于检索（如 HuggingFaceEmbedding）。</li>
<li><strong>索引模块</strong>：管理知识库，基于向量数据库检索数据（如 VectorStoreIndex）。</li>
<li><strong>工具模块</strong>：支持外部 API、函数或内部查询引擎，扩展代理能力。</li>
</ul>
</li>
<li>工作原理：
<ul>
<li>代理通过 LLM 理解用户意图，结合索引模块检索相关数据，使用工具补充信息。</li>
<li>代理动态决定执行路径，可能循环调用检索和工具，直到任务完成。</li>
<li>反射机制（reflection）或编译式推理（如 LLMCompilerAgentWorker）优化复杂任务的执行效率。</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Any</span></span><br><span class="line"><span class="keyword">from</span> llama_index.core <span class="keyword">import</span> VectorStoreIndex, FunctionTool</span><br><span class="line"><span class="keyword">from</span> llama_index.core.llms <span class="keyword">import</span> LLM</span><br><span class="line"><span class="keyword">from</span> llama_index.core.embeddings <span class="keyword">import</span> BaseEmbedding</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LlamaIndexAgent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, llm: LLM, index: VectorStoreIndex, tools: <span class="type">List</span>[FunctionTool], embedding_model: BaseEmbedding</span>):</span><br><span class="line">        self.llm = llm  <span class="comment"># 语言模型</span></span><br><span class="line">        self.index = index  <span class="comment"># 向量索引</span></span><br><span class="line">        self.tools = tools  <span class="comment"># 工具列表</span></span><br><span class="line">        self.embedding_model = embedding_model  <span class="comment"># 嵌入模型</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">self, user_query: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># 1. 解析用户输入</span></span><br><span class="line">        query = user_query.strip()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 任务分解与规划</span></span><br><span class="line">        plan = self.llm.generate_plan(query)  <span class="comment"># 使用 LLM 推理生成执行计划</span></span><br><span class="line">        sub_tasks = plan.get_sub_tasks()  <span class="comment"># 假设计划分解为子任务</span></span><br><span class="line"></span><br><span class="line">        context = []</span><br><span class="line">        <span class="keyword">for</span> task <span class="keyword">in</span> sub_tasks:</span><br><span class="line">            <span class="comment"># 3. 数据检索</span></span><br><span class="line">            <span class="keyword">if</span> task.requires_retrieval:</span><br><span class="line">                query_embedding = self.embedding_model.get_text_embedding(task.query)</span><br><span class="line">                retrieved_docs = self.index.query(query_embedding, top_k=<span class="number">5</span>)</span><br><span class="line">                context.extend(retrieved_docs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4. 工具调用</span></span><br><span class="line">            <span class="keyword">if</span> task.requires_tool:</span><br><span class="line">                tool = self.select_tool(task)  <span class="comment"># 动态选择工具</span></span><br><span class="line">                tool_output = tool.execute(task.tool_input)</span><br><span class="line">                context.append(tool_output)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. 上下文增强</span></span><br><span class="line">        augmented_context = self.combine_context(query, context)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 6. 反思（可选）</span></span><br><span class="line">        <span class="keyword">if</span> self.has_reflection:</span><br><span class="line">            augmented_context = self.reflect_and_refine(augmented_context)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 7. 生成响应</span></span><br><span class="line">        response = self.llm.generate_response(augmented_context)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 8. 反馈与迭代（可选）</span></span><br><span class="line">        <span class="keyword">if</span> self.needs_iteration(response):</span><br><span class="line">            <span class="keyword">return</span> self.chat(query)  <span class="comment"># 重新执行以优化结果</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_tool</span>(<span class="params">self, task: <span class="type">Dict</span></span>) -&gt; FunctionTool:</span><br><span class="line">        <span class="comment"># 动态选择适合任务的工具</span></span><br><span class="line">        <span class="keyword">for</span> tool <span class="keyword">in</span> self.tools:</span><br><span class="line">            <span class="keyword">if</span> tool.name == task.tool_name:</span><br><span class="line">                <span class="keyword">return</span> tool</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;No suitable tool found&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combine_context</span>(<span class="params">self, query: <span class="built_in">str</span>, context: <span class="type">List</span>[<span class="type">Any</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># 合并查询和上下文</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Query: <span class="subst">&#123;query&#125;</span>\nContext: <span class="subst">&#123;<span class="string">&#x27;&#x27;</span>.join(<span class="built_in">str</span>(c) <span class="keyword">for</span> c <span class="keyword">in</span> context)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reflect_and_refine</span>(<span class="params">self, context: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># 反思并优化上下文（适用于 IntrospectiveAgentWorker 等）</span></span><br><span class="line">        reflection = self.llm.evaluate_context(context)</span><br><span class="line">        <span class="keyword">return</span> reflection.refined_context</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">needs_iteration</span>(<span class="params">self, response: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment"># 判断是否需要迭代优化</span></span><br><span class="line">        <span class="keyword">return</span> self.llm.evaluate_response(response).needs_refinement</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例使用</span></span><br><span class="line">llm = OpenAI(model=<span class="string">&quot;gpt-4&quot;</span>)</span><br><span class="line">index = VectorStoreIndex.from_documents(documents)</span><br><span class="line">tools = [FunctionTool.from_defaults(fn=<span class="keyword">lambda</span> x: x * <span class="number">2</span>, name=<span class="string">&quot;double&quot;</span>)]</span><br><span class="line">embedding_model = OpenAIEmbedding(model=<span class="string">&quot;text-embedding-3-small&quot;</span>)</span><br><span class="line">agent = LlamaIndexAgent(llm, index, tools, embedding_model)</span><br><span class="line"></span><br><span class="line">response = agent.chat(<span class="string">&quot;Double the number 42 and summarize this document.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="3-主要-agents-介绍"><a class="markdownIt-Anchor" href="#3-主要-agents-介绍"></a> 3 <strong>主要 Agents 介绍</strong></h2>
<blockquote>
<ol>
<li><strong>ContextRetrieverOpenAIAgent</strong>
<ul>
<li><strong>功能</strong>：基于 OpenAI 语言模型的代理，结合上下文检索功能，优化 RAG 场景下的数据查询和响应生成。</li>
<li><strong>特点</strong>：
<ul>
<li>利用 OpenAI 模型进行推理，结合 LlamaIndex 的索引模块检索上下文。</li>
<li>适合需要强语义理解的任务，如问答、对话系统。</li>
<li>强调上下文相关性，确保检索到的信息高度匹配用户查询。</li>
</ul>
</li>
</ul>
</li>
<li><strong>FnRetrieverOpenAIAgent</strong>
<ul>
<li><strong>功能</strong>：基于 OpenAI 模型的代理，专注于通过函数调用（Function Calling）增强数据检索能力。</li>
<li><strong>特点</strong>：
<ul>
<li>支持动态函数调用，允许代理根据任务选择合适的检索工具或 API。</li>
<li>结合 LlamaIndex 的检索模块，优化复杂查询的处理。</li>
<li>适合需要结合外部工具和数据源的任务。</li>
</ul>
</li>
</ul>
</li>
<li><strong>LATSAgentWorker</strong>
<ul>
<li><strong>功能</strong>：基于 LATS（Learning-Augmented Task Solver）框架的代理，专注于任务分解和多步骤推理。</li>
<li><strong>特点</strong>：
<ul>
<li>通过学习增强任务解决能力，自动规划和执行复杂任务。</li>
<li>结合 LlamaIndex 的检索和工具调用功能，处理多源数据。</li>
<li>适合需要分步推理和动态规划的任务。</li>
</ul>
</li>
</ul>
</li>
</ol>
</blockquote>
<h1 id="其他处理"><a class="markdownIt-Anchor" href="#其他处理"></a> 其他处理</h1>
<h3 id="output-parsers"><a class="markdownIt-Anchor" href="#output-parsers"></a> Output Parsers</h3>
<blockquote>
<p>解析语言模型（LLM）的原始输出，将其从自由文本转换为结构化数据（如 JSON、列表、表格）或特定格式</p>
</blockquote>
<h3 id="post-processors"><a class="markdownIt-Anchor" href="#post-processors"></a> Post Processors</h3>
<blockquote>
<p>接收输入 👉 从索引（如 VectorStoreIndex）获取检索到的文档或从 LLM 获取生成结果。</p>
</blockquote>
<h3 id="agent-tools"><a class="markdownIt-Anchor" href="#agent-tools"></a> Agent Tools</h3>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/06/02/2025%E5%B9%B46%E6%9C%882%E6%97%A5-RAG/" data-id="cmbhxnxbe000ggov4ftob7p9q" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年5月27日-opencv汇总" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/05/27/2025%E5%B9%B45%E6%9C%8827%E6%97%A5-opencv%E6%B1%87%E6%80%BB/" class="article-date">
  <time class="post-time" datetime="2025-05-27T06:08:24.000Z" itemprop="datePublished">
    <span class="post-month">5月</span><br/>
    <span class="post-day">27</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/27/2025%E5%B9%B45%E6%9C%8827%E6%97%A5-opencv%E6%B1%87%E6%80%BB/">2025年5月27日 opencv汇总</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>✅</p>
<p>CAP_V4L2和cv2.CAP_FFMPEG</p>
<h1 id="opencv-图像读写与显示"><a class="markdownIt-Anchor" href="#opencv-图像读写与显示"></a> OpenCV ==图像读写与显示</h1>
<p>1️⃣ <strong>cv2.imread(filename[, flags])</strong> 用于读取图像文件。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image = cv2.imread(<span class="string">&#x27;example.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 以灰度模式读取图像</span></span><br><span class="line">gray_image = cv2.imread(<span class="string">&#x27;example.jpg&#x27;</span>, cv2.IMREAD_GRAYSCALE)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.imshow(winname, mat)</strong> 显示图像。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 显示图像</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;Image Window&#x27;</span>, image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)  <span class="comment"># 等待按键</span></span><br><span class="line">cv2.destroyAllWindows()  <span class="comment"># 关闭所有窗口</span></span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.imwrite(filename, img[, params])</strong> 保存图像到文件。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 保存图像</span></span><br><span class="line">cv2.imwrite(<span class="string">&#x27;output.jpg&#x27;</span>, image)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-色彩空间转换"><a class="markdownIt-Anchor" href="#opencv-色彩空间转换"></a> OpenCV ==色彩空间转换</h1>
<p>1️⃣ <strong>cv2.cvtColor(src, code[, dst[, dstCn]])</strong> ✅</p>
<p>转换色彩空间。</p>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 将BGR图像转换为灰度图像</span></span><br><span class="line">gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 将BGR图像转换为HSV图像</span></span><br><span class="line">hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.split(m[, mv])</strong> 分离图像通道。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 分离BGR通道</span></span><br><span class="line">b, g, r = cv2.split(image)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.merge(mv[, dst[, dstCn]])</strong> 合并图像通道。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 合并通道</span></span><br><span class="line">merged_image = cv2.merge([b, g, r])</span><br></pre></td></tr></table></figure>
<h1 id="opencv-图像增强与变换"><a class="markdownIt-Anchor" href="#opencv-图像增强与变换"></a> OpenCV ==图像增强与变换</h1>
<p>1️⃣ <strong>cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])</strong> 改变图像大小。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 改变图像大小</span></span><br><span class="line">resized_image = cv2.resize(image, (<span class="number">300</span>, <span class="number">300</span>))</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.flip(src, flipCode[, dst])</strong> 翻转图像。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 水平翻转图像</span></span><br><span class="line">flipped_image = cv2.flip(image, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])</strong> 仿射变换。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 定义旋转矩阵</span></span><br><span class="line">theta = <span class="number">45</span>  <span class="comment"># 旋转角度</span></span><br><span class="line">M = cv2.getRotationMatrix2D((image.shape[<span class="number">1</span>] // <span class="number">2</span>, image.shape[<span class="number">0</span>] // <span class="number">2</span>), theta, <span class="number">1.0</span>)</span><br><span class="line">rotated_image = cv2.warpAffine(image, M, (image.shape[<span class="number">1</span>], image.shape[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<h1 id="opencv-滤波与去噪"><a class="markdownIt-Anchor" href="#opencv-滤波与去噪"></a> OpenCV ==滤波与去噪</h1>
<p>1️⃣ <strong>cv2.GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]])</strong> 高斯滤波。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 高斯滤波</span></span><br><span class="line">blurred_image = cv2.GaussianBlur(image, (<span class="number">15</span>, <span class="number">15</span>), <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.medianBlur(src, ksize[, dst])</strong> 中值滤波。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 中值滤波</span></span><br><span class="line">median_blurred_image = cv2.medianBlur(image, <span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]])</strong> 双边滤波。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 双边滤波</span></span><br><span class="line">bilateral_filtered_image = cv2.bilateralFilter(image, <span class="number">15</span>, <span class="number">75</span>, <span class="number">75</span>)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-边缘检测"><a class="markdownIt-Anchor" href="#opencv-边缘检测"></a> OpenCV ==边缘检测</h1>
<p>1️⃣ <strong>cv2.Sobel(src, ddepth, dx, dy[, dst[, ksize[, scale[, delta[, borderType]]]]])</strong> 索贝尔边缘检测。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 索贝尔边缘检测</span></span><br><span class="line">sobel_x = cv2.Sobel(image, cv2.CV_64F, <span class="number">1</span>, <span class="number">0</span>, ksize=<span class="number">5</span>)</span><br><span class="line">sobel_y = cv2.Sobel(image, cv2.CV_64F, <span class="number">0</span>, <span class="number">1</span>, ksize=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]])</strong> Canny边缘检测。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># Canny边缘检测</span></span><br><span class="line">edges = cv2.Canny(image, <span class="number">100</span>, <span class="number">200</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]])</strong> 拉普拉斯边缘检测。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 拉普拉斯边缘检测</span></span><br><span class="line">laplacian = cv2.Laplacian(image, cv2.CV_64F)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-阈值与二值化"><a class="markdownIt-Anchor" href="#opencv-阈值与二值化"></a> OpenCV ==阈值与二值化</h1>
<p>1️⃣ <strong>cv2.threshold(src, thresh, maxval, type[, dst])</strong> 全局阈值。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 全局阈值</span></span><br><span class="line">ret, thresh = cv2.threshold(gray_image, <span class="number">127</span>, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst])</strong> 自适应阈值。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 自适应阈值</span></span><br><span class="line">adaptive_thresh = cv2.adaptiveThreshold(gray_image, <span class="number">255</span>, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, <span class="number">11</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-轮廓分析"><a class="markdownIt-Anchor" href="#opencv-轮廓分析"></a> OpenCV ==轮廓分析</h1>
<p>1️⃣ <strong>cv2.findContours(image, mode, method[, contours[, hierarchy[, offset]]])</strong> 查找轮廓。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 查找轮廓</span></span><br><span class="line">contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]])</strong> 绘制轮廓。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 绘制轮廓</span></span><br><span class="line">cv2.drawContours(image, contours, -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.contourArea(contour[, oriented])</strong> 计算轮廓面积。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 计算轮廓面积</span></span><br><span class="line">area = cv2.contourArea(contours[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<h1 id="opencv-形态学操作"><a class="markdownIt-Anchor" href="#opencv-形态学操作"></a> OpenCV ==形态学操作</h1>
<p>1️⃣ <strong>cv2.erode(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]])</strong> 腐蚀操作。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 定义结构元素</span></span><br><span class="line">kernel = np.ones((<span class="number">5</span>, <span class="number">5</span>), np.uint8)</span><br><span class="line">eroded_image = cv2.erode(image, kernel, iterations=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.dilate(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]])</strong> 膨胀操作。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 定义结构元素</span></span><br><span class="line">kernel = np.ones((<span class="number">5</span>, <span class="number">5</span>), np.uint8)</span><br><span class="line">dilated_image = cv2.dilate(image, kernel, iterations=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.morphologyEx(src, op, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]])</strong> 形态学变换。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 定义结构元素</span></span><br><span class="line">kernel = np.ones((<span class="number">5</span>, <span class="number">5</span>), np.uint8)</span><br><span class="line">opened_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)</span><br><span class="line">closed_image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-金字塔与融合"><a class="markdownIt-Anchor" href="#opencv-金字塔与融合"></a> OpenCV ==金字塔与融合</h1>
<p>1️⃣ <strong>cv2.pyrDown(src[, dst[, dstsize[, borderType]]])</strong> 金字塔下采样。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 金字塔下采样</span></span><br><span class="line">downsampled_image = cv2.pyrDown(image)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.pyrUp(src[, dst[, dstsize[, borderType]]])</strong> 金字塔上采样。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 金字塔上采样</span></span><br><span class="line">upsampled_image = cv2.pyrUp(image)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]])</strong> 图像融合。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 图像融合</span></span><br><span class="line">blended_image = cv2.addWeighted(image1, <span class="number">0.5</span>, image2, <span class="number">0.5</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-特征提取"><a class="markdownIt-Anchor" href="#opencv-特征提取"></a> OpenCV ==特征提取</h1>
<p>1️⃣ <strong>cv2.SIFT_create([nfeatures[, nOctaveLayers[, contrastThreshold[, edgeThreshold[, sigma]]]]])</strong> SIFT特征提取。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 创建SIFT对象</span></span><br><span class="line">sift = cv2.SIFT_create()</span><br><span class="line">keypoints, descriptors = sift.detectAndCompute(gray_image, <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.ORB_create([nfeatures[, scaleFactor[, nlevels[, edgeThreshold[, firstLevel[, WTA_K[, scoreType[, patchSize[, fastThreshold]]]]]]]])</strong> ORB特征提取。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 创建ORB对象</span></span><br><span class="line">orb = cv2.ORB_create()</span><br><span class="line">keypoints, descriptors = orb.detectAndCompute(gray_image, <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.drawKeypoints(image, keypoints, outImage[, color[, flags]])</strong> 绘制特征点。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 绘制特征点</span></span><br><span class="line">cv2.drawKeypoints(image, keypoints, image, color=(<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-视频处理"><a class="markdownIt-Anchor" href="#opencv-视频处理"></a> OpenCV ==视频处理</h1>
<p>1️⃣ <strong>cv2.VideoCapture(filename[, apiPreference])</strong> 打开视频文件。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 打开视频文件</span></span><br><span class="line">cap = cv2.VideoCapture(<span class="string">&#x27;example.mp4&#x27;</span>)</span><br><span class="line"><span class="keyword">while</span> cap.isOpened():</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    cv2.imshow(<span class="string">&#x27;Video&#x27;</span>, frame)</span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.VideoWriter(filename, fourcc, fps, frameSize[, isColor])</strong> 写入视频文件。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 创建视频写入对象</span></span><br><span class="line">fourcc = cv2.VideoWriter_fourcc(*<span class="string">&#x27;XVID&#x27;</span>)</span><br><span class="line">out = cv2.VideoWriter(<span class="string">&#x27;output.avi&#x27;</span>, fourcc, <span class="number">20.0</span>, (<span class="number">640</span>, <span class="number">480</span>))</span><br><span class="line"><span class="keyword">while</span> cap.isOpened():</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    out.write(frame)</span><br><span class="line">cap.release()</span><br><span class="line">out.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]])</strong> Canny边缘检测（视频帧处理）。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 对视频帧进行Canny边缘检测</span></span><br><span class="line"><span class="keyword">while</span> cap.isOpened():</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ret:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    edges = cv2.Canny(frame, <span class="number">100</span>, <span class="number">200</span>)</span><br><span class="line">    cv2.imshow(<span class="string">&#x27;Edges&#x27;</span>, edges)</span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<h1 id="opencv-目标检测"><a class="markdownIt-Anchor" href="#opencv-目标检测"></a> OpenCV ==目标检测</h1>
<p>1️⃣ <strong>cv2.CascadeClassifier(filename)</strong> 加载级联分类器。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 加载人脸检测级联分类器</span></span><br><span class="line">face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + <span class="string">&#x27;haarcascade_frontalface_default.xml&#x27;</span>)</span><br><span class="line">faces = face_cascade.detectMultiScale(gray_image, scaleFactor=<span class="number">1.1</span>, minNeighbors=<span class="number">5</span>, minSize=(<span class="number">30</span>, <span class="number">30</span>))</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])</strong> 绘制矩形框。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 绘制矩形框</span></span><br><span class="line"><span class="keyword">for</span> (x, y, w, h) <span class="keyword">in</span> faces:</span><br><span class="line">    cv2.rectangle(image, (x, y), (x + w, y + h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.HOGDescriptor_getDefaultPeopleDetector()</strong> HOG检测行人。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 加载HOG检测器</span></span><br><span class="line">hog = cv2.HOGDescriptor()</span><br><span class="line">hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())</span><br><span class="line">rects, weights = hog.detectMultiScale(image, winStride=(<span class="number">4</span>, <span class="number">4</span>), padding=(<span class="number">8</span>, <span class="number">8</span>), scale=<span class="number">1.05</span>)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-绘图文字"><a class="markdownIt-Anchor" href="#opencv-绘图文字"></a> OpenCV ==绘图文字</h1>
<p>1️⃣ <strong>cv2.line(img, pt1, pt2, color[, thickness[, lineType[, shift]]])</strong> 绘制直线。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 绘制直线</span></span><br><span class="line">cv2.line(image, (<span class="number">0</span>, <span class="number">0</span>), (<span class="number">100</span>, <span class="number">100</span>), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])</strong> 添加文本。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 添加文本</span></span><br><span class="line">cv2.putText(image, <span class="string">&#x27;Hello, OpenCV&#x27;</span>, (<span class="number">50</span>, <span class="number">50</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">1</span>, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.circle(img, center, radius, color[, thickness[, lineType[, shift]]])</strong> 绘制圆形。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 绘制圆形</span></span><br><span class="line">cv2.circle(image, (<span class="number">150</span>, <span class="number">150</span>), <span class="number">50</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-数学统计"><a class="markdownIt-Anchor" href="#opencv-数学统计"></a> OpenCV ==数学统计</h1>
<p>1️⃣ <strong>cv2.mean(src[, mask])</strong> 计算图像均值。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 计算图像均值</span></span><br><span class="line">mean_value = cv2.mean(image)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.meanStdDev(src</strong>[, mean[, stddev[, mask]]])** 计算图像均值和标准差。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 计算图像均值和标准差</span></span><br><span class="line">mean_value, stddev_value = cv2.meanStdDev(image)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.minMaxLoc(src[, mask])</strong> 找到图像中的最大值和最小值及其位置。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 找到图像中的最大值和最小值及其位置</span></span><br><span class="line">min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(image)</span><br></pre></td></tr></table></figure>
<h1 id="opencv-摄像机标定"><a class="markdownIt-Anchor" href="#opencv-摄像机标定"></a> OpenCV ==摄像机标定</h1>
<p>1️⃣ <strong>cv2.findChessboardCorners(image, patternSize[, corners[, flags]])</strong> 检测棋盘格角点。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 检测棋盘格角点</span></span><br><span class="line">ret, corners = cv2.findChessboardCorners(gray_image, (<span class="number">9</span>, <span class="number">6</span>), <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ <strong>cv2.calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]])</strong> 摄像机标定。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 棋盘格角点的3D坐标</span></span><br><span class="line">objp = np.zeros((<span class="number">9</span> * <span class="number">6</span>, <span class="number">3</span>), np.float32)</span><br><span class="line">objp[:, :<span class="number">2</span>] = np.mgrid[<span class="number">0</span>:<span class="number">9</span>, <span class="number">0</span>:<span class="number">6</span>].T.reshape(-<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">objectPoints = [objp]</span><br><span class="line">imagePoints = [corners]</span><br><span class="line"><span class="comment"># 摄像机标定</span></span><br><span class="line">ret, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objectPoints, imagePoints, gray_image.shape[::-<span class="number">1</span>], <span class="literal">None</span>, <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ <strong>cv2.drawChessboardCorners(image, patternSize, corners, patternWasFound)</strong> 绘制棋盘格角点。</p>
<p>例子：</p>
<p>Python</p>
<p>复制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 绘制棋盘格角点</span></span><br><span class="line">cv2.drawChessboardCorners(image, (<span class="number">9</span>, <span class="number">6</span>), corners, ret)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/05/27/2025%E5%B9%B45%E6%9C%8827%E6%97%A5-opencv%E6%B1%87%E6%80%BB/" data-id="cmbhxnxbd000egov411ngaenr" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年5月21日-yolo项目库汇总" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/05/21/2025%E5%B9%B45%E6%9C%8821%E6%97%A5-yolo%E9%A1%B9%E7%9B%AE%E5%BA%93%E6%B1%87%E6%80%BB/" class="article-date">
  <time class="post-time" datetime="2025-05-21T06:27:17.000Z" itemprop="datePublished">
    <span class="post-month">5月</span><br/>
    <span class="post-day">21</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/21/2025%E5%B9%B45%E6%9C%8821%E6%97%A5-yolo%E9%A1%B9%E7%9B%AE%E5%BA%93%E6%B1%87%E6%80%BB/">2025年5月21日 yolo项目库汇总</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/2025/05/21/2025%E5%B9%B45%E6%9C%8821%E6%97%A5-yolo%E9%A1%B9%E7%9B%AE%E5%BA%93%E6%B1%87%E6%80%BB/image-20250521142731106.png" alt="image-20250521142731106"></p>
<h2 id><a class="markdownIt-Anchor" href="#"></a> </h2>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/05/21/2025%E5%B9%B45%E6%9C%8821%E6%97%A5-yolo%E9%A1%B9%E7%9B%AE%E5%BA%93%E6%B1%87%E6%80%BB/" data-id="cmbhxnxbc000dgov40tge3pe5" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/yolo/" rel="tag">yolo</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年5月21日-code" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/05/21/2025%E5%B9%B45%E6%9C%8821%E6%97%A5-code/" class="article-date">
  <time class="post-time" datetime="2025-05-21T02:14:25.000Z" itemprop="datePublished">
    <span class="post-month">5月</span><br/>
    <span class="post-day">21</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/21/2025%E5%B9%B45%E6%9C%8821%E6%97%A5-code/">2025年5月21日 code</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-设置全局class实例"><a class="markdownIt-Anchor" href="#1-设置全局class实例"></a> 1 设置全局class实例</h2>
<p><img src="/2025/05/21/2025%E5%B9%B45%E6%9C%8821%E6%97%A5-code/image-20250521101506848.png" alt="image-20250521101506848"></p>
<blockquote>
<p>这样就不需要再重新创建了,也可以不需要把类的配置信息等等写在其他相关度不大的地方.,因为信息时不相关的(数据库启动信息)</p>
</blockquote>
<h2 id="2-重复创建"><a class="markdownIt-Anchor" href="#2-重复创建"></a> 2 重复创建</h2>
<p><img src="/2025/05/21/2025%E5%B9%B45%E6%9C%8821%E6%97%A5-code/image-20250521102044215.png" alt="image-20250521102044215"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/05/21/2025%E5%B9%B45%E6%9C%8821%E6%97%A5-code/" data-id="cmbhxnxbb000bgov44dk8g0cv" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年5月20日-cuda3" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/05/20/2025%E5%B9%B45%E6%9C%8820%E6%97%A5-cuda3/" class="article-date">
  <time class="post-time" datetime="2025-05-20T09:11:50.000Z" itemprop="datePublished">
    <span class="post-month">5月</span><br/>
    <span class="post-day">20</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/20/2025%E5%B9%B45%E6%9C%8820%E6%97%A5-cuda3/">2025年5月20日 cuda3</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/12661298743?utm_campaign=shareopn&amp;utm_medium=social&amp;utm_psn=1907929443126707440&amp;utm_source=wechat_session">https://zhuanlan.zhihu.com/p/12661298743?utm_campaign=shareopn&amp;utm_medium=social&amp;utm_psn=1907929443126707440&amp;utm_source=wechat_session</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/703256080?utm_campaign=shareopn&amp;utm_medium=social&amp;utm_psn=1886234892670572457&amp;utm_source=wechat_session">https://zhuanlan.zhihu.com/p/703256080?utm_campaign=shareopn&amp;utm_medium=social&amp;utm_psn=1886234892670572457&amp;utm_source=wechat_session</a></p>
<p><a target="_blank" rel="noopener" href="https://ubook.reader.qq.com/book-detail/45938055">https://ubook.reader.qq.com/book-detail/45938055</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/673046520?utm_campaign=shareopn&amp;utm_medium=social&amp;utm_psn=1766632559096975360&amp;utm_source=wechat_session">https://zhuanlan.zhihu.com/p/673046520?utm_campaign=shareopn&amp;utm_medium=social&amp;utm_psn=1766632559096975360&amp;utm_source=wechat_session</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Bartender_VA11/article/details/135999169">https://blog.csdn.net/Bartender_VA11/article/details/135999169</a></p>
<p>file:///E:/Download/GPU%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98-%E5%9F%BA%E4%BA%8EPython%E5%92%8CCUDA.pdf</p>
<p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html">https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/346910129">https://zhuanlan.zhihu.com/p/346910129</a></p>
</blockquote>
<p><img src="/2025/05/20/2025%E5%B9%B45%E6%9C%8820%E6%97%A5-cuda3/image-20250520185122575.png" alt="image-20250520185122575"></p>
<p><img src="/2025/05/20/2025%E5%B9%B45%E6%9C%8820%E6%97%A5-cuda3/image-20250520185117785.png" alt="image-20250520185117785"></p>
<h3 id="12-框架"><a class="markdownIt-Anchor" href="#12-框架"></a> 1.2 框架</h3>
<p><strong>grid&gt;block&gt;thread</strong></p>
<img src="/2025/05/20/2025%E5%B9%B45%E6%9C%8820%E6%97%A5-cuda3/image-20250520185054786.png" alt="image-20250520185054786" style="zoom:33%;"> 
<p><strong>warp</strong></p>
<p>在1个SM上，block中的thread被划分成warp执行，每个warp中一般有32个thread。</p>
<blockquote>
<p>是nvidia gpu上最小的调度单元</p>
</blockquote>
<h2 id="二-naive-gemm"><a class="markdownIt-Anchor" href="#二-naive-gemm"></a> 二、Naive GEMM</h2>
<blockquote>
<p><strong>每个thread负责读取A矩阵的一行和B矩阵的一列，去计算C矩阵的一个元素</strong>。则一共需要M*N个thread。<br>
<strong>矩阵A和矩阵B都存储在global memory，每个thread直接从global memory上进行读数</strong>，完成计算</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/05/20/2025%E5%B9%B45%E6%9C%8820%E6%97%A5-cuda3/" data-id="cmbhxnxba000agov42cxnb06x" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cuda/" rel="tag">cuda</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年5月20日-python异步库汇总" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/05/20/2025%E5%B9%B45%E6%9C%8820%E6%97%A5-python%E5%BC%82%E6%AD%A5%E5%BA%93%E6%B1%87%E6%80%BB/" class="article-date">
  <time class="post-time" datetime="2025-05-20T02:19:07.000Z" itemprop="datePublished">
    <span class="post-month">5月</span><br/>
    <span class="post-day">20</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/20/2025%E5%B9%B45%E6%9C%8820%E6%97%A5-python%E5%BC%82%E6%AD%A5%E5%BA%93%E6%B1%87%E6%80%BB/">2025年5月20日 python异步库汇总</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="python异步库汇总"><a class="markdownIt-Anchor" href="#python异步库汇总"></a> python异步库汇总</h2>
<h3 id="1-asyncioget_event_looptime"><a class="markdownIt-Anchor" href="#1-asyncioget_event_looptime"></a> 1 <code> asyncio.get_event_loop().time()</code></h3>
<blockquote>
<h2 id="和-timetime-的区别"><a class="markdownIt-Anchor" href="#和-timetime-的区别"></a> 和 <code>time.time()</code> 的区别</h2>
<table>
<thead>
<tr>
<th>方法</th>
<th>含义</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>time.time()</code></td>
<td>返回当前系统时间（UNIX 时间戳）</td>
<td>与系统挂钟同步，单位是秒（浮点数）</td>
</tr>
<tr>
<td><code>loop.time()</code> 或 <code>asyncio.get_event_loop().time()</code></td>
<td>返回事件循环的<strong>相对时间</strong>（高精度单调时钟）</td>
<td><strong>单调递增、不受系统时间调整影响</strong>，更适合做<strong>计时、超时控制</strong>等</td>
</tr>
</tbody>
</table>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">async def main():</span><br><span class="line">    loop = asyncio.get_event_loop()</span><br><span class="line">    start = loop.time()</span><br><span class="line">    await asyncio.sleep(1.5)</span><br><span class="line">    end = loop.time()</span><br><span class="line">    print(f&quot;Elapsed time: &#123;end - start:.3f&#125; seconds&quot;)</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/05/20/2025%E5%B9%B45%E6%9C%8820%E6%97%A5-python%E5%BC%82%E6%AD%A5%E5%BA%93%E6%B1%87%E6%80%BB/" data-id="cmawah6r10019ccv41l7ke34x" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月20日-深度学习问题总结" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/05/20/2025%E5%B9%B43%E6%9C%8820%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="post-time" datetime="2025-05-20T02:19:07.000Z" itemprop="datePublished">
    <span class="post-month">5月</span><br/>
    <span class="post-day">20</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/20/2025%E5%B9%B43%E6%9C%8820%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/">2025年3月20日 dl问题汇总</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="交叉熵为什么常用于机器学习中的分类问题"><a class="markdownIt-Anchor" href="#交叉熵为什么常用于机器学习中的分类问题"></a> 交叉熵为什么常用于机器学习中的分类问题</h3>
<p>交叉熵在机器学习中的分类问题中广泛使用，尤其是在多分类和二分类任务中，这是由于交叉熵具有以下几个重要特性和优势：</p>
<h4 id="1-衡量真实分布和预测分布之间的差异"><a class="markdownIt-Anchor" href="#1-衡量真实分布和预测分布之间的差异"></a> 1. 衡量真实分布和预测分布之间的差异</h4>
<p>交叉熵能够很好地度量模型的预测概率分布与真实概率分布之间的差异。其定义为：</p>
<p class="katex-block katex-error" title="ParseError: KaTeX parse error: Undefined control sequence: \[ at position 1: \̲[̲ H(p, q) = - \s…">\[ H(p, q) = - \sum_{x} p(x) \log q(x) \]
</p>
<p>其中，( p(x) ) 是真实标签的概率分布，通常是one-hot编码（对于正确类别概率为1，其余类别概率为0），( q(x) ) 是模型的预测概率分布。</p>
<h4 id="2-对错误分类有较大惩罚"><a class="markdownIt-Anchor" href="#2-对错误分类有较大惩罚"></a> 2. 对错误分类有较大惩罚</h4>
<p>交叉熵损失函数对错误分类的惩罚较大，能够更有效地引导模型进行优化。举个例子，对于一个二分类问题，假设真实标签 ( p = 1 )，而模型预测的概率 ( q ) 很接近0（完全错误的预测），则交叉熵损失值会非常高。这种特性使得交叉熵在训练过程中能够更快速地减少错误分类的概率。</p>
<h4 id="3-可微性"><a class="markdownIt-Anchor" href="#3-可微性"></a> 3. 可微性</h4>
<p>交叉熵损失函数是可微的，这使得它非常适合梯度下降等优化算法。通过计算损失函数相对于模型参数的梯度，模型可以逐步更新参数以最小化损失，从而提高分类性能。</p>
<h4 id="4-与softmax结合良好"><a class="markdownIt-Anchor" href="#4-与softmax结合良好"></a> 4. 与Softmax结合良好</h4>
<p>在多分类问题中，交叉熵损失函数通常与Softmax激活函数一起使用。Softmax函数将模型的输出转化为一个概率分布：</p>
<p class="katex-block katex-error" title="ParseError: KaTeX parse error: Undefined control sequence: \[ at position 1: \̲[̲ \sigma(z_i) = …">\[ \sigma(z_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}} \]
</p>
<p>结合Softmax和交叉熵，损失函数的梯度计算更为简便，优化过程更稳定。</p>
<h4 id="5-适合概率解释"><a class="markdownIt-Anchor" href="#5-适合概率解释"></a> 5. 适合概率解释</h4>
<p>交叉熵损失函数直接基于概率，因此它能够提供一种自然的方式来解释模型的输出。例如，输出值可以直接解释为某个类别的概率，这在很多实际应用中是非常有用的，如图像分类、自然语言处理等。</p>
<h4 id="6-数学上的凸性"><a class="markdownIt-Anchor" href="#6-数学上的凸性"></a> 6. 数学上的凸性</h4>
<p>在二分类问题中，交叉熵损失函数是凸的，这意味着它有唯一的全局最优解。尽管在多分类问题中，交叉熵损失函数可能不是严格凸的，但在实践中通过适当的优化方法（如SGD，Adam等）依然能有效地找到较优解。</p>
<h3 id="实际例子"><a class="markdownIt-Anchor" href="#实际例子"></a> 实际例子</h3>
<p>以二分类问题为例，假设真实标签 ( y ) 为1（即正类），模型预测正类的概率为 ( \hat{y} )。交叉熵损失函数为：</p>
<p class="katex-block katex-error" title="ParseError: KaTeX parse error: Undefined control sequence: \[ at position 1: \̲[̲ L = -[y \log(\…">\[ L = -[y \log(\hat{y}) + (1 - y) \log(1 - \hat{y})] \]
</p>
<p>当 ( y = 1 ) 时，损失函数简化为 ( L = -\log(\hat{y}) )。如果模型预测 ( \hat{y} ) 很小，则损失会非常大，从而迫使模型在训练过程中提高对正类的预测概率。</p>
<p>总的来说，交叉熵损失函数由于其良好的数学性质和对分类问题的适用性，成为机器学习中分类问题的标准选择。</p>
<h2 id="高维而带来的数据稀疏性问题"><a class="markdownIt-Anchor" href="#高维而带来的数据稀疏性问题"></a> 高维而带来的数据稀疏性问题</h2>
<p><strong>距离度量失效</strong>：在高维空间中，数据点之间的距离度量（如欧氏距离）可能失去区分性。随着维度增加，不同数据点之间的距离变得越来越相似，从而导致传统的距离度量方法失效。这对基于距离的算法（如K近邻算法、聚类算法等）影响尤为显著。</p>
<p><strong>计算复杂度增加</strong>：高维数据需要处理的特征数增多，计算复杂度随之增加。这对存储和计算资源都是巨大的挑战，尤其是在处理大规模数据集时。</p>
<p><strong>维度诅咒</strong>：高维数据通常伴随着“维度诅咒”问题，即随着维度增加，数据点需要的样本量指数级增长，才能维持同样的统计显著性和精度。这导致在高维空间中进行数据建模和分析变得困难，模型容易过拟合。</p>
<p><strong>模型解释性降低</strong>：高维数据中的特征较多，模型的解释性会降低。人类难以理解和解释高维空间中的特征关系，从而影响决策和分析的透明度。</p>
<h3 id="解决办法"><a class="markdownIt-Anchor" href="#解决办法"></a> 解决办法：</h3>
<p><strong>特征选择</strong>：通过选择与目标变量高度相关的特征，去除冗余或不相关的特征，从而降低数据的维度，提高模型的性能。</p>
<p><strong>特征提取</strong>：通过技术如主成分分析（PCA）、线性判别分析（LDA）和非负矩阵分解（NMF）等方法，将原始高维数据映射到低维空间，同时尽可能保留数据的主要信息。</p>
<p><strong>稀疏表示</strong>：利用稀疏编码、L1正则化等方法，使得数据在较少的特征上具有较大的表示，从而减少模型的复杂度和过拟合风险。</p>
<p><strong>核方法</strong>：如支持向量机（SVM）的核技巧，通过在高维空间中进行操作而不显式地计算高维特征，来处理非线性问题。</p>
<p><strong>深度学习</strong>：深度神经网络，尤其是自动编码器（Autoencoder），可以有效地学习数据的低维表示，从而在高维数据处理中表现出色</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/05/20/2025%E5%B9%B43%E6%9C%8820%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/" data-id="cmbhxnxb00007gov4b9630qdx" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/">&amp;laquo; pre</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/3/">next &amp;raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Weakliy_Blog</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>110</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>32</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="Github">
          Github
        </a>
      
    </div>

    <div class="friend-link">
      <h2>联系我</h2>
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2024 - 2025 Weakliy<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">首页</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">总览</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">xxx</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">xxxx</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>