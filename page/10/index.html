<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Weakliy_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Weakliy_Blog">
<meta property="og:url" content="https://shakewely.github.io/page/10/index.html">
<meta property="og:site_name" content="Weakliy_Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Weakliy">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Weakliy_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>122</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>36</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main">
  
    <article id="post-2023年12月4日-PCA" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/12/04/2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/" class="article-date">
  <time class="post-time" datetime="2023-12-04T13:06:58.000Z" itemprop="datePublished">
    <span class="post-month">12月</span><br/>
    <span class="post-day">04</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/12/04/2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/">2023年12月4日 PCA</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="pca"><a class="markdownIt-Anchor" href="#pca"></a> PCA</h1>
<h2 id="1-pca原理"><a class="markdownIt-Anchor" href="#1-pca原理"></a> 1、PCA原理</h2>
<p>参考：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1E5411E71z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=d3c0d5e026e5b0637b219503cea5513e">https://www.bilibili.com/video/BV1E5411E71z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=d3c0d5e026e5b0637b219503cea5513e</a></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211124849.png" alt="image-20231204211124849" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211048339.png" alt="image-20231204211048339" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211113027.png" alt="image-20231204211113027" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211258728.png" alt="image-20231204211258728" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211356758.png" alt="image-20231204211356758" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211402550.png" alt="image-20231204211402550" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211416402.png" alt="image-20231204211416402" /><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211427283.png" alt="image-20231204211427283" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211423299.png" alt="image-20231204211423299" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211505125.png" alt="image-20231204211505125" /><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211617375.png" alt="image-20231204211617375" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211650063.png" alt="image-20231204211650063" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211739123.png" alt="image-20231204211739123" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211747417.png" alt="image-20231204211747417" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204211757163.png" alt="image-20231204211757163" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204212108183.png" alt="image-20231204212108183" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204212313493.png" alt="image-20231204212313493" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204212518333.png" alt="image-20231204212518333" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204212506525.png" alt="image-20231204212506525" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204212512462.png" alt="image-20231204212512462" /></p>
<p><img src="./2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/image-20231204212542766.png" alt="image-20231204212542766" /></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/12/04/2023%E5%B9%B412%E6%9C%884%E6%97%A5-PCA/" data-id="clrwazlr3000y7ov4a2g29mne" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年11月20日-面试总结2" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/11/20/2023%E5%B9%B411%E6%9C%8820%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%932/" class="article-date">
  <time class="post-time" datetime="2023-11-19T16:49:22.000Z" itemprop="datePublished">
    <span class="post-month">11月</span><br/>
    <span class="post-day">20</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/2023%E5%B9%B411%E6%9C%8820%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%932/">2023年11月20日 面试总结2</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>概况</strong>：</p>
<ul>
<li>面试时间：早上十点</li>
<li>面试岗位：</li>
<li>面试内容：自我介绍、专业领域、大创项目、Stable Diffusion项目、解释Diffusion模型、解释gam模型、计算机网络提问、深度学习提问、问答环节</li>
</ul>
<p><strong>面试内容总结</strong>：</p>
<ol>
<li><strong>自我介绍和专业领域</strong>：
<ul>
<li>面试官询问了你的专业和为何选择该岗位，但我似乎没有清晰地表达出你的专业优势和学院背景。</li>
</ul>
</li>
<li><strong>大创项目</strong>：
<ul>
<li>数据怎么处理</li>
<li>模型用了什么alexnet  似乎太过于简单</li>
<li>判断输出用的什么方式  概率sofmax</li>
<li></li>
</ul>
</li>
<li><strong>Stable Diffusion项目</strong>：
<ul>
<li>lora模型介绍  回答不好</li>
<li>项目使用经验 自我感觉还行</li>
</ul>
</li>
<li><strong>深度学习提问</strong>：
<ul>
<li>diffusion模型解释  临时抱佛脚的</li>
<li>过拟合和欠拟合解释——回答的思路很乱</li>
<li>解释gam模型——回答不好，</li>
</ul>
</li>
<li><strong>计算机网络提问</strong>：
<ul>
<li>问了计算机单线程和多线程组成原理下的实现？——没学过</li>
</ul>
</li>
<li>python<strong>提问：</strong>
<ol>
<li>python中可变数据类型有哪些——没背，没准备，</li>
</ol>
</li>
<li><strong>工作安排</strong>：
<ul>
<li>模型训练和脚本编写，方便美工作图</li>
</ul>
</li>
<li><strong>问答环节</strong>：
<ul>
<li>忘了——但是降维打击了已经</li>
</ul>
</li>
</ol>
<p><strong>总结</strong>：</p>
<p>​	学习不充分——还有很大没涉及的地方</p>
<p>​	准备不充分——很多没有按格式作答、思路很乱</p>
<p>​	心态爆炸——在专业人士面前简直是降维打击！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/11/20/2023%E5%B9%B411%E6%9C%8820%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%932/" data-id="clrwazlqy000i7ov4aofx9c7i" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年11月17日-面试1总结" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/11/17/2023%E5%B9%B411%E6%9C%8817%E6%97%A5-%E9%9D%A2%E8%AF%951%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="post-time" datetime="2023-11-17T10:06:15.000Z" itemprop="datePublished">
    <span class="post-month">11月</span><br/>
    <span class="post-day">17</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/17/2023%E5%B9%B411%E6%9C%8817%E6%97%A5-%E9%9D%A2%E8%AF%951%E6%80%BB%E7%BB%93/">2023年11月17日 面试1总结</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>概况</strong>：</p>
<ul>
<li>面试时间：15:38</li>
<li>面试岗位：工程项目与人工智能领域相关</li>
<li>面试内容：自我介绍、专业领域、大创项目、插件印象、开发插件想法、Stable Diffusion项目、工作要求和任务、问答环节</li>
</ul>
<p><strong>面试内容总结</strong>：</p>
<ol>
<li><strong>自我介绍和专业领域</strong>：
<ul>
<li>面试官询问了你的专业和为何选择该岗位，但我似乎没有清晰地表达出你的专业优势和学院背景。</li>
</ul>
</li>
<li><strong>大创项目</strong>：
<ul>
<li>提及了大创项目的流程和任务，但忽略了项目目的和实现方法，可能需要更注重解释项目的目标和你在项目中的角色。</li>
</ul>
</li>
<li><strong>插件印象和开发想法</strong>：
<ul>
<li>我提到了一个能阅读文献的插件，但在回答开发自己的插件时，没有明确表达插件的功能和目的。</li>
</ul>
</li>
<li><strong>Stable Diffusion项目</strong>：
<ul>
<li>解释了Stable Diffusion是一个与AI相关的热门产品，并且提到了你尝试使用该产品的功能制作了人脸和衣服模型。</li>
</ul>
</li>
<li><strong>工作要求和任务</strong>：
<ul>
<li>面试官没有明确说明具体的工作任务，只是模糊地提到了要对Chat GPT的最新资讯进行咨询并给公司做总结，涉及到AI产品的探索。</li>
</ul>
</li>
<li><strong>工作安排</strong>：
<ul>
<li>面试官询问你一天能到岗多少天，但工资是按日结算，似乎有所限制，需要确定到岗时间并考虑工资结算方式。</li>
</ul>
</li>
<li><strong>问答环节</strong>：
<ul>
<li>你问了关于具体工作任务能否线上完成的问题，但面试官似乎未给出明确答复。</li>
</ul>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/11/17/2023%E5%B9%B411%E6%9C%8817%E6%97%A5-%E9%9D%A2%E8%AF%951%E6%80%BB%E7%BB%93/" data-id="clrwazlqx000g7ov48eub457k" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年11月7日-量化3-Question" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/" class="article-date">
  <time class="post-time" datetime="2023-11-07T12:25:22.000Z" itemprop="datePublished">
    <span class="post-month">11月</span><br/>
    <span class="post-day">07</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/">2023年11月7日 量化3 Question</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-cuda"><a class="markdownIt-Anchor" href="#1-cuda"></a> 1 cuda</h2>
<p>NotImplementedError: Could not run ‘quantized::linear_prepack_fp16’ with arguments from the ‘CUDA’ backend.</p>
<p><strong>量化过程中使用到了一个不支持CUDA的操作。</strong></p>
<h3 id="1-为什么量化层少了acc却降低了"><a class="markdownIt-Anchor" href="#1-为什么量化层少了acc却降低了"></a> 1 为什么量化层少了，acc却降低了？</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quantized_model = torch.quantization.quantize_dynamic(model, &#123;nn.Linear&#125;, dtype=torch.qint8)</span><br></pre></td></tr></table></figure>
<p><img src="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/image-20231107202610901.png" alt="image-20231107202610901"></p>
<p><img src="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/image-20231107202922407.png" alt="image-20231107202922407"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quantized_model = torch.quantization.quantize_dynamic(model, &#123;nn.Linear, nn.Conv2d&#125;, dtype=torch.qint8)</span><br></pre></td></tr></table></figure>
<p><img src="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/image-20231107202605391.png" alt="image-20231107202605391"></p>
<p><img src="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/image-20231107202821307.png" alt="image-20231107202821307"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/" data-id="clrwazlr0000o7ov4d56p813a" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%87%8F%E5%8C%96/" rel="tag">量化</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年11月7日-深度学习报错日记" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%A5%E9%94%99%E6%97%A5%E8%AE%B0/" class="article-date">
  <time class="post-time" datetime="2023-11-07T12:02:19.000Z" itemprop="datePublished">
    <span class="post-month">11月</span><br/>
    <span class="post-day">07</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%A5%E9%94%99%E6%97%A5%E8%AE%B0/">2023年11月7日 深度学习报错日记</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li>2</li>
</ul>
<p>RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same</p>
<p><strong>没有明确指定模型应该在GPU上运行。你可以使用<code>model.to(device)</code>将模型移动到GPU上</strong></p>
<ul>
<li>
<p>3</p>
<p>PIL.UnidentifiedImageError: cannot identify image file ‘F:\Dataset\PetImages\Cat\666.jpg’</p>
</li>
</ul>
<p><strong>图片损坏</strong></p>
<ul>
<li>继承Conv基类错误了</li>
</ul>
<p><img src="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%A5%E9%94%99%E6%97%A5%E8%AE%B0/a1fc621421e9142e2c9efb319447d81.png" alt="a1fc621421e9142e2c9efb319447d81"></p>
<p><img src="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%A5%E9%94%99%E6%97%A5%E8%AE%B0/8906c28d1e2f7e77d19994f0a920f62.png" alt="8906c28d1e2f7e77d19994f0a920f62"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%A5%E9%94%99%E6%97%A5%E8%AE%B0/" data-id="clrwazlr1000q7ov430ep5euf" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月24日-TensorRT1介绍" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT1%E4%BB%8B%E7%BB%8D/" class="article-date">
  <time class="post-time" datetime="2023-10-24T11:51:56.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">24</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT1%E4%BB%8B%E7%BB%8D/">2023年10月24日 TensorRT1介绍</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-什么是tensorrt"><a class="markdownIt-Anchor" href="#1-什么是tensorrt"></a> 1 什么是TensorRT</h2>
<h3 id="11-tensorrt介绍"><a class="markdownIt-Anchor" href="#11-tensorrt介绍"></a> 1.1 <strong>TensorRT介绍</strong></h3>
<p>TensorRT是可以在<strong>NVIDIA</strong>各种<strong>GPU硬件平台</strong>下运行的一个<strong>C++推理框架</strong>。</p>
<p>我们利用Pytorch训练好的模型，可以转化为TensorRT的格式，然后利用TensorRT推理引擎去运行我们这个模型，从而提升这个模型在英伟达GPU上运行的速度。<strong>速度提升</strong>的比例是<strong>比较可观</strong>的。</p>
<h3 id="12-tensorrt-工作流程"><a class="markdownIt-Anchor" href="#12-tensorrt-工作流程"></a> 1.2 TensorRT 工作流程</h3>
<img src="/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT1%E4%BB%8B%E7%BB%8D/.Hexo/MyBlog/source/_posts/2023年10月12日-TensorRT介绍/image-20250314191334384.png" alt="image-20250314191334384" style="zoom: 25%;">
<h3 id="13-为什么能加速"><a class="markdownIt-Anchor" href="#13-为什么能加速"></a> 1.3 为什么能加速？</h3>
<ul>
<li>
<p><strong>算子融合(层与张量融合)</strong>：简单来说就是通过融合一些计算op或者去掉一些多余op来<strong>减少数据流通次数以及显存的频繁使用来提速</strong>，使用更少的cuda核心</p>
<img src="/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT1%E4%BB%8B%E7%BB%8D/.Hexo\MyBlog\source\_posts\2023年10月12日-TensorRT介绍\image-20250314190650887.png" alt="image-20250314190650887" style="zoom: 50%;">
</li>
<li>
<p><strong>量化</strong>：量化即IN8量化或者FP16以及TF32等不同于常规FP32精度的使用，这些精度可以显著提升模型执行速度并且不会保持原先模型的精度</p>
</li>
<li>
<p><strong>内核自动调整</strong>：根据不同的显卡构架、SM数量、内核频率等(例如1080TI和2080TI)，选择不同的优化策略以及计算方式，寻找最合适当前构架的计算方式<code>对特定显卡进行特定优化</code>为模型的每一层选择最优化的GPU 内核。这种自适应方法可确保模型充分利用 GPU 的计算能力。</p>
<img src="/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT1%E4%BB%8B%E7%BB%8D/.Hexo/MyBlog/source/_posts/2023年10月12日-TensorRT介绍/image-20231012202620295.png" alt="image-20231012202620295" style="zoom: 33%;">
</li>
<li>
<p><strong>动态张量显存</strong>/<strong>动态Tensor 内存管理</strong>：TensorRT 在推理过程中有效管理tensor 内存使用情况，减少内存开销并优化内存分配。这使得GPU 的内存使用效率更高。</p>
</li>
<li>
<p><strong>多流执行</strong>：使用CUDA中的stream技术，最大化实现并行操作</p>
</li>
</ul>
<h3 id="14-tensorrt的加速效果怎么样"><a class="markdownIt-Anchor" href="#14-tensorrt的加速效果怎么样"></a> 1.<strong>4 TensorRT的加速效果怎么样</strong></h3>
<p>加速效果取决于模型的类型和大小，也取决于我们所使用的显卡类型。</p>
<p>TensorRT所做的优化也是<strong>基于GPU</strong>进行优化，当然也是更喜欢那种一大块一大块的矩阵运算，尽量直通到底。因此对于通道数比较多的卷积层和反卷积层，优化力度是比较大的；</p>
<p>如果是比较繁多复杂的各种细小op操作**(例如reshape、gather、split等)，那么TensorRT的优化力度就没有那么夸张了。**</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">所以在转onnx的时候需要对模型进行修改，减少reshape等</span><br></pre></td></tr></table></figure>
<h3 id="15概念和使用方式"><a class="markdownIt-Anchor" href="#15概念和使用方式"></a> 1.5概念和使用方式</h3>
<ul>
<li>
<p>支持模型、数据类型、支持的IO、支持的功能</p>
</li>
<li>
<p>TensorRT中context、engine、builder概念</p>
</li>
<li>
<p>环境搭建、运行环境</p>
<p><strong>1.5 什么是算子</strong></p>
<p>有时候自己会设计一些layer来满足任务需求，但是这些layer在使用Tensorrt优化时，TensorRT可能并不支持。</p>
<p>这时候就需要自己写一个算子/<strong>Plugin</strong> 来实现</p>
<img src="/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT1%E4%BB%8B%E7%BB%8D/.Hexo/MyBlog/source/_posts/2023年10月12日-TensorRT介绍/image-20250314191142137.png" alt="image-20250314191142137" style="zoom: 25%;">
</li>
</ul>
<h3 id="16-工作流程"><a class="markdownIt-Anchor" href="#16-工作流程"></a> 1.6 工作流程</h3>
<ul>
<li>python端API</li>
<li>C++端API</li>
<li>简单的demo</li>
</ul>
<h2 id="2-tensorrt完整流程"><a class="markdownIt-Anchor" href="#2-tensorrt完整流程"></a> 2 TensorRT完整流程</h2>
<h3 id="21-onnx转tensorrt"><a class="markdownIt-Anchor" href="#21-onnx转tensorrt"></a> 2.1 ONNX转TensorRT</h3>
<ul>
<li>parser方式转换模型</li>
<li>onnx2trt简单分析</li>
<li>graphsurgeon修改onnx网络</li>
<li>一些注意点</li>
</ul>
<h3 id="22-框架内使用tensorrt"><a class="markdownIt-Anchor" href="#22-框架内使用tensorrt"></a> 2.2 框架内使用tensorrt</h3>
<ul>
<li>torch_tensorrt介绍、使用</li>
<li>torch_tensorrt源码解析</li>
</ul>
<h2 id="3-tensorrt进阶操作"><a class="markdownIt-Anchor" href="#3-tensorrt进阶操作"></a> 3 TensorRT进阶操作</h2>
<h3 id="31-如何debug"><a class="markdownIt-Anchor" href="#31-如何debug"></a> 3.1 如何debug</h3>
<ul>
<li>精度问题debug（nan、精度不匹配）</li>
<li>网络可视化（netron、trt-explorer）</li>
<li>polygraphy（TensorRT官方提供的非常好的工具）</li>
</ul>
<h3 id="32-api搭建网络"><a class="markdownIt-Anchor" href="#32-api搭建网络"></a> 3.2 API搭建网络</h3>
<ul>
<li>API搭建网络基本方式、权重提取，这部分强烈建议看TensorRTx</li>
<li>explicit batch vs implicit batch</li>
</ul>
<h3 id="33-自定义插件plugin"><a class="markdownIt-Anchor" href="#33-自定义插件plugin"></a> 3.3 自定义插件plugin</h3>
<ul>
<li>如何写自定义plugin、Plugin中关键的API与注意点</li>
<li>自定义插件示例、集成plugin到trt中、参与trt序列化</li>
<li>plugin的生命周期、资源管理</li>
<li>dynamic-shape-plugin</li>
<li>Plugin的FP16和INT8</li>
</ul>
<h3 id="34-常见疑难杂症"><a class="markdownIt-Anchor" href="#34-常见疑难杂症"></a> 3.4 常见疑难杂症</h3>
<ul>
<li>各种log中的报错</li>
</ul>
<h2 id="4-tensorrt最佳使用指南"><a class="markdownIt-Anchor" href="#4-tensorrt最佳使用指南"></a> 4 TensorRT最佳使用指南</h2>
<h3 id="41-如何正确使用trtexec"><a class="markdownIt-Anchor" href="#41-如何正确使用trtexec"></a> 4.1 如何正确使用trtexec</h3>
<ul>
<li>trtexec基本用法</li>
<li>动态尺度、设置optimization profile以及注意点（min-opt-max）</li>
<li>trtexec源码解析</li>
</ul>
<h3 id="42-提升性能"><a class="markdownIt-Anchor" href="#42-提升性能"></a> 4.2 提升性能</h3>
<ul>
<li>多steam（重叠计算和数据拷贝的时间，增加GPU利用率）</li>
<li>多context（多线程推理）</li>
<li>多optimization profile</li>
<li>CUDA Graph（减少kernel launch时间）</li>
<li>Timing Cache（减少build时间）</li>
<li>Algorithm Selector</li>
</ul>
<h3 id="43-tensorrt转换相关"><a class="markdownIt-Anchor" href="#43-tensorrt转换相关"></a> 4.3 TensorRT转换相关</h3>
<ul>
<li>某些Layer选择的算法导致误差大，屏蔽掉该选择 tactic Source</li>
<li>更新权重refit功能（强化学习用的多）</li>
<li>构建期/运行期显存占用大（调整参数以及策略）</li>
</ul>
<h2 id="5-tensorrt量化"><a class="markdownIt-Anchor" href="#5-tensorrt量化"></a> 5 TensorRT量化</h2>
<h3 id="ptq"><a class="markdownIt-Anchor" href="#ptq"></a> PTQ</h3>
<h3 id="qat"><a class="markdownIt-Anchor" href="#qat"></a> QAT</h3>
<ul>
<li>fake_</li>
<li>QDQ 节点</li>
</ul>
<h3 id="tensorrt-fp16"><a class="markdownIt-Anchor" href="#tensorrt-fp16"></a> TensorRT-FP16</h3>
<ul>
<li>fp16精度设置与使用</li>
<li>fp16常见问题</li>
</ul>
<h3 id="tensorrt-int8"><a class="markdownIt-Anchor" href="#tensorrt-int8"></a> TensorRT-INT8</h3>
<ul>
<li>int8使用</li>
<li>PTQ校准集</li>
<li>QAT量化</li>
</ul>
<h3 id="混合精度"><a class="markdownIt-Anchor" href="#混合精度"></a> 混合精度</h3>
<ul>
<li>fp32和fp16</li>
<li>fp16和int8</li>
</ul>
<h2 id="6-tensorrt拓展"><a class="markdownIt-Anchor" href="#6-tensorrt拓展"></a> 6 TensorRT拓展</h2>
<h3 id="61-tensorrt转换的几种方式"><a class="markdownIt-Anchor" href="#61-tensorrt转换的几种方式"></a> 6.1 TensorRT转换的几种方式</h3>
<ul>
<li>torch2trt</li>
<li>torchscript2trt</li>
<li>fx2trt</li>
</ul>
<h2 id="7-tensorrt实战"><a class="markdownIt-Anchor" href="#7-tensorrt实战"></a> 7 TensorRT实战</h2>
<h3 id="61-检测模型转换"><a class="markdownIt-Anchor" href="#61-检测模型转换"></a> 6.1 检测模型转换</h3>
<ul>
<li>SSD模型转TensorRT dynamic-shape</li>
<li>带有自定义DCN-OP的CenterNet转TensorRT</li>
</ul>
<h3 id="62-识别-分割-nlp类模型"><a class="markdownIt-Anchor" href="#62-识别-分割-nlp类模型"></a> 6.2 识别、分割、nlp类模型</h3>
<ul>
<li>stable diffusion</li>
<li>GPT</li>
</ul>
<h3 id="63-tensorrttriton-inference-server线上线下部署"><a class="markdownIt-Anchor" href="#63-tensorrttriton-inference-server线上线下部署"></a> 6.3 TensorRT+triton-inference-server线上/线下部署</h3>
<ul>
<li>基本部署教程</li>
<li>大规模TensorRT模型部署、多卡、模型调度</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT1%E4%BB%8B%E7%BB%8D/" data-id="cmanj8o1q0001lcv4fsd382ib" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorRT/" rel="tag">TensorRT</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月19日-量化2代码实现" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%962%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" class="article-date">
  <time class="post-time" datetime="2023-10-19T08:49:29.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">19</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%962%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">2023年10月19日 量化2代码实现</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://blog.csdn.net/kuan__/article/details/109539007">https://blog.csdn.net/kuan__/article/details/109539007</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42506418/article/details/131234818">https://blog.csdn.net/weixin_42506418/article/details/131234818</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/126231261">https://blog.csdn.net/ljp1919/article/details/126231261</a></p>
<h2 id="3-训练后动态量化技术dynamic-quantization"><a class="markdownIt-Anchor" href="#3-训练后动态量化技术dynamic-quantization"></a> 3 **训练后动态量化技术（dynamic quantization）</h2>
<p>将模型的权重从浮点精度（例如32位浮点数）转换为低精度整数类型（例如8位整数）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quantized_model = torch.quantization.quantize_dynamic(model, &#123;nn.Linear, nn.Conv2d&#125;, dtype=torch.qint8)</span><br></pre></td></tr></table></figure>
<ol>
<li><code>model</code>: 这个变量应该是你想要进行量化的原始PyTorch模型，它可能是使用<code>torch.nn.Module</code>类定义的神经网络模型。</li>
<li><code>&#123;nn.Linear, nn.Conv2d&#125;</code>: 这个参数指定了你希望量化的模型层类型。在这个例子中，<code>nn.Linear</code>和<code>nn.Conv2d</code>表示对模型中的线性层和二维卷积层进行量化。
<ol>
<li><strong>线性层（Linear Layers）</strong>：<code>nn.Linear</code></li>
<li><strong>卷积层（Convolutional Layers）</strong>：<code>nn.Conv1d</code>, <code>nn.Conv2d</code>, <code>nn.Conv3d</code></li>
<li><strong>循环神经网络层（Recurrent Layers）</strong>：<code>nn.RNN</code>, <code>nn.LSTM</code>, <code>nn.GRU</code></li>
<li><strong>批归一化层（Batch Normalization Layers）</strong>：<code>nn.BatchNorm1d</code>, <code>nn.BatchNorm2d</code>, <code>nn.BatchNorm3d</code></li>
<li><strong>激活函数（Activation Functions）</strong>：<code>nn.ReLU</code>, <code>nn.LeakyReLU</code>, <code>nn.PReLU</code>, <code>nn.ReLU6</code>, 等等。</li>
<li><strong>池化层（Pooling Layers）</strong>：<code>nn.MaxPool1d</code>, <code>nn.MaxPool2d</code>, <code>nn.AvgPool1d</code>, <code>nn.AvgPool2d</code>, 等等。</li>
</ol>
</li>
<li><code>dtype=torch.qint8</code>: 这个参数指定了量化后的数据类型，这里是8位整数（qint8）。在推断时，量化模型将使用这种低精度整数类型进行计算。
<ol>
<li><strong><code>torch.qint8</code></strong>: 8位有符号整数。通常用于量化权重和激活值。</li>
<li><strong><code>torch.quint8</code></strong>: 8位无符号整数。通常用于量化正数的权重和激活值。</li>
<li><strong><code>torch.qint32</code></strong>: 32位有符号整数。通常用于量化权重和激活值。</li>
<li><strong><code>torch.float16</code></strong>: 16位浮点数。通常用于量化权重和激活值。不是整数量化，但比32位浮点数（<code>torch.float32</code>）占用更少内存。</li>
<li><strong><code>torch.bfloat16</code></strong>: 16位浮点数（Brain Floating Point）</li>
</ol>
</li>
</ol>
<h2 id="4-量化感知训练"><a class="markdownIt-Anchor" href="#4-量化感知训练"></a> 4 <strong>量化感知训练</strong></h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.quantization.FakeQuantize QAT</span><br></pre></td></tr></table></figure>
<p><strong>get_default_qconfig</strong></p>
<p>​	在使用量化（quantization）技术时，PyTorch会改变模型的结构，并为每个权重参数添加量化相关的信息。因此需要重新写一个量化model</p>
<p>量化后的模型（quantized model）的state_dict的键（keys）与原始模型的state_dict的键不匹配。</p>
<p>使用<code>torch.quantization.quantize_dynamic()</code>对模型进行量化时，它会在state_dict中添加与量化参数相关的额外键（比如scale、zero_point、dtype和_packed_params）。</p>
<p>为了解决这个问题，需要修改加载量化模型的代码。在加载量化模型的state_dict时，应该指定<code>map_location</code>参数，将量化模型的参数映射到适当的设备（GPU或CPU）（设备不匹配的错误）。此外，你需要传递<code>strict=False</code>参数给<code>load_state_dict()</code>，忽略量化模型state_dict中存在的额外键。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%962%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" data-id="clrwazlqu00057ov4bn1tbi46" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%87%8F%E5%8C%96/" rel="tag">量化</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月19日-量化1介绍" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/" class="article-date">
  <time class="post-time" datetime="2023-10-19T07:37:02.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">19</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/">2023年10月19日 量化1</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://blog.csdn.net/purple_love/article/details/127254449">https://blog.csdn.net/purple_love/article/details/127254449</a></p>
<h2 id="1-模型量化是什么"><a class="markdownIt-Anchor" href="#1-模型量化是什么"></a> 1、<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&amp;spm=1001.2101.3001.7020">模型量化</a>是什么？</h2>
<p>简而言之，所谓的模型量化就是将浮点存储（运算）转换为整型存储（运算）的一种<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9&amp;spm=1001.2101.3001.7020">模型压缩</a>技术。<strong>简单直白点讲，即原来表示一个权重需要使用float32表示，量化后只需要使用int8来表示就可以啦，仅仅这一个操作，我们就可以获得接近4倍的网络加速</strong>！</p>
<h2 id="2-为什么需要做模型量化模型量化动机是什么"><a class="markdownIt-Anchor" href="#2-为什么需要做模型量化模型量化动机是什么"></a> 2、为什么需要做模型量化？模型量化动机是什么？</h2>
<ul>
<li><strong>更少的存储开销和带宽需求</strong>。即使用更少的比特数存储数据，有效减少应用对存储资源的依赖，但现代系统往往拥有相对丰富的存储资源，这一点已经不算是采用量化的主要动机；</li>
<li><strong>更快的计算速度</strong>。即对大多数处理器而言，整型运算的速度一般（但不总是）</li>
</ul>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019161721639.png" alt="image-20231019161721639"></p>
<pre><code>**FP32乘法运算的能耗是INT8乘法运算能耗的18.5倍，芯片占用面积则是int8的27.3倍**，

**尚可接受的精度损失**。**即量化相当于对模型权重引入噪声，所幸CNN本身对噪声不敏感（在模型训练过程中，模拟量化所引入的权重加噪还有利于防止过拟合），在合适的比特数下量化后的模型并不会带来很严重的精度损失**。
</code></pre>
<h2 id="3-模型量化的方案"><a class="markdownIt-Anchor" href="#3-模型量化的方案"></a> 3、模型量化的方案</h2>
<ol>
<li><code>data free</code>：不使用校准集，传统的方法直接将浮点参数转化成量化数，使用上非常简单，但是一般会带来很大的精度损失，但是高通最新的论文 <code>DFQ</code> 不使用校准集也得到了很高的精度。</li>
<li><code>calibration</code>：基于校准集方案，通过输入少量真实数据进行统计分析。很多芯片厂商都提供这样的功能，如 <code>tensorRT</code>、高通、海思、地平线、寒武纪</li>
<li><code>finetune</code>：基于训练 <code>finetune</code> 的方案，将量化误差在训练时仿真建模，调整权重使其更适合量化。好处是能带来更大的精度提升，缺点是要修改模型训练代码，开发周期较长。</li>
</ol>
<h2 id="4-模型量化分类"><a class="markdownIt-Anchor" href="#4-模型量化分类"></a> 4、模型量化分类</h2>
<h3 id="41-线性量化"><a class="markdownIt-Anchor" href="#41-线性量化"></a> 4.1 线性量化</h3>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019161927584.png" alt="image-20231019161927584"></p>
<p>​	<strong>q 表示的是原始的float32数值；</strong><br>
​	<strong>Z表示的是float32数值的偏移量，在很多地方又叫Zero Point；</strong><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019162041599.png" alt="image-20231019162041599"></p>
<p>**	S表示的是float32的缩放因子，在很多地方又叫Scale；**</p>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019162119689.png" alt="image-20231019162119689">	<strong>Round(⋅) 表示的是四舍五入近似取整的数学函数，除了四舍五入，使用向上或者向下取整也是可以的；</strong><br>
<strong>r表示的是量化后的一个整数值。</strong></p>
<p><strong>根据参数 Z 是否为零可以将线性量化分为两类—即对称量化和非对称量化</strong>。</p>
<h4 id="411-对称量化"><a class="markdownIt-Anchor" href="#411-对称量化"></a> 4.1.1 对称量化</h4>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019162306723.png" alt="image-20231019162306723"></p>
<p>​	使用一个映射公式将输入数据映射到[-128,127]的范围内</p>
<p>在对称量化中，r 是用有符号的整型数值(int8)来表示的，此时 Z=0，且 q=0时恰好有r=0。在对称量化中，我们可以取Z=0，S的取值可以使用如下的公式，也可以采用其它的公式。其中，n 是用来表示该数值的位宽，x 是数据集的总体样本。</p>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019162300497.png" alt="image-20231019162300497"></p>
<h4 id="412-非对称量化"><a class="markdownIt-Anchor" href="#412-非对称量化"></a> 4.1.2 非对称量化</h4>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019162349206.png" alt="image-20231019162349206"></p>
<p>​	使用一个映射公式将输入数据映射到[0,255]的范围内</p>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019162416109.png" alt="image-20231019162416109"></p>
<h3 id="43-在线量化和离线量化"><a class="markdownIt-Anchor" href="#43-在线量化和离线量化"></a> 4.3 在线量化和离线量化</h3>
<p><strong>根据激活值的量化方式，可以分为在线（online）量化和离线（offline）量化。</strong></p>
<ul>
<li><strong>在线量化</strong>，即指激活值的S和Z<strong>在实际推断过程中根据实际的激活值动态计算</strong>；Z表示Zero Point的数值，S表示Scale的数值</li>
<li><strong>离线量化</strong>，即指<strong>提前确定好</strong>激活值的S和Z；</li>
</ul>
<p>​	由于不需要动态计算量化参数，通常离线量化的推断速度更快些，通常通过以下的三种方法来确定相关的量化参数。</p>
<ol>
<li>
<pre class="highlight"><code class>1. **指数平滑法**。即将校准数据集送入模型，收集每个量化层的输出特征图，计算每个batch的S和Z值，并**通过指数平滑法来更新S和Z值**。
2. **直方图截断法**。即在计算量化参数Z和S的过程中，由于**有的特征图**会出现偏离较远的奇异值，导致max非常大，所以可以通过直方图截取的形式，比如**抛弃最大的前1%数据，以前1%分界点的数值作为max计算量化参数**。
3. **KL散度校准法**。-即通过计算KL散度（也称为**相对熵**，用以描述两个分布之间的差异）来评估量化前后的两个分布之间存在的差异，**搜索并选取KL散度最小的量化参数Z和S作为最终的结果**。


</code></pre>
</li>
</ol>
<h3 id="44-比特量化"><a class="markdownIt-Anchor" href="#44-比特量化"></a> 4.4 比特量化</h3>
<p><strong>根据存储一个权重元素所需的位数，可以将其分为8bit量化、4bit量化、2bit量化和1bit量化等。</strong></p>
<ul>
<li><strong>二进制神经网络</strong>。即在运行时具有二进制权重和激活的神经网络，以及在训练时计算参数的梯度。</li>
<li><strong>三元权重网络</strong>。即权重约束为+1,0和-1的神经网络。</li>
<li><strong>XNOR网络</strong>。即过滤器和卷积层的输入是二进制的。XNOR 网络主要使用二进制运算来近似卷积。</li>
</ul>
<h3 id="45-权重量化和权重激活量化"><a class="markdownIt-Anchor" href="#45-权重量化和权重激活量化"></a> 4.5 权重量化和权重激活量化</h3>
<p><strong>根据需要量化的参数可以分类两类-权重量化和权重激活量化</strong>。</p>
<ul>
<li><strong>权重量化</strong>，即仅仅需要对网络中的权重执行量化操作。由于网络的权重一般都保存下来了，因而我们可以提前根据权重获得相应的量化参数S和Z。由于仅仅对权重执行了量化，这种量化方法的压缩力度不是很大</li>
<li><strong>权重激活量化</strong>，即不仅对网络中的权重进行量化，还对激活值进行量化。由于激活层的范围通常不容易提前获得，因而需要在网络推理的过程中进行计算或者根据模型进行大致的预测</li>
</ul>
<h3 id="46-对数量化一种比较特殊的量化方法"><a class="markdownIt-Anchor" href="#46-对数量化一种比较特殊的量化方法"></a> 4.6 **对数量化，**一种比较特殊的量化方法。</h3>
<p>​	两个同底的幂指数进行相乘，那么等价于其指数相加，降低了计算强度。同时加法也被转变为索引计算。目前 nvdia gpu，x86、arm 三大平台上没有实现对数量化的加速库，但是目前已知海思 351X 系列芯片上使用了对数量化</p>
<h2 id="5-模型量化原理"><a class="markdownIt-Anchor" href="#5-模型量化原理"></a> 5、模型量化原理</h2>
<h3 id="51-原理详解"><a class="markdownIt-Anchor" href="#51-原理详解"></a> 5.1 原理详解</h3>
<p><strong>模型量化桥接了定点与浮点，建立了一种有效的数据映射关系，使得以较小的精度损失代价获得了较好的收益</strong>，要弄懂模型量化的原理就是要弄懂这种数据映射关系。<br>
浮点转换为定点的公式如下所示：</p>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019163959165.png" alt="image-20231019163959165"></p>
<p><strong>其中R表示输入的浮点数据，Q表示量化之后的定点数据，Z表示Zero Point的数值，S表示Scale的数值，我们可以根据S和Z这两个参数来确定这个映射关系</strong>。</p>
<p>求解S和Z有很多种方法，这里列举中其中的一种求解方式如下：</p>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019164222886.png" alt="image-20231019164222886"></p>
<h3 id="52-具体案例"><a class="markdownIt-Anchor" href="#52-具体案例"></a> 5.2 具体案例</h3>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019164247159.png" alt="image-20231019164247159"></p>
<h2 id="6-量化功能"><a class="markdownIt-Anchor" href="#6-量化功能"></a> 6、量化功能</h2>
<p>具体包括训练后动态量化、训练后静态量化和训练时量化。</p>
<h3 id="训练后动态量化"><a class="markdownIt-Anchor" href="#训练后动态量化"></a> 训练后动态量化。</h3>
<p>这是最简单的量化形式，其中权重被提前量化，而激活在推理过程中被动态量化。这种方法用于模型执行时间由从内存加载权重而不是计算矩阵乘法所支配的情况，这适用于批量较小的LSTM和Transformer类型。对整个模型应用动态量化只需要调用一次torch.quantization.quantize_dynamic()函数即可完成具体的细节请参考该量化教程。</p>
<p><strong>实现对某些层进行量化，量化后的模型只能用于推理验证，不能用作训练</strong></p>
<h3 id="训练后静态量化"><a class="markdownIt-Anchor" href="#训练后静态量化"></a> <strong>训练后静态量化。</strong></h3>
<p>这是最常用的量化形式，其中权重是提前量化的，并且基于在校准过程中观察模型的行为来预先计算激活张量的比例因子和偏差。CNN是一个典型的用例，训练后量化通常是在内存带宽和计算节省都很重要的情况下进行的。进<strong>行训练后量化的一般过程如下所示：</strong><br>
步骤1-准备模型：通过添加QuantStub和DeQuantStub模块，指定在何处显式量化和反量化激活值；确保不重复使用模块；将需要重新量化的任何操作转换为模块的模式；<br>
步骤2-将诸如conv + relu或conv + batchnorm + relu之类的组合操作融合在一起，以提高模型的准确性和性能；<br>
步骤3-指定量化方法的配置，例如选择对称或非对称量化以及MinMax或L2Norm校准技术；<br>
步骤4- 插入torch.quantization.prepare()模块来在校准期间观察激活张量；<br>
步骤5-使用校准数据集对模型执行校准操作；<br>
步骤6-使用torch.quantization.convert() 模块来转化模型，具体包括计算并存储每个激活张量要使用的比例和偏差值，并替换关键算子的量化实现等。</p>
<h3 id="训练时量化"><a class="markdownIt-Anchor" href="#训练时量化"></a> 训练时量化。</h3>
<p>在极少数情况下，训练后量化不能提供足够的准确性，可以插入torch.quantization.FakeQuantize()模块执行训练时量化。计算将在FP32中进行，但将值取整并四舍五入以模拟INT8的量化效果。具体的量化步骤如下所示：<br>
步骤1-准备模型：通过添加QuantStub和DeQuantStub模块，指定在何处显式量化和反量化激活值；确保不重复使用模块；将需要重新量化的任何操作转换为模块的模式；<br>
步骤2-将诸如conv + relu或conv + batchnorm + relu之类的组合操作融合在一起，以提高模型的准确性和性能；<br>
步骤3-指定伪量化方法的配置，例如选择对称或非对称量化以及MinMax或L2Norm校准技术；<br>
步骤4-插入torch.quantization.prepare_qat() 模块，该模块用来在训练过程中的模拟量化；<br>
步骤5-训练或者微调模型；<br>
步骤6-使用torch.quantization.convert() 模块来转化模型，具体包括计算并存储每个激活张量要使用的比例和偏差值，并替换关键算子的量化实现等。</p>
<p>量化步骤</p>
<p>![image-20231019153830100](./2023年10月19日-量化1/image-20231019153830100.png</p>
<p><img src="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/image-20231019161437726.png" alt="image-20231019161437726"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961%E4%BB%8B%E7%BB%8D/" data-id="cm8q1tfhd0008pcv45prr2jai" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%87%8F%E5%8C%96/" rel="tag">量化</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月12日-numpy总结" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/12/2023%E5%B9%B410%E6%9C%8812%E6%97%A5-numpy%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="post-time" datetime="2023-10-12T03:31:14.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">12</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/12/2023%E5%B9%B410%E6%9C%8812%E6%97%A5-numpy%E6%80%BB%E7%BB%93/">2023年10月12日 numpy总结</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1"><a class="markdownIt-Anchor" href="#1"></a> 1</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看数组结构</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看数组类型</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看数组元素个数</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看数组每个元素大小</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">重新设置shape</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">linspace函数</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logspace函数</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zeros函数</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eye函数</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/12/2023%E5%B9%B410%E6%9C%8812%E6%97%A5-numpy%E6%80%BB%E7%BB%93/" data-id="clrwazlqs00037ov48l257joo" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年9月27日-cuda编程1" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/" class="article-date">
  <time class="post-time" datetime="2023-09-26T17:26:45.000Z" itemprop="datePublished">
    <span class="post-month">9月</span><br/>
    <span class="post-day">27</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/">cuda编程1</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/62996995/answer/3369541594">总结</a></p>
<p>打印核函数的helloword</p>
<img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927013114531.png" alt="image-20230927013114531" style="zoom:25%;"> 
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927014405611.png" alt="image-20230927014405611"></p>
<img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927014434932.png" alt="image-20230927014434932" style="zoom:33%;">
<img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927014417233.png" alt="image-20230927014417233" style="zoom:33%;">  
<img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927014503416.png" alt="image-20230927014503416" style="zoom:33%;"> 
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927014754011.png" alt="image-20230927014754011"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927014804867.png" alt="image-20230927014804867"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927015027916.png" alt="image-20230927015027916"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927015059462.png" alt="image-20230927015059462"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927015218279.png" alt="image-20230927015218279"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927015258301.png" alt="image-20230927015258301"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927015307806.png" alt="image-20230927015307806"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927020206228.png" alt="image-20230927020206228"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927020351307.png" alt="image-20230927020351307"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927020513187.png" alt="image-20230927020513187"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927020754977.png" alt="image-20230927020754977"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927021106475.png" alt="image-20230927021106475"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927021212837.png" alt="image-20230927021212837"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927021546123.png" alt="image-20230927021546123"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927021555549.png" alt="image-20230927021555549"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927154421445.png" alt="image-20230927154421445"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927154702719.png" alt="image-20230927154702719"></p>
<p><img src="/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/image-20230927154740546.png" alt="image-20230927154740546"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/09/27/2023%E5%B9%B49%E6%9C%8827%E6%97%A5-cuda%E7%BC%96%E7%A8%8B1/" data-id="cmbhxnxay0003gov4dnhfgmy8" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cuda/" rel="tag">cuda</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/9/">&amp;laquo; pre</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/11/">next &amp;raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Weakliy_Blog</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>122</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>36</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="Github">
          Github
        </a>
      
    </div>

    <div class="friend-link">
      <h2>联系我</h2>
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2024 - 2025 Weakliy<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">首页</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">总览</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">xxx</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">xxxx</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>