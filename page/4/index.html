<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Weakliy_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Weakliy_Blog">
<meta property="og:url" content="https://shakewely.github.io/page/4/index.html">
<meta property="og:site_name" content="Weakliy_Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Weakliy">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Weakliy_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>73</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>16</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main">
  
    <article id="post-2023年11月7日-量化3-Question" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/" class="article-date">
  <time class="post-time" datetime="2023-11-07T12:25:22.000Z" itemprop="datePublished">
    <span class="post-month">11月</span><br/>
    <span class="post-day">07</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/">2023年11月7日 量化3 Question</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="1-为什么量化层少了acc却降低了"><a class="markdownIt-Anchor" href="#1-为什么量化层少了acc却降低了"></a> 1 为什么量化层少了，acc却降低了？</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quantized_model = torch.quantization.quantize_dynamic(model, &#123;nn.Linear&#125;, dtype=torch.qint8)</span><br></pre></td></tr></table></figure>
<p><img src="./2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/image-20231107202610901.png" alt="image-20231107202610901" /></p>
<p><img src="./2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/image-20231107202922407.png" alt="image-20231107202922407" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quantized_model = torch.quantization.quantize_dynamic(model, &#123;nn.Linear, nn.Conv2d&#125;, dtype=torch.qint8)</span><br></pre></td></tr></table></figure>
<p><img src="./2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/image-20231107202605391.png" alt="image-20231107202605391" /></p>
<p><img src="./2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/image-20231107202821307.png" alt="image-20231107202821307" /></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E9%87%8F%E5%8C%963-Question/" data-id="clrwazlr0000o7ov4d56p813a" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%87%8F%E5%8C%96/" rel="tag">量化</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年11月7日-深度学习报错日记" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%A5%E9%94%99%E6%97%A5%E8%AE%B0/" class="article-date">
  <time class="post-time" datetime="2023-11-07T12:02:19.000Z" itemprop="datePublished">
    <span class="post-month">11月</span><br/>
    <span class="post-day">07</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%A5%E9%94%99%E6%97%A5%E8%AE%B0/">2023年11月7日 深度学习报错日记</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li>
<p>NotImplementedError: Could not run ‘quantized::linear_prepack_fp16’ with arguments from the ‘CUDA’ backend.</p>
<p><strong>量化过程中使用到了一个不支持CUDA的操作。</strong></p>
</li>
<li>
<p>RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same</p>
<p><strong>没有明确指定模型应该在GPU上运行。你可以使用<code>model.to(device)</code>将模型移动到GPU上</strong></p>
</li>
<li>
<p>PIL.UnidentifiedImageError: cannot identify image file ‘F:\Dataset\PetImages\Cat\666.jpg’</p>
<p><strong>图片损坏</strong></p>
</li>
<li>
<p>collate_fn 参数 什么意思dataloader里的</p>
<p><strong>?</strong></p>
</li>
<li></li>
<li></li>
<li></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/11/07/2023%E5%B9%B411%E6%9C%887%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%A5%E9%94%99%E6%97%A5%E8%AE%B0/" data-id="clrwazlr1000q7ov430ep5euf" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月24日-TensorRT2" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT2/" class="article-date">
  <time class="post-time" datetime="2023-10-24T11:51:56.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">24</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT2/">2023年10月24日 transformer学习</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-什么是tensorrt"><a class="markdownIt-Anchor" href="#1-什么是tensorrt"></a> 1 什么是TensorRT</h2>
<h3 id="11-tensorrt介绍"><a class="markdownIt-Anchor" href="#11-tensorrt介绍"></a> 1.1 TensorRT介绍</h3>
<ul>
<li>TensorRT干啥的，能做什么</li>
<li>TensorRT与训练框架（Pytorch、TensorFlow）以及推理引擎（onnxruntime、openvino）的比较</li>
<li>学习TensorRT提前要会什么</li>
<li>什么人应该学TensorRT</li>
</ul>
<h3 id="12-基本概念和使用方式"><a class="markdownIt-Anchor" href="#12-基本概念和使用方式"></a> 1.2 基本概念和使用方式</h3>
<ul>
<li>支持模型、数据类型、支持的IO、支持的功能</li>
<li>TensorRT中context、engine、builder概念</li>
<li>环境搭建、运行环境</li>
</ul>
<h3 id="13-工作流程"><a class="markdownIt-Anchor" href="#13-工作流程"></a> 1.3 工作流程</h3>
<ul>
<li>python端API</li>
<li>C++端API</li>
<li>简单的demo</li>
</ul>
<h2 id="2-tensorrt完整流程"><a class="markdownIt-Anchor" href="#2-tensorrt完整流程"></a> 2 TensorRT完整流程</h2>
<h3 id="21-onnx转tensorrt"><a class="markdownIt-Anchor" href="#21-onnx转tensorrt"></a> 2.1 ONNX转TensorRT</h3>
<ul>
<li>parser方式转换模型</li>
<li>onnx2trt简单分析</li>
<li>graphsurgeon修改onnx网络</li>
<li>一些注意点</li>
</ul>
<h3 id="22-框架内使用tensorrt"><a class="markdownIt-Anchor" href="#22-框架内使用tensorrt"></a> 2.2 框架内使用tensorrt</h3>
<ul>
<li>torch_tensorrt介绍、使用</li>
<li>torch_tensorrt源码解析</li>
</ul>
<h2 id="3-tensorrt进阶"><a class="markdownIt-Anchor" href="#3-tensorrt进阶"></a> 3 TensorRT进阶</h2>
<h3 id="31-如何debug"><a class="markdownIt-Anchor" href="#31-如何debug"></a> 3.1 如何debug</h3>
<ul>
<li>精度问题debug（nan、精度不匹配）</li>
<li>网络可视化（netron、trt-explorer）</li>
<li>polygraphy（TensorRT官方提供的非常好的工具）</li>
</ul>
<h3 id="32-api搭建网络"><a class="markdownIt-Anchor" href="#32-api搭建网络"></a> 3.2 API搭建网络</h3>
<ul>
<li>API搭建网络基本方式、权重提取，这部分强烈建议看TensorRTx</li>
<li>explicit batch vs implicit batch</li>
</ul>
<h3 id="33-自定义插件plugin"><a class="markdownIt-Anchor" href="#33-自定义插件plugin"></a> 3.3 自定义插件plugin</h3>
<ul>
<li>如何写自定义plugin、Plugin中关键的API与注意点</li>
<li>自定义插件示例、集成plugin到trt中、参与trt序列化</li>
<li>plugin的生命周期、资源管理</li>
<li>dynamic-shape-plugin</li>
<li>Plugin的FP16和INT8</li>
</ul>
<h3 id="34-常见疑难杂症"><a class="markdownIt-Anchor" href="#34-常见疑难杂症"></a> 3.4 常见疑难杂症</h3>
<ul>
<li>各种log中的报错</li>
</ul>
<h2 id="4-tensorrt最佳使用指南"><a class="markdownIt-Anchor" href="#4-tensorrt最佳使用指南"></a> 4 TensorRT最佳使用指南</h2>
<h3 id="41-如何正确使用trtexec"><a class="markdownIt-Anchor" href="#41-如何正确使用trtexec"></a> 4.1 如何正确使用trtexec</h3>
<ul>
<li>trtexec基本用法</li>
<li>动态尺度、设置optimization profile以及注意点（min-opt-max）</li>
<li>trtexec源码解析</li>
</ul>
<h3 id="42-提升性能"><a class="markdownIt-Anchor" href="#42-提升性能"></a> 4.2 提升性能</h3>
<ul>
<li>多steam（重叠计算和数据拷贝的时间，增加GPU利用率）</li>
<li>多context（多线程推理）</li>
<li>多optimization profile</li>
<li>CUDA Graph（减少kernel launch时间）</li>
<li>Timing Cache（减少build时间）</li>
<li>Algorithm Selector</li>
</ul>
<h3 id="43-tensorrt转换相关"><a class="markdownIt-Anchor" href="#43-tensorrt转换相关"></a> 4.3 TensorRT转换相关</h3>
<ul>
<li>某些Layer选择的算法导致误差大，屏蔽掉该选择 tactic Source</li>
<li>更新权重refit功能（强化学习用的多）</li>
<li>构建期/运行期显存占用大（调整参数以及策略）</li>
</ul>
<h2 id="5-tensorrt量化"><a class="markdownIt-Anchor" href="#5-tensorrt量化"></a> 5 TensorRT量化</h2>
<h3 id="tensorrt-fp16"><a class="markdownIt-Anchor" href="#tensorrt-fp16"></a> TensorRT-FP16</h3>
<ul>
<li>fp16精度设置与使用</li>
<li>fp16常见问题</li>
</ul>
<h3 id="tensorrt-int8"><a class="markdownIt-Anchor" href="#tensorrt-int8"></a> TensorRT-INT8</h3>
<ul>
<li>int8使用</li>
<li>PTQ校准集</li>
<li>QAT量化</li>
</ul>
<h3 id="混合精度"><a class="markdownIt-Anchor" href="#混合精度"></a> 混合精度</h3>
<ul>
<li>fp32和fp16</li>
<li>fp16和int8</li>
</ul>
<h2 id="6-tensorrt拓展"><a class="markdownIt-Anchor" href="#6-tensorrt拓展"></a> 6 TensorRT拓展</h2>
<h3 id="61-tensorrt转换的几种方式"><a class="markdownIt-Anchor" href="#61-tensorrt转换的几种方式"></a> 6.1 TensorRT转换的几种方式</h3>
<ul>
<li>torch2trt</li>
<li>torchscript2trt</li>
<li>fx2trt</li>
</ul>
<h2 id="7-tensorrt实战"><a class="markdownIt-Anchor" href="#7-tensorrt实战"></a> 7 TensorRT实战</h2>
<h3 id="61-检测模型转换"><a class="markdownIt-Anchor" href="#61-检测模型转换"></a> 6.1 检测模型转换</h3>
<ul>
<li>SSD模型转TensorRT dynamic-shape</li>
<li>带有自定义DCN-OP的CenterNet转TensorRT</li>
</ul>
<h3 id="62-识别-分割-nlp类模型"><a class="markdownIt-Anchor" href="#62-识别-分割-nlp类模型"></a> 6.2 识别、分割、nlp类模型</h3>
<ul>
<li>stable diffusion</li>
<li>GPT</li>
</ul>
<h3 id="63-tensorrttriton-inference-server线上线下部署"><a class="markdownIt-Anchor" href="#63-tensorrttriton-inference-server线上线下部署"></a> 6.3 TensorRT+triton-inference-server线上/线下部署</h3>
<ul>
<li>基本部署教程</li>
<li>大规模TensorRT模型部署、多卡、模型调度</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/24/2023%E5%B9%B410%E6%9C%8824%E6%97%A5-TensorRT2/" data-id="clx4fkxnc0001n0v4h8yzdf2m" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorRT/" rel="tag">TensorRT</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月19日-量化2代码实现" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%962%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" class="article-date">
  <time class="post-time" datetime="2023-10-19T08:49:29.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">19</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%962%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">2023年10月19日 量化2代码实现</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://blog.csdn.net/kuan__/article/details/109539007">https://blog.csdn.net/kuan__/article/details/109539007</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42506418/article/details/131234818">https://blog.csdn.net/weixin_42506418/article/details/131234818</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljp1919/article/details/126231261?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%E4%BB%A3%E7%A0%81&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-126231261.142%5Ev96%5Epc_search_result_base6&amp;spm=1018.2226.3001.4187">https://blog.csdn.net/ljp1919/article/details/126231261?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=模型量化代码&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-126231261.142^v96^pc_search_result_base6&amp;spm=1018.2226.3001.4187</a></p>
<h4 id="训练后动态量化技术dynamic-quantization来将模型的权重从浮点精度例如32位浮点数转换为低精度整数类型例如8位整数"><a class="markdownIt-Anchor" href="#训练后动态量化技术dynamic-quantization来将模型的权重从浮点精度例如32位浮点数转换为低精度整数类型例如8位整数"></a> **训练后动态量化技术（dynamic quantization）来将模型的权重从浮点精度（例如32位浮点数）转换为低精度整数类型（例如8位整数）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quantized_model = torch.quantization.quantize_dynamic(model, &#123;nn.Linear, nn.Conv2d&#125;, dtype=torch.qint8)</span><br></pre></td></tr></table></figure>
<ol>
<li><code>model</code>: 这个变量应该是你想要进行量化的原始PyTorch模型，它可能是使用<code>torch.nn.Module</code>类定义的神经网络模型。</li>
<li><code>&#123;nn.Linear, nn.Conv2d&#125;</code>: 这个参数指定了你希望量化的模型层类型。在这个例子中，<code>nn.Linear</code>和<code>nn.Conv2d</code>表示对模型中的线性层和二维卷积层进行量化。
<ol>
<li><strong>线性层（Linear Layers）</strong>：<code>nn.Linear</code></li>
<li><strong>卷积层（Convolutional Layers）</strong>：<code>nn.Conv1d</code>, <code>nn.Conv2d</code>, <code>nn.Conv3d</code></li>
<li><strong>循环神经网络层（Recurrent Layers）</strong>：<code>nn.RNN</code>, <code>nn.LSTM</code>, <code>nn.GRU</code></li>
<li><strong>批归一化层（Batch Normalization Layers）</strong>：<code>nn.BatchNorm1d</code>, <code>nn.BatchNorm2d</code>, <code>nn.BatchNorm3d</code></li>
<li><strong>激活函数（Activation Functions）</strong>：<code>nn.ReLU</code>, <code>nn.LeakyReLU</code>, <code>nn.PReLU</code>, <code>nn.ReLU6</code>, 等等。</li>
<li><strong>池化层（Pooling Layers）</strong>：<code>nn.MaxPool1d</code>, <code>nn.MaxPool2d</code>, <code>nn.AvgPool1d</code>, <code>nn.AvgPool2d</code>, 等等。</li>
</ol>
</li>
<li><code>dtype=torch.qint8</code>: 这个参数指定了量化后的数据类型，这里是8位整数（qint8）。在推断时，量化模型将使用这种低精度整数类型进行计算。
<ol>
<li><strong><code>torch.qint8</code></strong>: 8位有符号整数。通常用于量化权重和激活值。</li>
<li><strong><code>torch.quint8</code></strong>: 8位无符号整数。通常用于量化正数的权重和激活值。</li>
<li><strong><code>torch.qint32</code></strong>: 32位有符号整数。通常用于量化权重和激活值。</li>
<li><strong><code>torch.float16</code></strong>: 16位浮点数。通常用于量化权重和激活值。不是整数量化，但比32位浮点数（<code>torch.float32</code>）占用更少内存。</li>
<li><strong><code>torch.bfloat16</code></strong>: 16位浮点数（Brain Floating Point）</li>
</ol>
</li>
</ol>
<h4 id="量化感知训练torchquantizationfakequantize-qat"><a class="markdownIt-Anchor" href="#量化感知训练torchquantizationfakequantize-qat"></a> <strong>量化感知训练</strong>torch.quantization.FakeQuantize QAT</h4>
<p><strong>get_default_qconfig</strong></p>
<p>​	在使用量化（quantization）技术时，PyTorch会改变模型的结构，并为每个权重参数添加量化相关的信息。因此需要重新写一个量化model</p>
<p>量化后的模型（quantized model）的state_dict的键（keys）与原始模型的state_dict的键不匹配。</p>
<p>使用<code>torch.quantization.quantize_dynamic()</code>对模型进行量化时，它会在state_dict中添加与量化参数相关的额外键（比如scale、zero_point、dtype和_packed_params）。</p>
<p>为了解决这个问题，需要修改加载量化模型的代码。在加载量化模型的state_dict时，应该指定<code>map_location</code>参数，将量化模型的参数映射到适当的设备（GPU或CPU）（设备不匹配的错误）。此外，你需要传递<code>strict=False</code>参数给<code>load_state_dict()</code>，忽略量化模型state_dict中存在的额外键。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%962%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" data-id="clrwazlqu00057ov4bn1tbi46" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%87%8F%E5%8C%96/" rel="tag">量化</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月19日-量化1" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/" class="article-date">
  <time class="post-time" datetime="2023-10-19T07:37:02.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">19</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/">2023年10月19日 量化1</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://blog.csdn.net/purple_love/article/details/127254449?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_utm_term~default-4-127254449-blog-127521819.235%5Ev38%5Epc_relevant_sort_base2&amp;spm=1001.2101.3001.4242.3&amp;utm_relevant_index=5">https://blog.csdn.net/purple_love/article/details/127254449?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_utm_term~default-4-127254449-blog-127521819.235^v38^pc_relevant_sort_base2&amp;spm=1001.2101.3001.4242.3&amp;utm_relevant_index=5</a></p>
<h2 id="1-模型量化是什么"><a class="markdownIt-Anchor" href="#1-模型量化是什么"></a> 1、<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96&amp;spm=1001.2101.3001.7020">模型量化</a>是什么？</h2>
<p>简而言之，所谓的模型量化就是将浮点存储（运算）转换为整型存储（运算）的一种<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9&amp;spm=1001.2101.3001.7020">模型压缩</a>技术。<strong>简单直白点讲，即原来表示一个权重需要使用float32表示，量化后只需要使用int8来表示就可以啦，仅仅这一个操作，我们就可以获得接近4倍的网络加速</strong>！</p>
<h2 id="2-为什么需要做模型量化模型量化动机是什么"><a class="markdownIt-Anchor" href="#2-为什么需要做模型量化模型量化动机是什么"></a> 2、为什么需要做模型量化？模型量化动机是什么？</h2>
<ul>
<li><strong>更少的存储开销和带宽需求</strong>。即使用更少的比特数存储数据，有效减少应用对存储资源的依赖，但现代系统往往拥有相对丰富的存储资源，这一点已经不算是采用量化的主要动机；</li>
<li><strong>更快的计算速度</strong>。即对大多数处理器而言，整型运算的速度一般（但不总是）</li>
</ul>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019161721639.png" alt="image-20231019161721639" /></p>
<pre><code>**FP32乘法运算的能耗是INT8乘法运算能耗的18.5倍，芯片占用面积则是int8的27.3倍**，

**尚可接受的精度损失**。**即量化相当于对模型权重引入噪声，所幸CNN本身对噪声不敏感（在模型训练过程中，模拟量化所引入的权重加噪还有利于防止过拟合），在合适的比特数下量化后的模型并不会带来很严重的精度损失**。
</code></pre>
<h2 id="3-模型量化的方案"><a class="markdownIt-Anchor" href="#3-模型量化的方案"></a> 3、模型量化的方案</h2>
<ol>
<li><code>data free</code>：不使用校准集，传统的方法直接将浮点参数转化成量化数，使用上非常简单，但是一般会带来很大的精度损失，但是高通最新的论文 <code>DFQ</code> 不使用校准集也得到了很高的精度。</li>
<li><code>calibration</code>：基于校准集方案，通过输入少量真实数据进行统计分析。很多芯片厂商都提供这样的功能，如 <code>tensorRT</code>、高通、海思、地平线、寒武纪</li>
<li><code>finetune</code>：基于训练 <code>finetune</code> 的方案，将量化误差在训练时仿真建模，调整权重使其更适合量化。好处是能带来更大的精度提升，缺点是要修改模型训练代码，开发周期较长。</li>
</ol>
<h2 id="4-模型量化分类"><a class="markdownIt-Anchor" href="#4-模型量化分类"></a> 4、模型量化分类</h2>
<h3 id="41-线性量化"><a class="markdownIt-Anchor" href="#41-线性量化"></a> 4.1 线性量化</h3>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019161927584.png" alt="image-20231019161927584" /></p>
<p>​	<strong>q 表示的是原始的float32数值；</strong><br />
​	<strong>Z表示的是float32数值的偏移量，在很多地方又叫Zero Point；</strong><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019162041599.png" alt="image-20231019162041599" /></p>
<p>**	S表示的是float32的缩放因子，在很多地方又叫Scale；**</p>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019162119689.png" alt="image-20231019162119689" />	<strong>Round(⋅) 表示的是四舍五入近似取整的数学函数，除了四舍五入，使用向上或者向下取整也是可以的；</strong><br />
<strong>r表示的是量化后的一个整数值。</strong></p>
<p><strong>根据参数 Z 是否为零可以将线性量化分为两类—即对称量化和非对称量化</strong>。</p>
<h4 id="411-对称量化"><a class="markdownIt-Anchor" href="#411-对称量化"></a> 4.1.1 对称量化</h4>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019162306723.png" alt="image-20231019162306723" /></p>
<p>​	使用一个映射公式将输入数据映射到[-128,127]的范围内</p>
<p>在对称量化中，r 是用有符号的整型数值(int8)来表示的，此时 Z=0，且 q=0时恰好有r=0。在对称量化中，我们可以取Z=0，S的取值可以使用如下的公式，也可以采用其它的公式。其中，n 是用来表示该数值的位宽，x 是数据集的总体样本。</p>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019162300497.png" alt="image-20231019162300497" /></p>
<h4 id="412-非对称量化"><a class="markdownIt-Anchor" href="#412-非对称量化"></a> 4.1.2 非对称量化</h4>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019162349206.png" alt="image-20231019162349206" /></p>
<p>​	使用一个映射公式将输入数据映射到[0,255]的范围内</p>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019162416109.png" alt="image-20231019162416109" /></p>
<h3 id="43-在线量化和离线量化"><a class="markdownIt-Anchor" href="#43-在线量化和离线量化"></a> 4.3 在线量化和离线量化</h3>
<p><strong>根据激活值的量化方式，可以分为在线（online）量化和离线（offline）量化。</strong></p>
<ul>
<li><strong>在线量化</strong>，即指激活值的S和Z<strong>在实际推断过程中根据实际的激活值动态计算</strong>；</li>
<li><strong>离线量化</strong>，即指<strong>提前确定好</strong>激活值的S和Z；</li>
</ul>
<p>由于不需要动态计算量化参数，通常离线量化的推断速度更快些，通常通过以下的三种方法来确定相关的量化参数。</p>
<ul>
<li>
<p><strong>指数平滑法</strong>。即将校准数据集送入模型，收集每个量化层的输出特征图，计算每个batch的S和Z值，并<strong>通过指数平滑法来更新S和Z值</strong>。</p>
</li>
<li>
<p><strong>直方图截断法</strong>。即在计算量化参数Z和S的过程中，由于<strong>有的特征图</strong>会出现偏离较远的奇异值，导致max非常大，所以可以通过直方图截取的形式，比如<strong>抛弃最大的前1%数据，以前1%分界点的数值作为max计算量化参数</strong>。</p>
</li>
<li>
<p><strong>KL散度校准法</strong>。-即通过计算KL散度（也称为<strong>相对熵</strong>，用以描述两个分布之间的差异）来评估量化前后的两个分布之间存在的差异，<strong>搜索并选取KL散度最小的量化参数Z和S作为最终的结果</strong>。</p>
</li>
</ul>
<h3 id="44-比特量化"><a class="markdownIt-Anchor" href="#44-比特量化"></a> 4.4 比特量化</h3>
<p><strong>根据存储一个权重元素所需的位数，可以将其分为8bit量化、4bit量化、2bit量化和1bit量化等。</strong></p>
<ul>
<li><strong>二进制神经网络</strong>。即在运行时具有二进制权重和激活的神经网络，以及在训练时计算参数的梯度。</li>
<li><strong>三元权重网络</strong>。即权重约束为+1,0和-1的神经网络。</li>
<li><strong>XNOR网络</strong>。即过滤器和卷积层的输入是二进制的。XNOR 网络主要使用二进制运算来近似卷积。</li>
</ul>
<h3 id="45-权重量化和权重激活量化"><a class="markdownIt-Anchor" href="#45-权重量化和权重激活量化"></a> 4.5 权重量化和权重激活量化</h3>
<p><strong>根据需要量化的参数可以分类两类-权重量化和权重激活量化</strong>。</p>
<ul>
<li><strong>权重量化</strong>，即仅仅需要对网络中的权重执行量化操作。由于网络的权重一般都保存下来了，因而我们可以提前根据权重获得相应的量化参数S和Z。由于仅仅对权重执行了量化，这种量化方法的压缩力度不是很大</li>
<li><strong>权重激活量化</strong>，即不仅对网络中的权重进行量化，还对激活值进行量化。由于激活层的范围通常不容易提前获得，因而需要在网络推理的过程中进行计算或者根据模型进行大致的预测</li>
</ul>
<h3 id="46-对数量化一种比较特殊的量化方法"><a class="markdownIt-Anchor" href="#46-对数量化一种比较特殊的量化方法"></a> 4.6 **对数量化，**一种比较特殊的量化方法。</h3>
<p>​	两个同底的幂指数进行相乘，那么等价于其指数相加，降低了计算强度。同时加法也被转变为索引计算。目前 nvdia gpu，x86、arm 三大平台上没有实现对数量化的加速库，但是目前已知海思 351X 系列芯片上使用了对数量化</p>
<h2 id="5-模型量化原理"><a class="markdownIt-Anchor" href="#5-模型量化原理"></a> 5、模型量化原理</h2>
<h3 id="51-原理详解"><a class="markdownIt-Anchor" href="#51-原理详解"></a> 5.1 原理详解</h3>
<p><strong>模型量化桥接了定点与浮点，建立了一种有效的数据映射关系，使得以较小的精度损失代价获得了较好的收益</strong>，要弄懂模型量化的原理就是要弄懂这种数据映射关系。<br />
浮点转换为定点的公式如下所示：</p>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019163959165.png" alt="image-20231019163959165" /></p>
<p><strong>其中R表示输入的浮点数据，Q表示量化之后的定点数据，Z表示Zero Point的数值，S表示Scale的数值，我们可以根据S和Z这两个参数来确定这个映射关系</strong>。</p>
<p>求解S和Z有很多种方法，这里列举中其中的一种求解方式如下：</p>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019164222886.png" alt="image-20231019164222886" /></p>
<h3 id="52-具体案例"><a class="markdownIt-Anchor" href="#52-具体案例"></a> 5.2 具体案例</h3>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019164247159.png" alt="image-20231019164247159" /></p>
<h2 id="6-量化功能"><a class="markdownIt-Anchor" href="#6-量化功能"></a> 6、量化功能</h2>
<p>具体包括训练后动态量化、训练后静态量化和训练时量化。</p>
<h3 id="训练后动态量化"><a class="markdownIt-Anchor" href="#训练后动态量化"></a> 训练后动态量化。</h3>
<p>这是最简单的量化形式，其中权重被提前量化，而激活在推理过程中被动态量化。这种方法用于模型执行时间由从内存加载权重而不是计算矩阵乘法所支配的情况，这适用于批量较小的LSTM和Transformer类型。对整个模型应用动态量化只需要调用一次torch.quantization.quantize_dynamic()函数即可完成具体的细节请参考该量化教程。</p>
<p><strong>实现对某些层进行量化，量化后的模型只能用于推理验证，不能用作训练</strong></p>
<h3 id="训练后静态量化"><a class="markdownIt-Anchor" href="#训练后静态量化"></a> <strong>训练后静态量化。</strong></h3>
<p>这是最常用的量化形式，其中权重是提前量化的，并且基于在校准过程中观察模型的行为来预先计算激活张量的比例因子和偏差。CNN是一个典型的用例，训练后量化通常是在内存带宽和计算节省都很重要的情况下进行的。进<strong>行训练后量化的一般过程如下所示：</strong><br />
步骤1-准备模型：通过添加QuantStub和DeQuantStub模块，指定在何处显式量化和反量化激活值；确保不重复使用模块；将需要重新量化的任何操作转换为模块的模式；<br />
步骤2-将诸如conv + relu或conv + batchnorm + relu之类的组合操作融合在一起，以提高模型的准确性和性能；<br />
步骤3-指定量化方法的配置，例如选择对称或非对称量化以及MinMax或L2Norm校准技术；<br />
步骤4- 插入torch.quantization.prepare()模块来在校准期间观察激活张量；<br />
步骤5-使用校准数据集对模型执行校准操作；<br />
步骤6-使用torch.quantization.convert() 模块来转化模型，具体包括计算并存储每个激活张量要使用的比例和偏差值，并替换关键算子的量化实现等。</p>
<h3 id="训练时量化"><a class="markdownIt-Anchor" href="#训练时量化"></a> 训练时量化。</h3>
<p>在极少数情况下，训练后量化不能提供足够的准确性，可以插入torch.quantization.FakeQuantize()模块执行训练时量化。计算将在FP32中进行，但将值取整并四舍五入以模拟INT8的量化效果。具体的量化步骤如下所示：<br />
步骤1-准备模型：通过添加QuantStub和DeQuantStub模块，指定在何处显式量化和反量化激活值；确保不重复使用模块；将需要重新量化的任何操作转换为模块的模式；<br />
步骤2-将诸如conv + relu或conv + batchnorm + relu之类的组合操作融合在一起，以提高模型的准确性和性能；<br />
步骤3-指定伪量化方法的配置，例如选择对称或非对称量化以及MinMax或L2Norm校准技术；<br />
步骤4-插入torch.quantization.prepare_qat() 模块，该模块用来在训练过程中的模拟量化；<br />
步骤5-训练或者微调模型；<br />
步骤6-使用torch.quantization.convert() 模块来转化模型，具体包括计算并存储每个激活张量要使用的比例和偏差值，并替换关键算子的量化实现等。</p>
<p>量化步骤</p>
<p>![image-20231019153830100](./2023年10月19日-量化1/image-20231019153830100.png</p>
<p><img src="./2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/image-20231019161437726.png" alt="image-20231019161437726" /></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/19/2023%E5%B9%B410%E6%9C%8819%E6%97%A5-%E9%87%8F%E5%8C%961/" data-id="clrwazlqw000a7ov4f3yzcclv" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%87%8F%E5%8C%96/" rel="tag">量化</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月12日-TensorRT1" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/12/2023%E5%B9%B410%E6%9C%8812%E6%97%A5-TensorRT1/" class="article-date">
  <time class="post-time" datetime="2023-10-12T12:23:17.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">12</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/12/2023%E5%B9%B410%E6%9C%8812%E6%97%A5-TensorRT1/">2023年10月12日 TensorRT1</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="什么是tensorrt"><a class="markdownIt-Anchor" href="#什么是tensorrt"></a> <strong>什么是TensorRT</strong></h2>
<p>TensorRT是可以在<strong>NVIDIA</strong>各种<strong>GPU硬件平台</strong>下运行的一个<strong>C++推理框架</strong>。我们利用Pytorch</p>
<p>训练好的模型，可以转化为TensorRT的格式，然后利用TensorRT推理引擎去运行我们这个模型，从而提升这个模型在英伟达GPU上运行的速度。速度提升的比例是<strong>比较可观</strong>的。</p>
<h3 id="什么是计算能力compute-capability"><a class="markdownIt-Anchor" href="#什么是计算能力compute-capability"></a> 什么是计算能力(Compute Capability)</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">后面	</span><br></pre></td></tr></table></figure>
<img src="./2023年10月12日-TensorRT1/image-20231012202620295.png" alt="image-20231012202620295" style="zoom:50%;" />
<h2 id="tensorrt的加速效果怎么样"><a class="markdownIt-Anchor" href="#tensorrt的加速效果怎么样"></a> <strong>TensorRT的加速效果怎么样</strong></h2>
<p>加速效果取决于模型的类型和大小，也取决于我们所使用的显卡类型。</p>
<p>TensorRT所做的优化也是<strong>基于GPU</strong>进行优化，当然也是更喜欢那种一大块一大块的矩阵运算，尽量直通到底。因此对于通道数比较多的卷积层和反卷积层，优化力度是比较大的；</p>
<p>如果是比较繁多复杂的各种细小op操作**(例如reshape、gather、split等)，那么TensorRT的优化力度就没有那么夸张了。**</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">所以在转onnx的时候需要对模型进行修改，减少reshape等</span><br></pre></td></tr></table></figure>
<h3 id="为什么能加速"><a class="markdownIt-Anchor" href="#为什么能加速"></a> 为什么能加速？</h3>
<ul>
<li>算子融合(层与张量融合)：简单来说就是通过融合一些计算op或者去掉一些多余op来减少数据流通次数以及显存的频繁使用来提速</li>
<li>量化：量化即IN8量化或者FP16以及TF32等不同于常规FP32精度的使用，这些精度可以显著提升模型执行速度并且不会保持原先模型的精度</li>
<li>内核自动调整：根据不同的显卡构架、SM数量、内核频率等(例如1080TI和2080TI)，选择不同的优化策略以及计算方式，寻找最合适当前构架的计算方式</li>
<li>动态张量显存：我们都知道，显存的开辟和释放是比较耗时的，通过调整一些策略可以减少模型中这些操作的次数，从而可以减少模型运行的时间</li>
<li>多流执行：使用CUDA中的stream技术，最大化实现并行操作</li>
</ul>
<h3 id="安装tensorrt"><a class="markdownIt-Anchor" href="#安装tensorrt"></a> 安装tensorRT</h3>
<h4 id="ubuntu1804"><a class="markdownIt-Anchor" href="#ubuntu1804"></a> Ubuntu1804</h4>
<p>1 下载了CUDA12.0，TRT8.6.1 但是cuDNN 没有与Ubuntu1804对应的版本</p>
<p>2</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/12/2023%E5%B9%B410%E6%9C%8812%E6%97%A5-TensorRT1/" data-id="clrwazlqp00017ov4f4vb9qnt" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorRT/" rel="tag">TensorRT</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月12日-numpy总结" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/12/2023%E5%B9%B410%E6%9C%8812%E6%97%A5-numpy%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="post-time" datetime="2023-10-12T03:31:14.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">12</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/12/2023%E5%B9%B410%E6%9C%8812%E6%97%A5-numpy%E6%80%BB%E7%BB%93/">2023年10月12日 numpy总结</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1"><a class="markdownIt-Anchor" href="#1"></a> 1</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看数组结构</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看数组类型</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看数组元素个数</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看数组每个元素大小</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">重新设置shape</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">linspace函数</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logspace函数</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zeros函数</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eye函数</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/12/2023%E5%B9%B410%E6%9C%8812%E6%97%A5-numpy%E6%80%BB%E7%BB%93/" data-id="clrwazlqs00037ov48l257joo" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月7日-langchain学习" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/" class="article-date">
  <time class="post-time" datetime="2023-10-07T12:15:13.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">07</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/">2023年10月7日 langchain学习</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-什么是langchain"><a class="markdownIt-Anchor" href="#1-什么是langchain"></a> 1、什么是LangChain</h2>
<p>LangChain是一个开源框架，允许从事人工智能的开发者将例如GPT-4的大语言模型与外部计算和数据来源结合起来。</p>
<h2 id="2-三个重要概念"><a class="markdownIt-Anchor" href="#2-三个重要概念"></a> 2、三个重要概念</h2>
<ul>
<li><strong>Components</strong></li>
</ul>
<p>-LLM Wrapper：包装器，允许我们连接到大语言模型，例如GPT-4或HuggingFace的模型。</p>
<p>-Prompt Templates：提示模板，使我们不必对文本进行硬编码，而文本是LLM的输入。</p>
<p>-Indexes for relevant information retrieval：相关内容的索引，允许我们为LLM提取相关信息。</p>
<ul>
<li><strong>Chains</strong></li>
</ul>
<p>允许我们将多个组件组合在一起，以解决一个特定的任务，并建立一个完整的LLM应用程序。</p>
<ul>
<li><strong>Agents</strong></li>
</ul>
<p>允许LLM与外部API互动。</p>
<h2 id="3-原理"><a class="markdownIt-Anchor" href="#3-原理"></a> 3、原理</h2>
<p>​	将你的文件切成小块，把这些小块存储在一个矢量数据库中，这些块被存储为<strong>embedding</strong>，意味着它们是文本的矢量表示。</p>
<h3 id="pipeline执行流程"><a class="markdownIt-Anchor" href="#pipeline执行流程"></a> <strong>pipeline执行流程：</strong></h3>
<p>&gt;&gt;一个用户提出了初始问题。</p>
<p>&gt;&gt;然后，这个问题被发送到大语言模型，并将该问题的向量表示在向量数据库中做相似性搜索。</p>
<p>&gt;&gt;获取相关的信息块，将其反馈给大语言模型。</p>
<p>&gt;&gt;大语言模型通过初始问题和来自矢量数据库的相关信息，提供一个答案或采取一个行动。</p>
<p><img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231117001131635.png" alt="image-20231117001131635"></p>
<h2 id="4-开始使用"><a class="markdownIt-Anchor" href="#4-开始使用"></a> 4、开始使用</h2>
<p>安装相应的库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python-dotenv==1.0.0</span><br><span class="line">langchain==0.0.137</span><br><span class="line">pinecone-client==2.2.1</span><br></pre></td></tr></table></figure>
<p>具体操作参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/644500258">https://zhuanlan.zhihu.com/p/644500258</a></p>
<h2 id="5-问题梳理"><a class="markdownIt-Anchor" href="#5-问题梳理"></a> 5、问题梳理</h2>
<p>模块</p>
<p><img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007201607930.png" alt="image-20231007201607930"></p>
<h3 id="model-io"><a class="markdownIt-Anchor" href="#model-io"></a> model I/O</h3>
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007201707572.png" alt="image-20231007201707572" style="zoom:50%;">
<h3 id="prompt"><a class="markdownIt-Anchor" href="#prompt"></a> prompt</h3>
<h5 id="tempplate"><a class="markdownIt-Anchor" href="#tempplate"></a> tempplate</h5>
<p>提示词组合</p>
<h5 id="selecter"><a class="markdownIt-Anchor" href="#selecter"></a> selecter</h5>
<p>选择语言模型？</p>
<h4 id="language-model"><a class="markdownIt-Anchor" href="#language-model"></a> language model</h4>
<h5 id="llm"><a class="markdownIt-Anchor" href="#llm"></a> LLM</h5>
<p>续写类</p>
<h5 id="chat"><a class="markdownIt-Anchor" href="#chat"></a> Chat</h5>
<p>对话类</p>
<p>output parsers</p>
<p>josn</p>
<p>structured</p>
<p>结构化</p>
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007202210282.png" alt="image-20231007202210282" style="zoom:50%;">
<p>data connection</p>
<p>向量数据库</p>
<p>vector</p>
<p>embedding</p>
<p>向量化</p>
<p>memory self-hosted baas</p>
<p>存储位置</p>
<p>document loaders</p>
<p>数据来源</p>
<p>document transfomers</p>
<p>文本处理切片</p>
<p>文本数量text</p>
<p>字符数量code 代码片</p>
<p>token里去写</p>
<p>1000token=3/4词/character</p>
<p>document retrievers</p>
<p>vector DB数据库</p>
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007203321204.png" alt="image-20231007203321204" style="zoom:50%;">
<p>memory以前的数据，记录回答</p>
<p>vector DB</p>
<p>Buffer</p>
<p>缓冲区</p>
<p>KV DB</p>
<p>key-value数据存储</p>
<p>SQL DB</p>
<p>chains 串联</p>
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007203552182.png" alt="image-20231007203552182" style="zoom:50%;">
<p>sequential</p>
<p>再chain串联</p>
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007203702914.png" alt="image-20231007203702914" style="zoom:25%;">
<p>与其他的串联</p>
<p>foundational LLM</p>
<p>？？？ memory</p>
<p>conversational QA</p>
<p>问答/问问题？</p>
<p>retrieval QA</p>
<p>？？</p>
<p>document</p>
<p>文件串联</p>
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007203903160.png" alt="image-20231007203903160" style="zoom:50%;">
<p>思考链路 承接工作</p>
<p>抽出问题？优化？单独求解？</p>
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007204100627.png" alt="image-20231007204100627" style="zoom: 33%;">
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007204106824.png" alt="image-20231007204106824" style="zoom:33%;">
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007204300244.png" alt="image-20231007204300244" style="zoom:50%;">
<p>web搜索？</p>
<img src="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/image-20231007204433608.png" alt="image-20231007204433608" style="zoom:50%;">
<p>langsmith</p>
<p>记录</p>
<p>console</p>
<p>custom</p>
<p>日志记录？</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-langchain%E5%AD%A6%E4%B9%A0/" data-id="clrwazlqw000b7ov4765h8718" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-简历" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/07/%E7%AE%80%E5%8E%86/" class="article-date">
  <time class="post-time" datetime="2023-10-07T12:09:50.257Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">07</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>人工智能：</p>
<p>​	熟悉机器学习、深度学习原理，用深度神经网络实现过简单的深度学习系统</p>
<p>​	熟悉多种深度神经网络模型，了解<strong>CNN</strong>、<strong>RNN</strong>、<strong>LSTM</strong>、<strong>GAN</strong>模型原理</p>
<p>​	进行过算法模型效果分析，及参数调优；接触过模型压缩技术（剪枝、量化、知识蒸馏、权重共享等），</p>
<p>​	语言：熟悉python，能够使用pytorch, numpy,pillow的用于深度学习的库；学过C，C++；了解过cuda编程，onnx模型以及tensorRT</p>
<p>​	对数据敏感，能够进行特征使用、特征获取、特征处理、特征选择和特征监控等</p>
<p>​	了解AIGC，使用过stable diffusion等AI绘画模型，并根据个人的的使用需求，使用过control-net模型、进行过lora模型训练等</p>
<p>​	了解过ChatGPT/ChatGLM/LangChain等大模型开发技术栈</p>
<p>项目经历：</p>
<p>​	参与过茶汤视觉分析大创项目，负责项目模型编写、训练、调优以及部署；并于项目开发基于flask框架的小程序api</p>
<p>​	参与校数据开放大赛，负责项目中药识别与分类的数据预处理以及基于PyQt5的客户端界面编写</p>
<p>其他：</p>
<p>​	已过英语四级<br />
​	个人博客:<a href="https://shakewely.github.io">https://shakewely.github.io</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/07/%E7%AE%80%E5%8E%86/" data-id="clrwazlrl003x7ov4esxwbu6x" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2023年10月7日-c-实践" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-c-%E5%AE%9E%E8%B7%B5/" class="article-date">
  <time class="post-time" datetime="2023-10-07T10:43:42.000Z" itemprop="datePublished">
    <span class="post-month">10月</span><br/>
    <span class="post-day">07</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-c-%E5%AE%9E%E8%B7%B5/">c++实践</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Cxiazaiyu/article/details/108937936">https://blog.csdn.net/Cxiazaiyu/article/details/108937936</a></p>
<h2 id="1头文件保护"><a class="markdownIt-Anchor" href="#1头文件保护"></a> 1.头文件保护</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#ifndef MAINWINDOW_H</span><br><span class="line">#define MAINWINDOW_H</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#endif MAINWINDOW_H</span><br></pre></td></tr></table></figure>
<ol>
<li><code>#ifndef MAINWINDOW_H</code>: 这行代码以 <code>#ifndef</code> 开头，它的作用是检查是否已经定义了名为 <code>MAINWINDOW_H</code> 的宏。如果之前未定义，就会执行接下来的代码块，否则会跳过这个代码块。</li>
<li><code>#define MAINWINDOW_H</code>: 这行代码定义了一个名为 <code>MAINWINDOW_H</code> 的宏。宏的作用是在代码中创建一个标记，以防止多次包含同一个头文件。这样可以避免头文件的重复包含，从而提高编译效率并防止潜在的编译错误。</li>
</ol>
<h2 id="2-宏"><a class="markdownIt-Anchor" href="#2-宏"></a> 2. 宏</h2>
<p><code>Q_OBJECT</code> 宏</p>
<h2 id="3函数"><a class="markdownIt-Anchor" href="#3函数"></a> 3.函数</h2>
<h3 id="1"><a class="markdownIt-Anchor" href="#1"></a> 1</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Example obj(42); //创建Example(int x) : mymember(x) &#123;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">Example obj(42); //创建</span><br></pre></td></tr></table></figure>
<p>创建<code>Example</code> 类的对象时，用传递给它的整数参数 <code>x</code> 来初始化对象的成员变量 <code>mymember</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Example</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x</span>):</span><br><span class="line">        self.mymember = x</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="2"><a class="markdownIt-Anchor" href="#2"></a> 2</h3>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MainWindow::<span class="built_in">MainWindow</span>(QWidget *parent) : <span class="built_in">QMainWindow</span>(parent)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QMainWindow, QWidget</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MainWindow</span>(<span class="title class_ inherited__">QMainWindow</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        构造函数的声明，指定了函数名称、参数列表和初始化方法。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        :param parent: 可选的父对象，默认为None，用于管理对象的父子关系。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(MainWindow, self).__init__(parent)  <span class="comment"># 调用父类 QMainWindow 的构造函数</span></span><br><span class="line">        <span class="comment"># 在构造函数中可以进行其他的初始化操作</span></span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法：</span></span><br><span class="line"><span class="comment"># 创建一个父对象（QWidget），然后创建 MainWindow 对象并传递父对象</span></span><br><span class="line">parent_widget = QWidget()</span><br><span class="line">main_window = MainWindow(parent=parent_widget)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2023/10/07/2023%E5%B9%B410%E6%9C%887%E6%97%A5-c-%E5%AE%9E%E8%B7%B5/" data-id="clrwazlqv00077ov48dbr6gvc" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/c/" rel="tag">c++</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/3/">&amp;laquo; pre</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/5/">next &amp;raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Weakliy_Blog</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>73</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>16</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="Github">
          Github
        </a>
      
    </div>

    <div class="friend-link">
      <h2>联系我</h2>
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2023 - 2024 Weakliy<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">首页</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">总览</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">xxx</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">xxxx</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>