<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Weakliy_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Weakliy_Blog">
<meta property="og:url" content="https://shakewely.github.io/page/5/index.html">
<meta property="og:site_name" content="Weakliy_Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Weakliy">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Weakliy_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>115</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>33</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main">
  
    <article id="post-2025年4月4日-triton" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/04/02/2025%E5%B9%B44%E6%9C%884%E6%97%A5-triton/" class="article-date">
  <time class="post-time" datetime="2025-04-02T13:45:53.000Z" itemprop="datePublished">
    <span class="post-month">4月</span><br/>
    <span class="post-day">02</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/04/02/2025%E5%B9%B44%E6%9C%884%E6%97%A5-triton/">2025年4月4日 triton</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/684473453">https://zhuanlan.zhihu.com/p/684473453</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/703256080">https://zhuanlan.zhihu.com/p/703256080</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/04/02/2025%E5%B9%B44%E6%9C%884%E6%97%A5-triton/" data-id="cmanj8o26000nlcv4hdsi2bjg" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl%E3%80%81infer/" rel="tag">dl、infer</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-算法设计" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/31/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/" class="article-date">
  <time class="post-time" datetime="2025-03-31T13:50:35.913Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">31</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="动态规划"><a class="markdownIt-Anchor" href="#动态规划"></a> 动态规划</h2>
<ul>
<li>暴力穷举
<ul>
<li>记录避免重复</li>
<li>
<img src="/2025/03/31/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/image-20250331215153891.png" alt="image-20250331215153891" style="zoom:33%;">
</li>
</ul>
</li>
<li>方向进行
<ul>
<li>
<img src="/2025/03/31/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/image-20250331215203800.png" alt="image-20250331215203800" style="zoom:33%;">
</li>
</ul>
</li>
</ul>
<h2 id="分子法"><a class="markdownIt-Anchor" href="#分子法"></a> 分子法</h2>
<img src="/2025/03/31/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/image-20250331215909614.png" alt="image-20250331215909614" style="zoom:50%;">
<ul>
<li>分 二分</li>
<li>治 递归</li>
<li>处理 子问题合并</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/31/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1/" data-id="cmc9s779y00022ov4bcfddpu2" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年4月16日-TensorRT2export汇总" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/16/2025%E5%B9%B44%E6%9C%8816%E6%97%A5-TensorRT2export%E6%B1%87%E6%80%BB/" class="article-date">
  <time class="post-time" datetime="2025-03-16T09:30:04.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">16</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/16/2025%E5%B9%B44%E6%9C%8816%E6%97%A5-TensorRT2export%E6%B1%87%E6%80%BB/">2023年11月16日 TensorRT推理汇总</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>去</p>
<h3 id><a class="markdownIt-Anchor" href="#"></a> </h3>
<h1 id="流程"><a class="markdownIt-Anchor" href="#流程"></a> 流程</h1>
<p><strong>“ONNX → TensorRT Engine → 加载引擎文件并反序列化为可执行模型 → 分配输入输出 → 推理执行 → 拷出结果 → 后处理”</strong></p>
<blockquote>
<ol>
<li>？反序列化为可执行模型</li>
<li>？？ 创建执行上下文（IExecutionContext）</li>
</ol>
</blockquote>
<h2 id="1-exe-导出"><a class="markdownIt-Anchor" href="#1-exe-导出"></a> 1 Exe 导出</h2>
<p><strong>加上 <code>--verbose</code></strong> 运行 <code>trtexec</code></p>
<p>模型汇总</p>
<table>
<thead>
<tr>
<th>格式</th>
<th>文件扩展名</th>
<th>内容</th>
<th>用途</th>
<th>生成方式</th>
<th>可直接推理？</th>
</tr>
</thead>
<tbody>
<tr>
<td>WTS</td>
<td><code>.wts</code></td>
<td>网络结构各层的权重（文本或二进制）</td>
<td>通常用于从 PyTorch 到 TensorRT 的自定义转换流程，如通过 C++ 的 API 加载</td>
<td>通常通过 PyTorch 脚本导出</td>
<td>❌</td>
</tr>
<tr>
<td>TRT Engine</td>
<td><code>.trt</code> / <code>.engine</code></td>
<td>已优化的推理引擎（含网络结构 + 权重 + TensorRT 优化）</td>
<td>TensorRT 的最终部署格式</td>
<td>使用 <code>trtexec</code> 或 TensorRT API 编译 <code>.onnx</code> 或 <code>.wts</code> 模型生成</td>
<td>✅</td>
</tr>
</tbody>
</table>
<h1 id="问题汇总"><a class="markdownIt-Anchor" href="#问题汇总"></a> 问题汇总</h1>
<h3 id="️-自定义层问题"><a class="markdownIt-Anchor" href="#️-自定义层问题"></a> ⚠️ 自定义层问题</h3>
<h4 id="1-eyelike动态形状"><a class="markdownIt-Anchor" href="#1-eyelike动态形状"></a> 1 EyeLike动态形状</h4>
<p><code>EyeLike</code> 是 ONNX 中一个用于生成单位矩阵的操作。该错误说明：</p>
<ul>
<li>你模型中的某个节点使用了 <code>EyeLike</code> 操作；</li>
<li>但这个操作的输入张量是动态维度（即维度在推理时不固定）；</li>
<li>而 TensorRT <strong>不支持对动态维度使用 EyeLike</strong>。</li>
</ul>
<p><strong>EyeLike 操作</strong>：这是一个自定义层或特殊层，在某些情况下，TensorRT 不支持动态形状。</p>
<p><strong>动态形状问题</strong>：TensorRT 不支持动态形状的输入（<code>EyeLike</code> 操作的输入是动态形状），这导致了错误。</p>
<blockquote>
<p>使用batch 大小不需要变化的minShapes时没用的！</p>
</blockquote>
<h3 id="️-动态输入尺寸问题"><a class="markdownIt-Anchor" href="#️-动态输入尺寸问题"></a> ⚠️ 动态输入尺寸问题：</h3>
<h4 id="1-onnx参数dynamictrue"><a class="markdownIt-Anchor" href="#1-onnx参数dynamictrue"></a> 1 ONNX参数dynamic=True</h4>
<p>你导出的 ONNX 模型使用了 <strong>动态输入尺寸</strong>（<code>dynamic=True</code>），导致 <code>trtexec</code> 在构建 TensorRT 引擎时需要你<strong>明确地指定输入尺寸 profile</strong>，否则就会报错。</p>
<p>解决：</p>
<blockquote>
<p>trtexec <br>
–onnx=best_dynamic.onnx <br>
–saveEngine=best.engine <br>
–fp16 <br>
–minShapes=images:1x3x640x640 <br>
–optShapes=images:8x3x640x640 <br>
–maxShapes=images:16x3x640x640</p>
</blockquote>
<h3 id="️-量化问题"><a class="markdownIt-Anchor" href="#️-量化问题"></a> ⚠️  量化问题</h3>
<h4 id="1-int64数据"><a class="markdownIt-Anchor" href="#1-int64数据"></a> 1 INT64数据</h4>
<p>你的 ONNX 模型中包含了一些 <strong><code>INT64</code> 类型的权重或常量</strong>，而 TensorRT <strong>原生只支持 <code>INT32</code> 及以下的整数类型</strong>，因此它尝试<strong>自动将 <code>INT64</code> 转换为 <code>INT32</code></strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="️错误"><a class="markdownIt-Anchor" href="#️错误"></a> ⚠️错误</h3>
<p>[05/13/2025-15:25:59] [TRT] [E] 1: [defaultAllocator.cpp::nvinfer1::internal::DefaultAllocator::deallocate::61] Error Code 1: Cuda Runtime (invalid argument)</p>
<h1 id="success"><a class="markdownIt-Anchor" href="#success"></a> success！</h1>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">trtexec --onnx=F:\Pydata\DL_NEW\fuxian\ultralytics\runs\detect\wire-Ghost-C3ghost-GSCSP-CBAM3\weights\best_simplify_dynamic=False.onnx --saveEngine=best_int8.trt --int8 --verbose  --minShapes=images:1x3x640x640 --optShapes=images:8x3x640x640 --maxShapes=images:16x3x640x640trtexec ^</span><br><span class="line">--onnx=F:\Pydata\DL_NEW\fuxian\ultralytics\runs\detect\wire-Ghost-C3ghost-GSCSP-CBAM3\weights\best_simplify_dynamic.onnx ^</span><br><span class="line">--saveEngine=best_int8.trt ^</span><br><span class="line">--int8 ^</span><br><span class="line">--verbose ^</span><br><span class="line">--minShapes=images:1x3x640x640 ^</span><br><span class="line">--optShapes=images:8x3x640x640 ^</span><br><span class="line">--maxShapes=images:16x3x640x640</span><br></pre></td></tr></table></figure>
<p><img src="/2025/03/16/2025%E5%B9%B44%E6%9C%8816%E6%97%A5-TensorRT2export%E6%B1%87%E6%80%BB/C:%5CUsers%5Cadmin%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250513135551397.png" alt="image-20250513135551397"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/16/2025%E5%B9%B44%E6%9C%8816%E6%97%A5-TensorRT2export%E6%B1%87%E6%80%BB/" data-id="cmanj8o27000plcv44xiw84f2" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorRT/" rel="tag">TensorRT</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月16日-DL八股文" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/14/2025%E5%B9%B43%E6%9C%8816%E6%97%A5-DL%E5%85%AB%E8%82%A1%E6%96%87/" class="article-date">
  <time class="post-time" datetime="2025-03-14T06:44:16.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">14</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/14/2025%E5%B9%B43%E6%9C%8816%E6%97%A5-DL%E5%85%AB%E8%82%A1%E6%96%87/">2025年3月16日 DL八股文</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>记录一些学了又忘或是没学的DL八股文知识</p>
</blockquote>
<h1 id="dl八股文"><a class="markdownIt-Anchor" href="#dl八股文"></a> DL八股文</h1>
<h1 id="原理"><a class="markdownIt-Anchor" href="#原理"></a> 原理</h1>
<p>一种基于深层神经网络的机器学习方法，通过多层次的非线性变换自动提取数据特征，实现复杂模式的识别与预测。核心是模仿人脑神经元的连接方式，构建“输入-隐藏-输出”层级的计算模型，从数据中学习从简单到抽象的特征表示</p>
<h1 id="训练"><a class="markdownIt-Anchor" href="#训练"></a> 训练</h1>
<blockquote>
<p>模型训练的核心是通过调整参数（如权重 <em>w</em> 和偏置 <em>b</em>） 最小化损失函数 L</p>
</blockquote>
<h2 id="过拟合"><a class="markdownIt-Anchor" href="#过拟合"></a> 过拟合</h2>
<h3 id="1-什么是过拟合"><a class="markdownIt-Anchor" href="#1-什么是过拟合"></a> 1 什么是过拟合</h3>
<p>指模型在训练集上表现优异，但在测试集或新数据上泛化能力显著下降的现象。其核心矛盾是模型过度<strong>学习了训练数据中的噪声和非全局性特征</strong>，而非数据背后的真实规律 。</p>
<h3 id="2-原因"><a class="markdownIt-Anchor" href="#2-原因"></a> 2 原因</h3>
<ol>
<li>数据层面：<strong>数据量不足</strong>，导致没有学到全局特征。<strong>噪声干扰</strong>，数据中存在异常值或错误标签，模型误将其作为学习目标</li>
<li>模型层面：模型过于复杂，<strong>过度适应训练数据细节</strong></li>
<li>训练层面：迭代次数过多（未早停）或学习率未优化/</li>
</ol>
<h3 id="3-如何解决"><a class="markdownIt-Anchor" href="#3-如何解决"></a> 3 如何解决</h3>
<ol>
<li>
<p>：数据增强与数据清洗</p>
</li>
<li>
<p>：选用简单模型。添加正则化策略，<strong>Dropout</strong>、<strong>批量归一化</strong>BatchNorm、<strong>池化</strong></p>
</li>
<li>
<p>：早停法、动态学习率、</p>
</li>
<li>
<p><strong>集成方法</strong>：结合多个模型的预测结果（如随机森林投票），减少单个模型方差</p>
<p><strong>迁移学习等</strong></p>
</li>
</ol>
<h3 id="4-欠拟合呢"><a class="markdownIt-Anchor" href="#4-欠拟合呢"></a> 4 欠拟合呢？</h3>
<h2 id="训练方法"><a class="markdownIt-Anchor" href="#训练方法"></a> 训练方法</h2>
<p>训练方法</p>
<h3 id="1-监督学习"><a class="markdownIt-Anchor" href="#1-监督学习"></a> 1 监督学习</h3>
<h3 id="3-自监督学习"><a class="markdownIt-Anchor" href="#3-自监督学习"></a> 3 自监督学习</h3>
<blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1257862?spm=a2c6h.24874632.expert-profile.15.45a63181v37e02%5C">https://developer.aliyun.com/article/1257862?spm=a2c6h.24874632.expert-profile.15.45a63181v37e02\</a></p>
</blockquote>
<h4 id="定义"><a class="markdownIt-Anchor" href="#定义"></a> 定义</h4>
<p>​	它利用未标记的数据来训练模型，而无需人工标注的标签</p>
<p>​	利用数据中的自动生成的标签或任务来训练模型</p>
<h4 id="自监督学习方法"><a class="markdownIt-Anchor" href="#自监督学习方法"></a> 自监督学习方法</h4>
<h3 id="4-zero-shot-one-shot-and-few-shot-learning概念"><a class="markdownIt-Anchor" href="#4-zero-shot-one-shot-and-few-shot-learning概念"></a> 4 Zero-Shot, One-Shot, and Few-Shot Learning概念</h3>
<ol>
<li>Zero-Shot是指训练一个模型来对其从未见过的对象进行分类。其核心思想是利用另一个模型的现有知识，以获得新类别的有意义的表示。</li>
<li>One-Shot是确定图像A是否等同于图像B。这是通过将模型从先前任务的经验中获得的信息进行概括来实现的。</li>
<li>Few-Shot Learning它是元学习的一个子领域，旨在开发能够从少量有标签示例中学习的算法</li>
</ol>
<h2 id="迁移学习微调-️"><a class="markdownIt-Anchor" href="#迁移学习微调-️"></a> 迁移学习+微调 ☑️</h2>
<h3 id="1-迁移学习"><a class="markdownIt-Anchor" href="#1-迁移学习"></a> 1 迁移学习</h3>
<p>在大型数据集上训练好的模型可以被“迁移”到新的任务中，从而避免从零开始训练。大地缩短训练时间，并显著提高性能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载预训练的ResNet模型</span></span><br><span class="line">resnet = models.resnet50(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="2-微调"><a class="markdownIt-Anchor" href="#2-微调"></a> 2 微调</h3>
<ul>
<li>通过对预训练模型<strong>进行部分或全部参数的微调</strong>，模型可以适应新任务中的特定数据。微调的程度取决于新任务的相似性和目标。</li>
<li>通常会冻结模型的部分层，以保留通用的特征提取能力，针对新任务<strong>只对高层</strong>进行微调。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 冻结所有层的参数，以便只微调最后的全连接层</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> resnet.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 解冻部分层，允许更多层进行训练</span></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> resnet.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;layer4&quot;</span> <span class="keyword">in</span> name:  <span class="comment"># 假设只解冻ResNet的最后一层</span></span><br><span class="line">        param.requires_grad = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        param.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h2 id="梯度"><a class="markdownIt-Anchor" href="#梯度"></a> 梯度</h2>
<p><img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8816%E6%97%A5-DL%E5%85%AB%E8%82%A1%E6%96%87/image-20250320184024743.png" alt></p>
<h3 id="2-梯度稀疏化问题"><a class="markdownIt-Anchor" href="#2-梯度稀疏化问题"></a> 2 梯度稀疏化问题</h3>
<h4 id="定义-2"><a class="markdownIt-Anchor" href="#定义-2"></a> 定义</h4>
<p>在深度学习中，梯度是指损失函数对模型参数的偏导数。通过反向传播算法，我们可以计算得到每个参数的梯度，并使用优化算法（如随机梯度下降）来更新参数。然而，在深层神经网络中，梯度通常具有很高的维度，<strong>其中大部分元素都是接近于零或者非常小的值</strong>。这些接近于零的梯度元素对参数更新几乎没有贡献，并且会占用大量内存空间和计算资源。</p>
<ul>
<li>
<p>模型更新偏差：仅部分参数被有效更新，可能偏离全局最优解</p>
</li>
<li>
<p>训练不稳定：梯度分布不均加剧收敛震荡</p>
</li>
</ul>
<h4 id="成因"><a class="markdownIt-Anchor" href="#成因"></a> <strong>成因</strong></h4>
<ol>
<li><strong>模型结构与激活函数</strong>
<ul>
<li>局部激活稀疏性：ReLU等激活函数在输入为负时输出零梯度，导致大量神经元处于“死亡”状态</li>
<li>深度网络层间依赖：深层网络中矩阵连乘导致梯度衰减或爆炸，加剧稀疏性</li>
</ul>
</li>
<li><strong>优化策略与正则化</strong>
<ul>
<li>L1正则化：通过惩罚权重绝对值，强制稀疏参数分布，间接导致梯度稀疏</li>
<li>梯度裁剪：限制梯度幅值，抑制小梯度更新</li>
</ul>
</li>
<li><strong>训练数据分布</strong>
<ul>
<li>数据不均衡：长尾数据导致部分类别梯度贡献微弱</li>
<li>特征冗余：输入数据中存在大量无关特征，相关梯度趋近于零</li>
</ul>
</li>
</ol>
<h4 id="处理方法"><a class="markdownIt-Anchor" href="#处理方法"></a> <strong>处理方法</strong></h4>
<p><strong>优化算法改进</strong></p>
<ul>
<li><strong>动量修正与误差补偿</strong>：如DGC中的Momentum Correction，缓解因稀疏化导致的梯度滞后问题</li>
<li><strong>自适应优化器</strong>：Adam等算法动态调整学习率，避免小梯度参数被完全抑制</li>
</ul>
<p><strong>数据与训练策略调整</strong></p>
<ul>
<li><strong>数据增强与重采样</strong>：平衡类别分布，提升尾部数据的梯度贡献</li>
<li><strong>渐进式稀疏训练</strong>：初期保留更多梯度，逐步增加稀疏率以避免过早信息丢失</li>
</ul>
<h4 id="应用"><a class="markdownIt-Anchor" href="#应用"></a> 应用</h4>
<ol>
<li>剪枝与梯度量化</li>
<li></li>
</ol>
<h2 id="激活函数"><a class="markdownIt-Anchor" href="#激活函数"></a> 激活函数</h2>
<h3 id="1-定义"><a class="markdownIt-Anchor" href="#1-定义"></a> 1 定义</h3>
<p>引入<strong>非线性因素</strong>,处理复杂的问题</p>
<h3 id="2-常见激活函数"><a class="markdownIt-Anchor" href="#2-常见激活函数"></a> 2 常见激活函数</h3>
<h4 id="1-sigmoid"><a class="markdownIt-Anchor" href="#1-sigmoid"></a> 1 Sigmoid</h4>
<img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8816%E6%97%A5-DL%E5%85%AB%E8%82%A1%E6%96%87/image-20250320185054836.png" alt="image-20250320185054836" style="zoom:33%;"> 
<h4 id="2-tanh"><a class="markdownIt-Anchor" href="#2-tanh"></a> 2 Tanh</h4>
<img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8816%E6%97%A5-DL%E5%85%AB%E8%82%A1%E6%96%87/image-20250320185034344.png" alt="image-20250320185034344" style="zoom: 33%;">  
<blockquote>
<p>存在梯度消失的问题，因为它们的导数（连乘）在两端会趋近于零，导致深层网络训练困难</p>
</blockquote>
<h4 id="3-relu"><a class="markdownIt-Anchor" href="#3-relu"></a> 3 relu</h4>
<img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8816%E6%97%A5-DL%E5%85%AB%E8%82%A1%E6%96%87/image-20250320184950902.png" alt="image-20250320184950902" style="zoom: 67%;"> 
<h5 id="优势"><a class="markdownIt-Anchor" href="#优势"></a> 优势</h5>
<ol>
<li><strong>缓解梯度消失</strong>：
<ul>
<li>Sigmoid/Tanh的饱和区：导数在输入绝对值较大时趋近于0（如Sigmoid导数值最大仅0.25），导致深层网络梯度链式相乘后指数级衰减</li>
<li>ReLU的非饱和性：<strong>正区间的导数为1</strong>，保证梯度稳定传递，支持深层网络训练</li>
</ul>
</li>
<li><strong>计算高效</strong>：ReLU仅需判断输入是否大于0（<strong>无指数运算</strong>），比Sigmoid/Tanh快6倍以上，适合大规模数据和复杂模型</li>
<li><strong>稀疏激活</strong>：ReLU将负输入强制置零，使网络<strong>稀疏化</strong>（约50%神经元激活），降低参数依赖性和过拟合风险，增强模型鲁棒性</li>
</ol>
<h5 id="不足"><a class="markdownIt-Anchor" href="#不足"></a> 不足</h5>
<ol>
<li>为负时，ReLU输出恒为0，梯度为0，导致对应权重无法更新（“<strong>死亡</strong>”）</li>
</ol>
<h5 id="改进"><a class="markdownIt-Anchor" href="#改进"></a> 改进</h5>
<blockquote>
<p>改进ReLU的方法，比如Leaky ReLU、Parametric ReLU（PReLU）和ELU，</p>
</blockquote>
<h2 id="损失函数"><a class="markdownIt-Anchor" href="#损失函数"></a> 损失函数</h2>
<blockquote>
<p>解释什么是损失函数，它的作用，常见的损失函数类型，以及如何根据不同的任务选择合适的损失函数，还有在训练过程中如何优化损失。</p>
</blockquote>
<h3 id="1-定义-2"><a class="markdownIt-Anchor" href="#1-定义-2"></a> <strong>1 定义</strong>：</h3>
<p>损失函数是衡量模型预测值与真实值<strong>差异的量化指标</strong>，</p>
<p><strong>用于指导模型参数优化</strong>。反向传播更新梯度</p>
<p><img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8816%E6%97%A5-DL%E5%85%AB%E8%82%A1%E6%96%87/image-20250320182842833.png" alt="image-20250320182842833"></p>
<h3 id="2-常见"><a class="markdownIt-Anchor" href="#2-常见"></a> 2 常见</h3>
<ol>
<li><strong>均方误差</strong> 绝对误差等等</li>
<li>交叉熵</li>
</ol>
<h1 id="模型"><a class="markdownIt-Anchor" href="#模型"></a> 模型</h1>
<h2 id="cnn"><a class="markdownIt-Anchor" href="#cnn"></a> CNN</h2>
<h3 id="0-图像性质"><a class="markdownIt-Anchor" href="#0-图像性质"></a> 0 图像性质</h3>
<ol>
<li><strong>平移不变性</strong>：池化与卷积核滑动使模型对目标位置变化不敏感。</li>
</ol>
<h3 id="1-定义-3"><a class="markdownIt-Anchor" href="#1-定义-3"></a> 1 定义</h3>
<p>核心思想是通过<strong>局部感受野</strong>和<strong>参数共享</strong>，高效提取空间或时序特征。<br>
从原始像素中学习到“边缘→纹理→物体部件→完整物体”的层次化特征表示</p>
<h3 id="2-组成"><a class="markdownIt-Anchor" href="#2-组成"></a> 2 组成</h3>
<h4 id="卷积层"><a class="markdownIt-Anchor" href="#卷积层"></a> <strong>卷积层</strong></h4>
<p><strong>卷积层堆叠</strong>：</p>
<ul>
<li>浅层卷积核提取边缘、颜色等低级特征。</li>
<li>深层卷积核组合低级特征，形成高级语义（如车轮、车窗</li>
</ul>
<h4 id="池化层"><a class="markdownIt-Anchor" href="#池化层"></a> <strong>池化层</strong></h4>
<blockquote>
<p>减少计算量并增强平移不变性。</p>
</blockquote>
<h2 id="resnet"><a class="markdownIt-Anchor" href="#resnet"></a> resnet</h2>
<h3 id="1思想"><a class="markdownIt-Anchor" href="#1思想"></a> 1<strong>思想</strong></h3>
<blockquote>
<p><strong>学习残差而非直接学习目标映射</strong>   通过（跳跃连接）实现残差学习</p>
</blockquote>
<h3 id="2-解决问题"><a class="markdownIt-Anchor" href="#2-解决问题"></a> 2 解决问题</h3>
<h5 id="1-深层网络退化degradation"><a class="markdownIt-Anchor" href="#1-深层网络退化degradation"></a> 1. <strong>深层网络退化（Degradation）</strong></h5>
<ul>
<li><strong>现象</strong>：传统CNN（如VGG）随着层数增加（如20层以上），训练误差和测试误差反而上升，<strong>这不是过拟合，而是模型难以优化</strong>。</li>
<li><strong>原因</strong>：叠加非线性层导致信息传递效率下降，深层网络难以学习有效的恒等映射（Identity Mapping）。</li>
<li><strong>解决</strong>：跳跃连接强制网络学习残差 F(x)<em>F</em>(<em>x</em>)，当最优解接近恒等映射时，F(x)<em>F</em>(<em>x</em>) 只需逼近0，比直接拟合 H(x)=x<em>H</em>(<em>x</em>)=<em>x</em> 更简单。</li>
</ul>
<h5 id="2-梯度消失vanishing-gradient"><a class="markdownIt-Anchor" href="#2-梯度消失vanishing-gradient"></a> 2. <strong>梯度消失（Vanishing Gradient）</strong></h5>
<ul>
<li><strong>现象</strong>：反向传播时，梯度在深层网络中逐层连乘，导致浅层权重更新缓慢甚至停滞。</li>
<li><strong>解决</strong>：跳跃连接提供<strong>梯度高速公路</strong>，梯度可通过加法操作直接回传至浅层（如公式 ∂L∂x=∂L∂H(x)⋅(1+∂F(x)∂x)∂<em>x</em>∂<em>L</em>=∂<em>H</em>(<em>x</em>)∂<em>L</em>⋅(1+∂<em>x</em>∂<em>F</em>(<em>x</em>))），避免梯度被多次非线性变换稀释。</li>
</ul>
<h2 id="模型难以优化"><a class="markdownIt-Anchor" href="#模型难以优化"></a> <strong>模型难以优化</strong></h2>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/14/2025%E5%B9%B43%E6%9C%8816%E6%97%A5-DL%E5%85%AB%E8%82%A1%E6%96%87/" data-id="cm8q1tfhq0011pcv41q1mcut5" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月14日-据增强方法" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/14/2025%E5%B9%B43%E6%9C%8814%E6%97%A5-%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/" class="article-date">
  <time class="post-time" datetime="2025-03-14T05:34:43.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">14</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/14/2025%E5%B9%B43%E6%9C%8814%E6%97%A5-%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/">2025年3月14日 数据增强方法</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="数据预处理"><a class="markdownIt-Anchor" href="#数据预处理"></a> 数据预处理</h1>
<h2 id="数据增强方法"><a class="markdownIt-Anchor" href="#数据增强方法"></a> 数据增强方法</h2>
<h3 id="1-数据增强的作用"><a class="markdownIt-Anchor" href="#1-数据增强的作用"></a> 1 数据增强的作用</h3>
<p>1） 避免过拟合。当数据集具有某种明显的特征，例如数据集中图片基本在同一个场景中拍摄，使用Cutout方法和风格迁移变化等相关方法可避免模型学到跟目标无关的信息。</p>
<p>2）提升模型鲁棒性，降低模型对图像的敏感度。当训练数据都属于比较理想的状态，碰到一些特殊情况，如遮挡，亮度，模糊等情况容易识别错误，对训练数据加上噪声，掩码等方法可提升模型鲁棒性。</p>
<p>3）增加训练数据，提高模型泛化能力。</p>
<p>4）避免样本不均衡。在工业缺陷检测方面，医疗疾病识别方面，容易出现正负样本极度不平衡的情况，通过对少样本进行一些数据增强方法，降低样本不均衡比例。</p>
<p>———————————————</p>
<h3 id="2-哪些数据增强方法"><a class="markdownIt-Anchor" href="#2-哪些数据增强方法"></a> 2 哪些数据增强方法</h3>
<h4 id="几何变换"><a class="markdownIt-Anchor" href="#几何变换"></a> 几何变换</h4>
<p>随机旋转（±15°）、</p>
<p>翻转</p>
<p>裁剪，</p>
<p>缩放，</p>
<p>平移，</p>
<h4 id="像素变换"><a class="markdownIt-Anchor" href="#像素变换"></a> 像素变换</h4>
<p>高斯噪声、</p>
<p>运动模糊模拟</p>
<p>调整HSV对比度</p>
<p>调节亮度，饱和度，直方图均衡化，调整白平衡</p>
<h3 id="3-特殊任务"><a class="markdownIt-Anchor" href="#3-特殊任务"></a> 3 特殊任务</h3>
<h4 id="适合分类任务"><a class="markdownIt-Anchor" href="#适合分类任务"></a> 适合分类任务</h4>
<p><img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8814%E6%97%A5-%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/image-20250314143616191.png" alt="image-20250314143616191"></p>
<blockquote>
<p>Mixup, Cutmix只用于分类任务</p>
</blockquote>
<h4 id="适合检测任务"><a class="markdownIt-Anchor" href="#适合检测任务"></a> 适合检测任务</h4>
<p>GridMask</p>
<img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8814%E6%97%A5-%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/image-20250314143710300.png" alt="image-20250314143710300" style="zoom: 33%;"> 
<h4 id="mosaic数据增强"><a class="markdownIt-Anchor" href="#mosaic数据增强"></a> mosaic数据增强</h4>
<img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8814%E6%97%A5-%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/image-20250314143803362.png" alt="image-20250314143803362" style="zoom: 43%;"> 
<h2 id="4-transformscompose"><a class="markdownIt-Anchor" href="#4-transformscompose"></a> 4 Transforms.Compose</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">256</span>),          <span class="comment"># 调整图像尺寸</span></span><br><span class="line">    transforms.RandomCrop(<span class="number">224</span>),      <span class="comment"># 随机裁剪为224x224</span></span><br><span class="line">    transforms.RandomHorizontalFlip(), <span class="comment"># 随机水平翻转（概率0.5）</span></span><br><span class="line">    transforms.ToTensor(),           <span class="comment"># 转为张量并归一化至[0,1]</span></span><br><span class="line">    transforms.Normalize(            <span class="comment"># 标准化（均值、标准差）</span></span><br><span class="line">        mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], </span><br><span class="line">        std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">    )</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h3 id="5-复杂场景的特殊处理"><a class="markdownIt-Anchor" href="#5-复杂场景的特殊处理"></a> 5 复杂场景的特殊处理</h3>
<p>复杂场景如图像可能包含以下问题：</p>
<ol>
<li><strong>遮挡与局部模糊</strong>（如交通监控中的车辆遮挡）</li>
<li><strong>光照不均</strong>（如夜间低光照或强反光区域）</li>
<li><strong>动态模糊</strong>（如快速移动目标）</li>
<li><strong>背景干扰</strong>（如医疗图像中器官重叠</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">transform = Compose([</span><br><span class="line">    RandomPerspective(distortion_scale=0.5),  # 透视变形模拟遮挡  </span><br><span class="line">    AdjustGamma(gamma=0.5),                   # 调整伽马值应对低光照  </span><br><span class="line">    GaussianBlur(kernel_size=5)               # 模拟运动模糊  </span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h2 id="数据不平衡问题"><a class="markdownIt-Anchor" href="#数据不平衡问题"></a> <strong>数据不平衡问题</strong></h2>
<p>参考:<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/296632599%5C">https://zhuanlan.zhihu.com/p/296632599\</a></p>
<h3 id="1-数据不平衡"><a class="markdownIt-Anchor" href="#1-数据不平衡"></a> 1 数据不平衡</h3>
<p>不同类别的样本量差异非常大，或者少数样本代表了业务的关键数据</p>
<h3 id="2-如何处理"><a class="markdownIt-Anchor" href="#2-如何处理"></a> 2 <strong>如何处理</strong></h3>
<ol>
<li>
<p>欠采样：<strong>在少量样本数量不影响模型训练的情况下</strong>，可通过对<strong>多数类样本欠采样</strong>，实现少数样本和多数样本均衡。</p>
</li>
<li>
<p>过采样：在少量样本数量<strong>不支持</strong>模型训练的情况下，可以通过对<strong>少数类样本过采样</strong>，实现少数样本和多数样本的均衡。</p>
</li>
<li>
<p>模型算法：通过引入有权重的模型算法，<strong>针对少量样本着重拟合</strong>，以提升对少量样本特征的学习。</p>
</li>
</ol>
<h4 id="1欠采样"><a class="markdownIt-Anchor" href="#1欠采样"></a> 1.欠采样</h4>
<p>​	减少大样本数量的采集</p>
<h5 id="随机法删除"><a class="markdownIt-Anchor" href="#随机法删除"></a> <strong>随机法</strong>删除</h5>
<blockquote>
<p>随机的删除一些多数类样本</p>
</blockquote>
<h4 id="2过采样"><a class="markdownIt-Anchor" href="#2过采样"></a> 2.过采样</h4>
<h5 id="随机复制"><a class="markdownIt-Anchor" href="#随机复制"></a> <strong>随机复制</strong></h5>
<blockquote>
<p>对少量样本进行复制后达到样本均衡的效果以提升模型的效果。</p>
</blockquote>
<p><strong>样本生成</strong></p>
<blockquote>
<p>SMOTE方法为例，对于任意选取的少类样本，它用K近邻选取相似样本，并通过对样本线性插值得到新样本。</p>
</blockquote>
<h4 id="3模型算法"><a class="markdownIt-Anchor" href="#3模型算法"></a> 3.模型算法</h4>
<p>​	从算法层面</p>
<h5 id="focal-loss"><a class="markdownIt-Anchor" href="#focal-loss"></a> <strong>Focal Loss</strong></h5>
<blockquote>
<p>Focal loss 在标准交叉熵损失的基础上修改得到的，通过减少易分类样本的权重，使得模型在训练时更专注于难分类的样本</p>
</blockquote>
<p><strong>解耦特征和分类器</strong></p>
<h3 id="3-目标检测中"><a class="markdownIt-Anchor" href="#3-目标检测中"></a> 3 目标检测中</h3>
<p><strong>定义</strong></p>
<ul>
<li>正样本：<strong>标签区域内</strong>的图像区域，即目标图像块</li>
<li>负样本：<strong>标签区域以外</strong>的图像区域，即图像背景区域</li>
<li>易分正样本：容易正确分类的正样本，在实际训练过程中，<strong>该类占总体样本的比重非常高，单个样本的损失函数较小</strong>，但是累计的损失函数会主导损失函数</li>
<li>易分负样本：容易正确分类的负样本，在实际训练过程中，<strong>该类占的比重非常高</strong>，单个样本的损失函数较小，但是累计的损失函数会主导损失函数</li>
<li>难分正样本：错分成负样本的正样本，这部分样本在训练过程中单个样本的损失函数较高，但是<strong>该类占总体样本的比例较小</strong></li>
<li>难分负样本：错分成正样本的负样本，这部分样本在训练过程中单个样本的损失函数教高，但是该类占总体样本的比例教小</li>
</ul>
<img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8814%E6%97%A5-%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/image-20250314152506435.png" alt="image-20250314152506435" style="zoom:50%;">
<blockquote>
<p>和grand true 的框重叠部分</p>
</blockquote>
<h4 id="1正负样本不均衡"><a class="markdownIt-Anchor" href="#1正负样本不均衡"></a> <strong>1.正负样本不均衡</strong></h4>
<p>以Faster RCNN为例，在RPN部分会生成20000个左右的Anchor，由于一张图中通常有10个左右的物体，<strong>导致可能只有100个左右的Anchor会是正样本，正负样本比例约为1∶200，存在严重的不均衡。</strong></p>
<h4 id="2难易样本不均衡"><a class="markdownIt-Anchor" href="#2难易样本不均衡"></a> <strong>2.难易样本不均衡</strong></h4>
<ol>
<li>难样本指的是<strong>分类不太明确的边框，处在前景与背景的过渡区域上</strong></li>
<li>然而，大量的样本并非处在前景与背景的过渡区，而是**与真实物体没有重叠区域的负样本，或者与真实物体重叠程度很高的正样本，<strong>这部分被称为</strong>简单样本，**单个损失会较小，对参数收敛的作用有限。</li>
</ol>
<h4 id="3类别间样本不均衡"><a class="markdownIt-Anchor" href="#3类别间样本不均衡"></a> <strong>3.类别间样本不均衡</strong></h4>
<p>机器学习中，样本不均衡问题的解决方法</p>
<h1 id="多进程"><a class="markdownIt-Anchor" href="#多进程"></a> 多进程</h1>
<h2 id="几种方法实现"><a class="markdownIt-Anchor" href="#几种方法实现"></a> 几种方法实现：</h2>
<h3 id="多进程创建模型推理"><a class="markdownIt-Anchor" href="#多进程创建模型推理"></a> 多进程创建模型推理</h3>
<p><strong>多进程并行推理</strong></p>
<ol>
<li>创建多个进程：每个进程加载一个YOLOv8模型实例，将待推理的图像或视频流分配给不同的进程并行处理。</li>
<li>进程间通信：使用队列、管道等机制实现进程间的通信和数据交换。例如，可以使用multiprocessing.Queue来传递待处理的图像数据和推理结果。</li>
<li>合理分配任务：根据硬件资源和任务特性，合理分配每个进程的推理任务量，避免资源浪费和性能瓶颈。</li>
</ol>
<p><strong>硬件加速与优化</strong></p>
<ol>
<li>使用GPU加速：将YOLOv8模型部署在GPU上，利用GPU的并行计算能力加速模型推理。可以使用TensorRT等工具对模型进行优化，进一步提升推理效率。</li>
<li>模型优化：对YOLOv8模型进行量化、剪枝等优化操作，减少模型的计算复杂度和参数量，从而提高推理速度。</li>
<li>前后处理加速：优化图像的预处理和后处理步骤，例如使用内存0拷贝技术、快速的解码和编码算法等，减少数据传输和处理的时间。</li>
</ol>
<p><strong>多线程辅助</strong></p>
<ol>
<li>多线程数据读写：在多进程推理的基础上，可以使用多线程来辅助数据的读写操作，提高数据处理的效率。例如，使用线程池来维护多个线程，每个线程负责读取或写入一部分数据。</li>
<li>界面与推理分离：如果需要在GUI界面中进行YOLOv8推理，可以将推理任务放在单独的线程中执行，避免阻塞界面线程，提高用户体验。</li>
</ol>
<p>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zhiqingAI/article/details/145017566">https://blog.csdn.net/zhiqingAI/article/details/145017566</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Queue</span><br><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">worker</span>(<span class="params">q, model_path</span>):</span><br><span class="line">    model = YOLO(model_path)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        img = q.get()</span><br><span class="line">        <span class="keyword">if</span> img <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        results = model.predict(source=img)</span><br><span class="line">        <span class="comment"># 处理推理结果</span></span><br><span class="line">        <span class="built_in">print</span>(results)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    q = Queue()</span><br><span class="line">    model_path = <span class="string">&#x27;yolov8n.pt&#x27;</span></span><br><span class="line">    num_processes = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建多个进程</span></span><br><span class="line">    processes = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_processes):</span><br><span class="line">        p = Process(target=worker, args=(q, model_path))</span><br><span class="line">        p.start()</span><br><span class="line">        processes.append(p)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将图像数据放入队列</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        img_path = <span class="string">f&#x27;image_<span class="subst">&#123;i&#125;</span>.jpg&#x27;</span></span><br><span class="line">        img = cv2.imread(img_path)</span><br><span class="line">        q.put(img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 结束进程</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_processes):</span><br><span class="line">        q.put(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">        p.join()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="多线程同时访问相同模型"><a class="markdownIt-Anchor" href="#多线程同时访问相同模型"></a> 多线程同时访问相同模型</h3>
<p>多线程推理函数</p>
<h4 id="1-解决图像接收端与推理端速度不匹配的问题"><a class="markdownIt-Anchor" href="#1-解决图像接收端与推理端速度不匹配的问题"></a> 1. 解决图像接收端与推理端速度不匹配的问题</h4>
<p>当出现生产者生产太快，而消费太慢时：会让图片发生堆积，一张图片可能有2MB，如果长期运行，就会发现，程序可能在某一刻发生崩溃（内存消耗殆尽）</p>
<h3 id="检测与识别并行"><a class="markdownIt-Anchor" href="#检测与识别并行"></a> 检测与识别并行</h3>
<h4 id="一张图片经多个模型推理的异步模式设计"><a class="markdownIt-Anchor" href="#一张图片经多个模型推理的异步模式设计"></a> 一张图片，经多个模型推理的异步模式设计</h4>
<p>参考:<a target="_blank" rel="noopener" href="https://blog.csdn.net/hh1357102/article/details/127586846%5C">https://blog.csdn.net/hh1357102/article/details/127586846\</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/14/2025%E5%B9%B43%E6%9C%8814%E6%97%A5-%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/" data-id="cmanj8o220009lcv41hue4oqi" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月15日-模型评价指标" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/14/2025%E5%B9%B43%E6%9C%8815%E6%97%A5-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/" class="article-date">
  <time class="post-time" datetime="2025-03-13T16:26:50.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">14</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/14/2025%E5%B9%B43%E6%9C%8815%E6%97%A5-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/">2025年3月15日 模型评价指标</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="计算量与参数量"><a class="markdownIt-Anchor" href="#计算量与参数量"></a> 计算量与参数量</h1>
<h2 id="1-定义"><a class="markdownIt-Anchor" href="#1-定义"></a> 1 定义</h2>
<ol>
<li>计算量-时间复杂度  <strong>乘法和加发的操作次数</strong></li>
<li>参数量-空间复杂度</li>
</ol>
<h3 id="卷积层"><a class="markdownIt-Anchor" href="#卷积层"></a> 卷积层</h3>
<p><strong>计算量</strong>: (KxKxWxH) x C_in x C_out</p>
<blockquote>
<p>W\H: 输出feature map 的size</p>
<p>回忆卷积操作过程</p>
</blockquote>
<p><strong>参数量</strong>: KxKxC_inxC_out</p>
<blockquote>
<p>卷积核的weight</p>
</blockquote>
<h3 id="池化层"><a class="markdownIt-Anchor" href="#池化层"></a> 池化层</h3>
<p><strong>计算量</strong>: 不同池化操作不同 Cin x Cout x W x H x K xK</p>
<blockquote></blockquote>
<p><strong>参数量</strong>  无</p>
<h3 id="全连接层"><a class="markdownIt-Anchor" href="#全连接层"></a> 全连接层</h3>
<p>参数量 weight_in*weight_out</p>
<p>计算量＝ 2 x Cin x Cout</p>
<h3 id="batchnorm"><a class="markdownIt-Anchor" href="#batchnorm"></a> BatchNorm</h3>
<p>计算量: 4WHC</p>
<blockquote></blockquote>
<p>参数量: 2C</p>
<blockquote>
<p>(y=ax+b) xC</p>
</blockquote>
<h3 id="激活函数"><a class="markdownIt-Anchor" href="#激活函数"></a> 激活函数</h3>
<p>计算量: H×W×C</p>
<blockquote>
<p>path个数</p>
</blockquote>
<h2 id="硬件需求"><a class="markdownIt-Anchor" href="#硬件需求"></a> 硬件需求</h2>
<p>计算量的要求是在于芯片的__（指的是gpu的运算能力）</p>
<p>参数量取决于__大小</p>
<h3 id="计算量和参数量查看"><a class="markdownIt-Anchor" href="#计算量和参数量查看"></a> 计算量和参数量查看</h3>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40507857/article/details/118764782">https://blog.csdn.net/qq_40507857/article/details/118764782</a></p>
<h3 id="输入数据对模型的参数量和计算量的影响"><a class="markdownIt-Anchor" href="#输入数据对模型的参数量和计算量的影响"></a> 输入数据对模型的参数量和计算量的影响</h3>
<h1 id="tf-fp-fn-tn"><a class="markdownIt-Anchor" href="#tf-fp-fn-tn"></a> TF FP FN TN</h1>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wzk4869/article/details/127879761">https://blog.csdn.net/wzk4869/article/details/127879761</a></p>
<img src="https://picx.zhimg.com/70/v2-895d6f8e80c0078c92244158dec97bfc_1440w.image?source=172ae18b&biz_tag=Post" alt="深挖一下F1 score (F-measure, F-score)[根据公式分析]" style="zoom:50%;">
<h2 id="1-准确率precision"><a class="markdownIt-Anchor" href="#1-准确率precision"></a> 1 准确率（Precision）</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="2-召回率-recall"><a class="markdownIt-Anchor" href="#2-召回率-recall"></a> 2 召回率 (Recall)</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="目标检测的评价指标"><a class="markdownIt-Anchor" href="#目标检测的评价指标"></a> 目标检测的评价指标</h1>
<h2 id="1-iou"><a class="markdownIt-Anchor" href="#1-iou"></a> 1: IoU</h2>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="2-f1-score"><a class="markdownIt-Anchor" href="#2-f1-score"></a> 2: F1 Score</h2>
<p><strong>定义</strong>: F Score 是 Precision 和 Recall 的调和平均数 (harmonic mean)</p>
<p><img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8815%E6%97%A5-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/image-20250314011150884.png" alt="image-20250314011150884"></p>
<blockquote>
<p>Precision 与 Recall 看起来很相似，实际上这两个是“冤家”。为什么这么说呢？因为在大多数情况下，这两者有一定的互斥性。****</p>
</blockquote>
<p><strong>作用:</strong></p>
<h2 id="平均准确度-average-precisionap"><a class="markdownIt-Anchor" href="#平均准确度-average-precisionap"></a> 平均准确度 (Average Precision，AP)</h2>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/14/2025%E5%B9%B43%E6%9C%8815%E6%97%A5-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/" data-id="cm8q1tfhp000xpcv44db75i16" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月12日-onnx5-算子" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/" class="article-date">
  <time class="post-time" datetime="2025-03-12T14:42:57.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">12</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/">2025年3月12日 onnx问答</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zhaoyqcsdn/article/details/135512992%E3%80%81">https://blog.csdn.net/zhaoyqcsdn/article/details/135512992、</a></p>
<h1 id="1-算子不兼容"><a class="markdownIt-Anchor" href="#1-算子不兼容"></a> 1 算子不兼容</h1>
<p>onnx算子是否支持<br>
<a target="_blank" rel="noopener" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md">https://github.com/onnx/onnx/blob/main/docs/Operators.md</a></p>
<h2 id="11-pytorch中有onnx中也有的算子"><a class="markdownIt-Anchor" href="#11-pytorch中有onnx中也有的算子"></a> 1.1 pytorch中有，onnx中也有的算子</h2>
<h2 id="12-pytorch中有onnx中无的算子"><a class="markdownIt-Anchor" href="#12-pytorch中有onnx中无的算子"></a> 1.2 pytorch中有，onnx中无的算子</h2>
<p>继承<code>torch.autograd.Function</code>实现自定义算子</p>
<h3 id="1-案例示例-focus层的切片操作"><a class="markdownIt-Anchor" href="#1-案例示例-focus层的切片操作"></a> <strong>1 案例示例</strong>： <code>Focus</code>层的切片操作</h3>
<blockquote>
<p>通过其他变换来改成兼容的算子</p>
</blockquote>
<p>在目标检测项目中，将PyTorch训练的YOLOv5模型转换为ONNX时，需处理<code>Focus</code>层的切片操作兼容性问题，通过重构为<code>Conv</code>层解决，将size减少一半通道数增加一倍</p>
<h3 id="2-实际案例动态切片问题"><a class="markdownIt-Anchor" href="#2-实际案例动态切片问题"></a> 2 <strong>实际案例：动态切片问题</strong></h3>
<p>静态图无法处理随机性</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 原始PyTorch代码（无法导出）</span><br><span class="line">x_slice = x[:, :, start_idx:start_idx+10]</span><br><span class="line"></span><br><span class="line"># 修改为ONNX兼容方式</span><br><span class="line">indices = torch.arange(start_idx, start_idx+10, device=x.device)</span><br><span class="line">x_slice = torch.index_select(x, dim=2, index=indices)</span><br></pre></td></tr></table></figure>
<h3 id="3-案例示例创建新的算子-手动实现"><a class="markdownIt-Anchor" href="#3-案例示例创建新的算子-手动实现"></a> 3 案例示例：创建新的算子 手动实现</h3>
<blockquote>
<p>使用支持的操作来手动实现算子</p>
</blockquote>
<ul>
<li>
<p>****：部分框架特定操作（如PyTorch自定义层）需替换为ONNX标准算子或自定义实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.onnx</span><br><span class="line"><span class="keyword">from</span> torch.onnx <span class="keyword">import</span> register_custom_op_symbolic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 定义自定义算子</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomRelu</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播：自定义的ReLU操作&quot;&quot;&quot;</span></span><br><span class="line">        ctx.save_for_backward(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.maximum(<span class="built_in">input</span>, torch.tensor(<span class="number">0.5</span>))  <span class="comment"># 比普通ReLU多了一个偏移</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;反向传播：ReLU的梯度计算&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">input</span>, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[<span class="built_in">input</span> &lt; <span class="number">0.5</span>] = <span class="number">0</span>  <span class="comment"># 低于0.5的部分梯度置零</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建 ONNX 计算图中的算子</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">symbolic_custom_relu</span>(<span class="params">g, <span class="built_in">input</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;定义 ONNX 计算图中的 custom_relu&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> g.op(<span class="string">&quot;custom_domain::CustomRelu&quot;</span>, <span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 绑定 ONNX 导出</span></span><br><span class="line">register_custom_op_symbolic(<span class="string">&quot;::CustomRelu&quot;</span>, symbolic_custom_relu, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 使用自定义算子</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomModel</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> CustomRelu.apply(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 实例化模型</span></span><br><span class="line">model = CustomModel()</span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 导出为 ONNX（确保 opset 版本支持）</span></span><br><span class="line">torch.onnx.export(</span><br><span class="line">    model, x, <span class="string">&quot;custom_relu.onnx&quot;</span>,</span><br><span class="line">    opset_version=<span class="number">11</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    operator_export_type=torch.onnx.OperatorExportTypes.ONNX</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="问题动态batch或可变输入尺寸导致转换失败"><a class="markdownIt-Anchor" href="#问题动态batch或可变输入尺寸导致转换失败"></a> <strong>问题</strong>：动态Batch或可变输入尺寸导致转换失败。</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.onnx.export(</span><br><span class="line">    model, dummy_input, &quot;yolov5_dynamic.onnx&quot;,</span><br><span class="line">    opset_version=11,</span><br><span class="line">    input_names=[&quot;input&quot;], output_names=[&quot;output&quot;],</span><br><span class="line">    dynamic_axes=&#123;</span><br><span class="line">        &quot;input&quot;: &#123;0: &quot;batch_size&quot;&#125;,   # 让 input 的 batch 维度 (dim=0) 变为动态</span><br><span class="line">        &quot;output&quot;: &#123;0: &quot;batch_size&quot;&#125;   # 让 output 的 batch 维度 (dim=0) 变为动态</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="2-写占位符号替换乱七八糟的算子"><a class="markdownIt-Anchor" href="#2-写占位符号替换乱七八糟的算子"></a> 2 写占位符号替换乱七八糟的算子</h1>
<p><img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/image-20250315101551480.png" alt="image-20250315101551480" style="zoom: 50%;"> <img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/image-20250315101542696.png"></p>
<h2 id="代码怎么写"><a class="markdownIt-Anchor" href="#代码怎么写"></a> 代码怎么写</h2>
<h3 id="todo"><a class="markdownIt-Anchor" href="#todo"></a> TODO</h3>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/" data-id="cmanj8o23000dlcv4dnxrcuh0" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/onnx/" rel="tag">onnx</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月12日-onnx4-图优化" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/" class="article-date">
  <time class="post-time" datetime="2025-03-12T14:14:32.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">12</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/">2025年3月12日 onnx3</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="图优化"><a class="markdownIt-Anchor" href="#图优化"></a> 图优化</h1>
<h3 id="1"><a class="markdownIt-Anchor" href="#1"></a> 1</h3>
<p><img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/image-20250312222559294.png" alt="image-20250312222559294"></p>
<p><strong>引擎能够针对特定硬件进行深度优化，实现最佳的性能和效率</strong></p>
<p><img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/image-20250312224327684.png" alt="image-20250312224327684"></p>
<h3 id="3-查看netron节点"><a class="markdownIt-Anchor" href="#3-查看netron节点"></a> 3 查看netron节点</h3>
<p>ONNX的optimizer模块提供部分图优化的功能，例如最常用的：fuse_bn_into_conv，fuse_pad_into_conv等等。</p>
<p><img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/image-20250312232520596.png" alt="image-20250312232520596"></p>
<h3 id="2-为什么需要forward_fuse"><a class="markdownIt-Anchor" href="#2-为什么需要forward_fuse"></a> 2. 为什么需要forward_fuse？</h3>
<ul>
<li>
<p>forward_fuse通常用于把卷积和BN层合并，或者把多个卷积分支合并，减少计算量，提高推理速度。</p>
</li>
<li>
<p>如果你的模块没有BN层，或者结构很简单，不需要合并，也应该定义一个forward_fuse，让它和forward一样。</p>
</li>
</ul>
<h3 id="4-onnxslim-模块未安装简化失败"><a class="markdownIt-Anchor" href="#4-onnxslim-模块未安装简化失败"></a> <code>4 onnxslim</code> 模块未安装，简化失败</h3>
<h4 id="简化-onnx-的主要作用"><a class="markdownIt-Anchor" href="#简化-onnx-的主要作用"></a> ✅ 简化 ONNX 的主要作用：</h4>
<table>
<thead>
<tr>
<th>好处</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>📦 减少模型大小</td>
<td>去除冗余算子与中间变量，减小 <code>.onnx</code> 文件大小</td>
</tr>
<tr>
<td>🚀 加速推理速度</td>
<td>简化计算图后，ONNX Runtime / TensorRT 推理更快</td>
</tr>
<tr>
<td>🔧 提高兼容性</td>
<td>某些部署平台（如 OpenVINO、MNN）对简化后的模型兼容性更强</td>
</tr>
<tr>
<td>🧩 易于可视化分析</td>
<td>模型结构更清晰，利于在 Netron 中查看和理解</td>
</tr>
</tbody>
</table>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/" data-id="cmanj8o210008lcv42fxu34el" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/onnx/" rel="tag">onnx</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月11日-yolov5-5-0训练" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/11/2025%E5%B9%B43%E6%9C%8811%E6%97%A5-yolov5-5-0%E8%AE%AD%E7%BB%83/" class="article-date">
  <time class="post-time" datetime="2025-03-11T03:59:58.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">11</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/11/2025%E5%B9%B43%E6%9C%8811%E6%97%A5-yolov5-5-0%E8%AE%AD%E7%BB%83/">2025年3月11日 yolov5 5.0训练</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="sad"><a class="markdownIt-Anchor" href="#sad"></a> sad</h2>
<h2 id="报错"><a class="markdownIt-Anchor" href="#报错"></a> 报错</h2>
<p>库的版本要匹配上 否则会出现不确定错误</p>
<ol>
<li>
<p>pydantic_core._pydantic_core.ValidationError: 1 validation error for Settings<br>
anonymous<br>
Input should be ‘allow’, ‘must’ or ‘never’ [type=literal_error, input_value=‘true’, input_type=str]<br>
For further information visit <a target="_blank" rel="noopener" href="https://errors.pydantic.dev/2.10/v/literal_error">https://errors.pydantic.dev/2.10/v/literal_error</a></p>
<p>建议：wandb 下降版本<code>pip install wandb==0.12.10</code></p>
</li>
<li>
<p>You are using <code>torch.load</code> with <code>weights_only=False</code> (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling</p>
<p>修改代码中加载模型权重的部分</p>
<p><code> run_id = torch.load(weights, weights_only=True).get('wandb_id')  # 添加weights_only=True</code></p>
</li>
<li>
<p>File “F:\Pydata\DL_NEW\YOLO\yolov5-5.0\utils\datasets.py”, line 411, in <strong>init</strong><br>
bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index</p>
</li>
</ol>
<p><code>pip install numpy==1.22.4       # 部分新库兼容的中间版本</code></p>
<ol start="4">
<li>
<p>TypeError: Descriptors cannot be created directly.<br>
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc &gt;= 3.19.0.<br>
If you cannot immediately regenerate your protos, some other possible workarounds are:</p>
<ol>
<li>Downgrade the protobuf package to 3.20.x or lower.</li>
<li>Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).</li>
</ol>
<p><code>pip install protobuf==3.20.1 </code></p>
</li>
<li>
<p>是</p>
</li>
</ol>
<p>代码出现的问题:</p>
<ol>
<li>
<p>手动添加SSF层</p>
</li>
<li>
<p>缺少logger</p>
<p>手动添加 <code>logger = logging.getLogger(__name__)</code></p>
</li>
<li></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/11/2025%E5%B9%B43%E6%9C%8811%E6%97%A5-yolov5-5-0%E8%AE%AD%E7%BB%83/" data-id="cm8q1tfhp000upcv4f52t1sn8" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/yolo/" rel="tag">yolo</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月10日-onnx3进阶使用与常见问题" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-onnx3%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" class="article-date">
  <time class="post-time" datetime="2025-03-10T13:15:13.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">10</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-onnx3%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/">2025年3月10日 onnx2</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li></li>
</ul>
<h2 id="导出报错"><a class="markdownIt-Anchor" href="#导出报错"></a> 导出报错</h2>
<p>Unsupported: ONNX export of convolution for kernel of unknown shape”，这通常与动态形状或无法推断的卷积核尺寸有</p>
<ol>
<li>
<p>静态化Reshape操作</p>
</li>
<li>
<p>修复多级融合的TracerWarning fused_cls = sum(w * c for w, c in zip(weights_cls, preds_cls))</p>
<p><code>sum(w * c for w, c in zip(...))</code>中的迭代操作会被PyTorch的JIT Tracer识别为动态控制流，导致ONNX导出时无法生成静态计算图。这种Python层的迭代操作在模型跟踪阶段会被视为潜在动态行为，从而触发TracerWarning</p>
</li>
</ol>
<h3 id="2-importerror-dll-load-failed-while-importing-onnx_cpp2py_export-动态链接库dll初始化例程失败"><a class="markdownIt-Anchor" href="#2-importerror-dll-load-failed-while-importing-onnx_cpp2py_export-动态链接库dll初始化例程失败"></a> 2 ImportError: DLL load failed while importing onnx_cpp2py_export: 动态链接库(DLL)初始化例程失败。</h3>
<blockquote>
<p>重新安装 onnx</p>
</blockquote>
<h2 id="结构报错"><a class="markdownIt-Anchor" href="#结构报错"></a> 结构报错</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="1-为什么导出的onnx会有那么多identity这是什么怎么消除"><a class="markdownIt-Anchor" href="#1-为什么导出的onnx会有那么多identity这是什么怎么消除"></a> 1 为什么导出的onnx会有那么多Identity，这是什么，怎么消除</h3>
<p><img src="/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-onnx3%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20250310215555781.png" alt="image-20250310215555781"></p>
<ol>
<li><strong>数据传递占位符</strong> Identity节点的核心功能是将输入张量原样输出，不进行任何计算</li>
<li><strong>框架转换机制缺陷</strong></li>
<li><strong>自定义算子副作用</strong></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-onnx3%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" data-id="cmanj8o1s0006lcv45hyj3669" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/onnx/" rel="tag">onnx</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/4/">&amp;laquo; pre</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/6/">next &amp;raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Weakliy_Blog</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>115</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>33</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="Github">
          Github
        </a>
      
    </div>

    <div class="friend-link">
      <h2>联系我</h2>
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2024 - 2025 Weakliy<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">首页</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">总览</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">xxx</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">xxxx</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>