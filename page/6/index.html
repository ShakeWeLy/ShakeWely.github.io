<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Weakliy_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Weakliy_Blog">
<meta property="og:url" content="https://shakewely.github.io/page/6/index.html">
<meta property="og:site_name" content="Weakliy_Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Weakliy">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Weakliy_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>102</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>31</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main">
  
    <article id="post-2025年2月10日-轻量化神经网络3" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/02/10/2025%E5%B9%B42%E6%9C%8810%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C3/" class="article-date">
  <time class="post-time" datetime="2025-02-10T03:40:45.000Z" itemprop="datePublished">
    <span class="post-month">2月</span><br/>
    <span class="post-day">10</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/02/10/2025%E5%B9%B42%E6%9C%8810%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C3/">2025年2月10日 轻量化神经网络3</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> <strong>Introduction</strong></h1>
<p>近期卷积网络的设计除了注重准确率之外，还需要兼顾运行性能，特别是在移动设备上的运行性能，这使得卷积神经网络的设计变得更加难，主要有以下难点：</p>
<ul>
<li>Intractable design space，由于卷积网络参数很多，导致设计空间十分复杂，目前很多方法提出自动化搜索，能够简化人工设计的流程，但这种方法一般需要大量的算力。</li>
<li>Nontransferable optimality，卷积网络的性能取决于很多因素，比如输入分辨率和目标设备，不同的分辨率需要调整不同的网络参数，而相同block在不同的设备上的效率也可能大不相同，所以需要对网络在特定的条件下进行特定的调优。</li>
<li>Inconsistent efficiency metrics，大多数效率指标不仅与网络结构相关，也和目标设备上的软硬件设置有关。为了简化，很多研究都采用硬件无关的指标来表示卷积的效率，比如FLOPs，但FLOPs并不能总等同于性能，还跟block的实现方式相关，这使得网络的设计更加困难。</li>
</ul>
<h1 id="nas"><a class="markdownIt-Anchor" href="#nas"></a> NAS</h1>
<h2 id="总结nas-发展历程"><a class="markdownIt-Anchor" href="#总结nas-发展历程"></a> <strong>总结：NAS 发展历程</strong></h2>
<table>
<thead>
<tr>
<th>阶段</th>
<th>方法</th>
<th>主要创新点</th>
<th>计算成本</th>
<th>代表性模型</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>早期 NAS</strong></td>
<td>强化学习 NAS</td>
<td>RNN 控制器搜索网络结构</td>
<td>高</td>
<td>NASNet</td>
</tr>
<tr>
<td><strong>进化 NAS</strong></td>
<td>进化算法 NAS</td>
<td>变异 + 交叉进化优化网络</td>
<td>高</td>
<td>AmoebaNet</td>
</tr>
<tr>
<td><strong>梯度优化 NAS</strong></td>
<td>DARTS</td>
<td>采用梯度下降进行高效搜索</td>
<td>低</td>
<td>DARTS、ProxylessNAS</td>
</tr>
<tr>
<td><strong>高效 NAS</strong></td>
<td>Efficient NAS</td>
<td>共享参数 + 复合缩放 + 硬件感知搜索</td>
<td>低</td>
<td>EfficientNet、FBNet、OFA</td>
</tr>
</tbody>
</table>
<h1 id="fbnet"><a class="markdownIt-Anchor" href="#fbnet"></a> FBNet</h1>
<img src="/2025/02/10/2025%E5%B9%B42%E6%9C%8810%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C3/image-20250219134545540.png" style="zoom:67%;">
<p>将 <strong>硬件性能约束</strong>（如浮点运算量 FLOPs、内存使用量、计算延迟等）引入到 NAS 的搜索过程，使得网络架构不仅能够实现高精度，还能在指定硬件上具有良好的执行效率。</p>
<p>BNet 的工作流程可以分为以下几个步骤：</p>
<ol>
<li><strong>硬件感知的目标函数</strong>：<br>
在设计过程中，FBNet 将目标硬件（如移动设备、嵌入式设备等）的约束（如内存、计算量等）纳入考虑。FBNet 的目标是最小化 <strong>计算资源的消耗</strong>，同时保证较高的 <strong>分类精度</strong>。这个目标函数是硬件感知的，旨在寻找在硬件上性能最优的网络架构。</li>
<li><strong>可微分架构搜索</strong>：<br>
FBNet 使用了一种基于梯度优化的搜索方法，即将 NAS 搜索过程转化为可微分的优化问题。这使得 FBNet 可以在较少的计算资源下快速找到高效的网络架构。具体来说，FBNet 在 <strong>超网络（SuperNet）</strong> 中进行架构搜索，超网络包含了多种候选网络结构，通过训练和优化选择最优的架构。</li>
<li><strong>选择模块</strong>：<br>
在 FBNet 中，网络结构的选择是模块化的，每个模块（如卷积、深度可分离卷积等）都有多个候选结构，而这些候选结构的选择在搜索过程中是通过<strong>可微分的路径选择</strong>来实现的。最终，FBNet 在候选模块中选择一个最优的结构。</li>
<li><strong>搜索策略</strong>：<br>
为了加速搜索过程，FBNet 使用了 <strong>混合搜索策略</strong>，即结合了 <strong>强化学习</strong> 和 <strong>梯度优化</strong> 两种方法。强化学习用于生成架构的候选方案，而梯度优化则用于对这些方案进行优化。通过这种方式，FBNet 能够在复杂的搜索空间中找到最优的架构。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/02/10/2025%E5%B9%B42%E6%9C%8810%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C3/" data-id="cm8q1tfhg000hpcv4f8qg1hic" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E3%80%81model/" rel="tag">轻量化神经网络、model</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年2月9日-轻量化神经网络2" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/" class="article-date">
  <time class="post-time" datetime="2025-02-09T07:21:36.000Z" itemprop="datePublished">
    <span class="post-month">2月</span><br/>
    <span class="post-day">09</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/">2025年2月9日 轻量化神经网络2</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="lcnet"><a class="markdownIt-Anchor" href="#lcnet"></a> LCNet</h1>
<blockquote>
<p>CPU端的最强轻量型架构</p>
</blockquote>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250219133119899.png" alt="image-20250219133119899" style="zoom:33%;">
<h3 id="主要解决方案"><a class="markdownIt-Anchor" href="#主要解决方案"></a> 主要解决方案：</h3>
<ol>
<li>采用H-Swish作为激活函数，性能大幅提升，而推理速度几乎不变。</li>
<li>在网络合适的位置添加少量的SE模块可以进一步提升模型性能；实验表明：当把SE置于模型的尾部时，它具有更好的效果。因此，我们仅将SE模块添加到接近网络尾部的模块即可, 这种处理方式具有更好的精度-速度平衡。</li>
<li>根据MixNet的实验论证结果:在一定范围内大的卷积核可以提升模型的性能，但是超过这个范围会有损模型的性能。本文通过实验总结了一些更大的卷积核在不同位置的作用，类似SE模块的位置，更大的卷积核在网络的中后部作用更明显。比如5x5卷积。</li>
<li>GAP后使用更大的1x1卷积层；在GoogLeNet之后，GAP（Global-Average-Pooling）后往往直接接分类层，但是在轻量级网络中，这样会导致GAP后提取的特征没有得到进一步的融合和加工。如果在此后使用一个更大的1x1卷积层（等同于FC层），GAP后的特征便不会直接经过分类层，而是先进行了融合，并将融合的特征进行分类。这样可以在不影响模型推理速度的同时大大提升准确率。</li>
<li>使用dropout技术可以进一步提升模型的精度。</li>
</ol>
<p><strong>低秩卷积的引入</strong>：</p>
<ul>
<li>低秩卷积的引入是 LCNet 的最大创新之一。通过矩阵低秩分解，LCNet 能够将卷积操作的计算复杂度降到最低，从而显著减少了卷积神经网络的计算负担和内存消耗。</li>
</ul>
<p><strong>高效的通道剪枝</strong>：</p>
<ul>
<li>LCNet 提出了通道剪枝的概念，即对卷积层中的不重要通道进行剪枝，减少冗余计算。这个过程通过分析每个通道的贡献，剔除那些对最终输出没有显著影响的通道，从而大幅减小模型的规模。</li>
</ul>
<p><strong>集成深度可分离卷积</strong>：</p>
<ul>
<li>深度可分离卷积已经被证明是提升计算效率的一种有效手段，LCNet 将其应用到各个卷积层中，通过拆解卷积操作来减少计算量和参数量，提高了模型的运行效率。</li>
</ul>
<p><strong>硬件友好设计</strong>：</p>
<ul>
<li>LCNet 强调了硬件友好的设计理念，特别是在移动设备和嵌入式设备上。网络架构通过采用低计算量的卷积和模块化设计，使得 LCNet 在计算资源受限的设备上表现更好。</li>
</ul>
<p><strong>优化的注意力机制</strong>：</p>
<ul>
<li>LCNet 在设计中还结合了高效的注意力机制，通过优化网络对输入信息的加权方式，使得网络能够更好地关注到重要特征，从而提升分类性能，同时保持较低的计算开销。</li>
</ul>
<h1 id="squeezenet"><a class="markdownIt-Anchor" href="#squeezenet"></a> SqueezeNet</h1>
<h2 id="fire-module"><a class="markdownIt-Anchor" href="#fire-module"></a> Fire Module</h2>
<p><strong>Fire Module</strong>：每个 Fire Module 由两个主要部分组成：</p>
<ul>
<li><strong>Squeeze层</strong>：一个1x1的卷积层，用来减少特征图的深度。</li>
<li><strong>Expand层</strong>：两个分支，一个是1x1卷积，另一个是3x3卷积，用来增加特征图的深度。</li>
</ul>
<p>通过这种结构，SqueezeNet能够有效地减少参数量，而不牺牲太多的准确度。</p>
<p><strong>减少全连接层的参数</strong>：SqueezeNet中没有传统的全连接层，而是使用全局平均池化（Global Average Pooling）来替代。这样大大减少了参数数量，且仍然保留了模型的表现力。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat([x1, x2], 1)</span><br></pre></td></tr></table></figure>
<h1 id="mobilenethttpsblogcsdnnetqq_37555071articledetails108393809"><a class="markdownIt-Anchor" href="#mobilenethttpsblogcsdnnetqq_37555071articledetails108393809"></a> [MobileNet][<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37555071/article/details/108393809">https://blog.csdn.net/qq_37555071/article/details/108393809</a>]</h1>
<h2 id="深度可分离卷积depthwise-separable-convolutions"><a class="markdownIt-Anchor" href="#深度可分离卷积depthwise-separable-convolutions"></a> 深度可分离卷积(Depthwise Separable Convolutions)</h2>
<p>（Depthwise Separable Convolutions）</p>
<p><strong>深度卷积（Depthwise Convolution）</strong>：对每个输入通道独立进行卷积操作，而不是像传统卷积那样对所有通道进行卷积。这大大减少了计算量。</p>
<p><strong>逐点卷积（Pointwise Convolution）</strong>：即1x1卷积，用于将深度卷积的输出进行线性组合，融合通道信息。</p>
<p><strong>宽度和分辨率的可调性</strong>： MobileNet引入了两个超参数，分别是<strong>宽度系数（Width Multiplier）**和**分辨率系数（Resolution Multiplier）</strong>，使得网络的大小和计算量可以根据实际需求进行调整。</p>
<ul>
<li><strong>宽度系数（α）</strong>：用于控制网络每一层的通道数。通过减小α的值，可以降低网络的复杂度和参数数量。</li>
<li><strong>分辨率系数（ρ）</strong>：用于控制输入图像的分辨率，通过减小分辨率来减少计算量。</li>
</ul>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209162740618.png" alt="image-20250209162740618"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, groups=in_channels, bias=<span class="literal">False</span>)</span><br><span class="line">// groups=in_channels</span><br></pre></td></tr></table></figure>
<h1 id="shufflenet"><a class="markdownIt-Anchor" href="#shufflenet"></a> ShuffleNet</h1>
<p><strong>深度可分离卷积（Depthwise Separable Convolution） 和</strong></p>
<h2 id="通道混洗channel-shuffle"><a class="markdownIt-Anchor" href="#通道混洗channel-shuffle"></a> <strong>通道混洗（Channel Shuffle）</strong></h2>
<p>通道混洗技术会在<strong>每个卷积层的输出中打乱通道的顺序</strong>，使得不同通道的特征能够进行更好的融合，从而提高模型的表达能力和准确率。</p>
<h2 id="分组卷积grouped-convolution"><a class="markdownIt-Anchor" href="#分组卷积grouped-convolution"></a> <strong>分组卷积（Grouped Convolution）</strong></h2>
<p>为了进一步提高网络的计算效率，ShuffleNet 采用了 <strong>分组卷积（Grouped Convolution）</strong>。分组卷积将输入通道分成多个组，每个组内的通道与一个独立的卷积核进行卷积，从而减少了卷积运算的计算量。</p>
<h1 id="googlenet"><a class="markdownIt-Anchor" href="#googlenet"></a> GoogLeNet</h1>
<h2 id="inception块"><a class="markdownIt-Anchor" href="#inception块"></a> Inception块</h2>
<p>各种模块全都要</p>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209172824970.png" alt="image-20250209172824970" style="zoom:50%;">
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209172918099.png" alt="image-20250209172918099" style="zoom:67%;">
<h2 id="xception-块"><a class="markdownIt-Anchor" href="#xception-块"></a> <strong>Xception 块</strong></h2>
<p>极限情况</p>
<h1 id="efficientnet"><a class="markdownIt-Anchor" href="#efficientnet"></a> EfficientNet</h1>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209173848541.png" alt="image-20250209173848541" style="zoom: 80%;"><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174104028.png" alt="image-20250209174104028" style="zoom: 67%;"></p>
<h2 id="原理"><a class="markdownIt-Anchor" href="#原理"></a> 原理</h2>
<h3 id="网络架构搜索nas"><a class="markdownIt-Anchor" href="#网络架构搜索nas"></a> <strong>网络架构搜索（NAS）</strong>：</h3>
<ul>
<li>EfficientNet 使用了 <strong>神经架构搜索</strong>（NAS）来自动化地找到最适合的卷积神经网络架构。在这个过程中，作者通过 NAS 来寻找一个 <strong>基础架构</strong>，该架构在计算效率和性能之间取得了最佳的平衡。</li>
</ul>
<h3 id="优化网络的宽度-深度和分辨率"><a class="markdownIt-Anchor" href="#优化网络的宽度-深度和分辨率"></a> <strong>优化网络的宽度、深度和分辨率</strong>：</h3>
<ul>
<li>EfficientNet 在进行网络扩展时，并不是简单地增加网络的层数或通道数，而是采用了更加 <strong>均衡的增长策略</strong>。通过在深度、宽度和输入图像分辨率上都进行扩展，模型能够获得更强的表达能力，同时保持较低的计算成本。</li>
</ul>
<h3 id="高效的卷积操作"><a class="markdownIt-Anchor" href="#高效的卷积操作"></a> <strong>高效的卷积操作</strong>：</h3>
<ul>
<li>EfficientNet 采用了高效的卷积操作，如 <strong>Depthwise Separable Convolution</strong>，以进一步减少计算量。</li>
</ul>
<p>通过结构搜索（NAS, Neural Architecture Search）和优化策略，在精度和计算效率之间找到最好的平衡。</p>
<h2 id="mbconvefficientnet块"><a class="markdownIt-Anchor" href="#mbconvefficientnet块"></a> MBConv/EfficientNet块</h2>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209180216944.png" alt="image-20250209180216944"></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174529781.png" alt="image-20250209174529781"></p>
<h3 id="倒残差结构inverted-residuals"><a class="markdownIt-Anchor" href="#倒残差结构inverted-residuals"></a> 倒残差结构（Inverted Residuals)</h3>
<p><img src="https://pic2.zhimg.com/v2-7c42cff2fa3c346d2e41be95848fc619_1440w.jpg" alt="img"></p>
<blockquote>
<p>使用逐通道卷积和逐点卷积来提高计算效率。</p>
</blockquote>
<h2 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制"></a> 注意力机制</h2>
<h3 id="se模块squeeze-and-excitation-block"><a class="markdownIt-Anchor" href="#se模块squeeze-and-excitation-block"></a> SE模块（Squeeze-and-Excitation Block）</h3>
<p>来源于人类视觉系统中的注意机制：大脑会根据不同的视觉刺激，<strong>自动聚焦于最重要的信息，并忽略不相关的部分</strong>。SE模块通过类似的机制，<strong>自动为每个通道分配不同的重要性</strong>，从而增强模型对重要特征的敏感度。</p>
<ul>
<li>
<p><strong>queeze-and-Excitation</strong>（SE）模块，提升了特征通道之间的依赖关系.仅在 <strong>通道维度</strong> 上进行加权</p>
</li>
<li>
<p>通过一个 <strong>“Squeeze”</strong> 操作来压缩空间维度信息，再通过 <strong>“Excitation”</strong> 操作生成通道权重</p>
</li>
</ul>
<p><strong>Squeeze（压缩）</strong>：</p>
<ul>
<li>输入是一个 <strong>H×W×C</strong> 的特征图，其中 H和 W 分别是空间维度的高度和宽度，C 是通道数。</li>
<li><strong>通过全局平均池化</strong>（Global Average Pooling）对每个通道进行压缩。即对每个通道的空间维度（H×W）求平均，得到一个 <strong>C</strong> 维的向量，表示每个通道的“全局特征”。</li>
</ul>
<p><strong>Excitation（激励）</strong>：</p>
<ul>
<li>对通道的全局特征向量进行<strong>两层全连接层操作</strong>，其中第二层是激活函数（通常是 <strong>Sigmoid</strong>），生成每个通道的 <strong>注意力系数</strong>。</li>
<li>第一个全连接层是 <strong>瓶颈层（bottleneck layer）</strong>，通常通过降低维度来减少计算量。然后通过第二个全连接层，将输出恢复到原始通道数，得到每个通道的权重。</li>
</ul>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174719710.png" alt="image-20250209174719710" style="zoom:67%;">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_se_block</span>(<span class="params">self, channels, se_ratio</span>):</span><br><span class="line">        reduction = <span class="built_in">int</span>(channels * se_ratio)</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">            nn.AdaptiveAvgPool2d(<span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(channels, reduction, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(reduction, channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h4 id="空间注意力机制"><a class="markdownIt-Anchor" href="#空间注意力机制"></a> 空间注意力机制</h4>
<p>对特征图的<strong>每个位置</strong>分配一个权重来决定哪些空间区域应该被网络更多关注</p>
<blockquote>
<p>人类的视觉注意力更多的是<strong>空间注意力</strong>，也就是对图片上不同区域赋予不同的权重</p>
</blockquote>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209183640934.png" alt="image-20250209183640934" style="zoom:67%;">
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250303211827687.png" alt="image-20250303211827687"></p>
<h4 id="通道注意力机制"><a class="markdownIt-Anchor" href="#通道注意力机制"></a> 通道注意力机制</h4>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250303211752599.png" alt="image-20250303211752599"></p>
<h4 id="cbam注意力"><a class="markdownIt-Anchor" href="#cbam注意力"></a> CBAM注意力</h4>
<p>CBAM 通过融合 <strong>通道注意力机制</strong> 和 <strong>空间注意力机制</strong></p>
<h4 id="视觉自注意力non-local"><a class="markdownIt-Anchor" href="#视觉自注意力non-local"></a> 视觉自注意力(Non Local))</h4>
<p>用来在不引入过多计算量的基础上提高CNN网络的<strong>远程依赖</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209184403579.png" alt="image-20250209184403579"></p>
<blockquote>
<p>我可能先识别到篮球，然后在其周围找到人和篮筐，并根据他们的位置我们才能判断这个图是不是表达人在灌篮这个动作。其中，篮球位置可以理解为<strong>查询点</strong>，周边（可能离得较远）的人和篮筐就是<strong>查询点对应的关联区域</strong>。</p>
</blockquote>
<p>查询点到关联区域的对应可以加深CNN网络对场景<strong>从局部到整体</strong>的理解，因此可以有效提高CNN网络在视觉任务的效率。</p>
<ul>
<li>
<p>该模块建立了图像中<strong>每个像素/区域之间的关联</strong>，有效提升了CNN网络的感受野</p>
</li>
<li>
<p>对每个空间位置生成与所有其他位置的<strong>相似度</strong>。</p>
</li>
<li>
<p>基于<strong>相似度进行加权</strong>，使得每个位置可以融合其他位置的信息。</p>
</li>
</ul>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209184638406.png" alt="image-20250209184638406"></p>
<blockquote>
<p>其大概的运算过程是：</p>
<p>（1）为了降低运算量，采用三个不同1x1卷积层进行维度减半，即图上的 x→ϕ(x),θ(x),g(x) ;</p>
<p>（2）为 ϕ(x),θ(x),g(x) 按照w,h维度进行铺平，即图上三个flatten；</p>
<p>（3）利用铺平的 ϕ(x),θ(x) 进行矩阵乘法运算，并通过softmax获得各空间位置之间的<strong>关联图</strong>（即图中的 vc ），很明显这个关联图的大小为 (w×h,w×h) ，表征着各个像素点（区域）之间的联系；</p>
<p>（4）将铺平转置的 g(x) 与vc进行矩阵乘法，获得 y ；</p>
<p>（5）对y进行展开与特征提取（Conv4），获得注意力（refined）;</p>
<p>（6）利用注意力调整原始输入的分布，Over!!!</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/350760243">https://zhuanlan.zhihu.com/p/350760243</a></p>
</blockquote>
<h4 id="non-local改进版-gcnet"><a class="markdownIt-Anchor" href="#non-local改进版-gcnet"></a> Non Local改进版 — GCNet</h4>
<p>原因:<strong>不同查询点（区域）居然对应相同的attention map</strong></p>
<img src="https://pic4.zhimg.com/v2-31d05dfac01c6ae64bd5bf4e52ffc069_1440w.jpg" alt="img" style="zoom: 33%;">
<p>与查询（点）无关的依赖（query-independent dependency）。那么这是否意味着原始Non Local中<strong>query分支可以剪去不要</strong>呢</p>
<img src="https://pic4.zhimg.com/v2-dc2339ac78de452e286317dd259070f5_1440w.jpg" alt="img" style="zoom: 50%;">
<img src="https://pic3.zhimg.com/v2-104058d724746316b12298ec27fafe26_1440w.jpg" alt="img" style="zoom:50%;">
<h3 id="dfc-注意力模块"><a class="markdownIt-Anchor" href="#dfc-注意力模块"></a> DFC 注意力模块</h3>
<p>利用固定权重的全连接层来创建具有全局感受野的注意力图，以捕 获长距离空间位置的依赖关系</p>
<h1 id="efficientdet"><a class="markdownIt-Anchor" href="#efficientdet"></a> EfficientDet</h1>
<h2 id="结构概述"><a class="markdownIt-Anchor" href="#结构概述"></a> <strong>结构概述</strong></h2>
<h3 id="1-backboneefficientnet"><a class="markdownIt-Anchor" href="#1-backboneefficientnet"></a> 1 Backbone（EfficientNet）</h3>
<ul>
<li>EfficientDet 的 backbone 使用了 EfficientNet 作为特征提取器。EfficientNet 是一种使用<strong>复合缩放</strong>策略的高效网络，在目标检测任务中，EfficientDet 对 EfficientNet 进行调整和优化，使得其能更好地适应目标检测的要求。</li>
</ul>
<p>BiFPN（双向特征金字塔网络）**</p>
<ul>
<li>BiFPN 通过对低层和高层特征的加权融合，使得低层和高层的特征能够互相补充，提升了多尺度特征的利用率。</li>
</ul>
<h3 id="2-head"><a class="markdownIt-Anchor" href="#2-head"></a> 2 Head</h3>
<ul>
<li><strong>分类头</strong>：用于对目标进行分类，预测每个框的类别。</li>
<li><strong>回归头</strong>：用于回归目标的边界框坐标。</li>
</ul>
<h3 id="3-复合缩放"><a class="markdownIt-Anchor" href="#3-复合缩放"></a> 3 复合缩放</h3>
<ul>
<li>EfficientDet 通过复合缩放策略调整模型的深度、宽度和输入分辨率，使得模型可以在不同的硬件环境下进行灵活的调整，同时提升了精度和效率。</li>
</ul>
<h2 id="fpn到bifpn"><a class="markdownIt-Anchor" href="#fpn到bifpn"></a> FPN.到BiFPN</h2>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209190732084.png" style="zoom: 80%;">
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224653761.png" style="zoom: 80%;">
<blockquote>
<p>a. 网络只是针对某一特点的分辨率进行训练, 如果只是在测试和推理阶段使用图像金字塔的话, 可能导致训练和测试推理过程不匹配</p>
<p>b. 利用单个高层特征图(主干网络产生)进行物体的分类和bounding box的回归</p>
<p>c. 在 <strong>多个不同尺度的特征图（如 38×38、19×19、10×10）</strong> 上直接预测目标框。</p>
<p>d 尽管在SSD中我们已经使用了特征金字塔, 但该金字塔中的所有要素都处于不同的比例, 并且由于网络中层的深度不同而存在巨大的语义鸿沟. 高分辨率地图具有低级语义特征, 而低分辨率地图具有较高的语义特征, 这会损害其对象识别的表示能力.</p>
</blockquote>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209223353104.png" alt="image-20250209223353104" style="zoom:50%;">
<blockquote>
<p>先对高阶特征进行上采样, 然后使用横向连接将其与低阶特征进行组合, 该横向连接基本上是1x1卷积, 然后进行求和,</p>
</blockquote>
<h3 id="fully-connected-fpn-and-nas-fpn"><a class="markdownIt-Anchor" href="#fully-connected-fpn-and-nas-fpn"></a> Fully connected FPN and NAS-FPN</h3>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224903212.png" alt="image-20250209224903212"></p>
<blockquote>
<p>a. 传统fpn</p>
<p>b. 全连接网络</p>
<p>c. NAS</p>
</blockquote>
<h3 id="panet"><a class="markdownIt-Anchor" href="#panet"></a> PANet</h3>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224555819.png" alt="image-20250209224555819"></p>
<blockquote>
<p>添加<strong>自下而上的路径</strong>以增强FPN中的自上而下的路径</p>
</blockquote>
<h3 id="simplified-fpn-and-bifpn"><a class="markdownIt-Anchor" href="#simplified-fpn-and-bifpn"></a> Simplified FPN and BiFPN</h3>
<p><img src="https://pic4.zhimg.com/v2-faec285a27615d8829af43172d9d1385_1440w.jpg" alt="img"></p>
<blockquote>
<p>a. 如果一个节点只有一个输入边并且没有特征融合, 那么它对特征网络的融合贡献较小, 这个节点可以删除(Simplified PANET)</p>
<p>b. 添加一条额外的连接路径,融合更多功能(BiFPN). 这点其实跟skip connection很相似</p>
<p>c. 重复叠加相同的特征网络层 复合缩放</p>
</blockquote>
<h2 id="权重计算"><a class="markdownIt-Anchor" href="#权重计算"></a> 权重计算</h2>
<p>快速归一化融合特征网络.计算路径,计算出不同特征节点的输入最合适的权值</p>
<p><img src="https://pic4.zhimg.com/v2-a0f1319eae0571829c79b1a70d4fc1b9_1440w.jpg" alt="img"></p>
<h2 id="compound-scaling"><a class="markdownIt-Anchor" href="#compound-scaling"></a> Compound Scaling</h2>
<p>复合缩放的目标是在任何给定的资源约束下最大化模型精度, 因此可以表述为优化问题.</p>
<p><strong>对网络深度、宽度和分辨率中的任何尺度进行缩放都可以提高精度, 但是当模型足够大时, 这种放大的收益会减弱。</strong></p>
<p><strong>FLOPS</strong>是floating point operations per second的缩写, 意指每秒浮点运算次数, 理解为计算速度. 是一个衡量硬件性能的指标. 我们假设我们能使用的FLOPS是2.</p>
<p><img src="https://pic2.zhimg.com/v2-032dfea7e52345c3f26a543e3dbcc6fd_1440w.jpg" alt="img"></p>
<blockquote>
<p>a. 对于网络模型depth来说, 加倍深度会使得FLOPS加倍.</p>
</blockquote>
<p><img src="https://pic1.zhimg.com/v2-4f1414b59ea6700387f0dea2dac0d878_1440w.jpg" alt="img"></p>
<blockquote>
<p>b. 对于网络模型width来说, 由于width(#channel)的增加导致卷积计算的路径平方级增加, 因此加倍宽度会使得FLOPS加4倍.</p>
</blockquote>
<p><img src="https://pica.zhimg.com/v2-646a538d15c17d28145024953ff90eda_1440w.jpg" alt="img"></p>
<blockquote>
<p>c. 对于网络模型resolution来说, 和width的情况一样, 由于resolution的增加会导致feather map呈现平方级扩张, 因此加倍图像分辨率也会使得FLOPS加4倍.</p>
</blockquote>
<p><strong>复合缩放公式:</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209230157789.png" alt="image-20250209230157789"></p>
<p><strong>网格搜索</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209230342459.png" alt></p>
<p><strong>复合缩放的总结图:</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209231222947.png" alt="image-20250209231222947"></p>
<h1 id="ghostnet"><a class="markdownIt-Anchor" href="#ghostnet"></a> GhostNet</h1>
<p>特征图存在<strong>冗余性</strong> 廉价操作 生成 Ghost 特征图</p>
<h2 id="原理-2"><a class="markdownIt-Anchor" href="#原理-2"></a> 原理</h2>
<h2 id="ghost-卷积"><a class="markdownIt-Anchor" href="#ghost-卷积"></a> Ghost 卷积</h2>
<p>利用计算量较低的线性操作来增加特征图的数量， 从而在保持输出特征图不变的同时，显著地降低了计算复杂度</p>
<ol>
<li>使用1×1卷积对输入特征进行压缩，以获取少量特征图</li>
<li>这部分特征图通过线性变换生成另一部分特征图</li>
<li>将两部分特征图进行拼接，形 成最终的输出特征图</li>
</ol>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250303184803366.png" alt="image-20250303184803366" style="zoom:67%;">
<h1 id="mobilevit"><a class="markdownIt-Anchor" href="#mobilevit"></a> MobileViT</h1>
<p><strong>融合 CNN 和 Transformer</strong>：通过将卷积操作与 Transformer 结合，模型能够同时捕捉局部和全局特征，提高了特征表达能力。</p>
<p><strong>高效的特征处理</strong>：通过<strong>展开和折叠操作</strong>(unfold )，将特征映射到序列空间进行处理，然后再映射回原始空间，实现了高效的特征处理。</p>
<p><strong>模型图：</strong></p>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250210155707027.png" alt="image-20250210155707027" style="zoom:50%;">
<h2 id="mobile-vit-块"><a class="markdownIt-Anchor" href="#mobile-vit-块"></a> Mobile ViT 块</h2>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250210155825206.png" alt="image-20250210155825206" style="zoom: 50%;">
<blockquote>
<p>…</p>
</blockquote>
<p>减少self-attention</p>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250210160135377.png" alt="image-20250210160135377" style="zoom:50%;"> 
<blockquote>
<p>冗余信息多,相邻token信息差异小</p>
</blockquote>
<h3 id="fold"><a class="markdownIt-Anchor" href="#fold"></a> fold</h3>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250210160342687.png" alt="image-20250210160342687" style="zoom:33%;">
<h1 id="emo结合-cnn-和-transformerhttpsdeveloperaliyuncomarticle1210407"><a class="markdownIt-Anchor" href="#emo结合-cnn-和-transformerhttpsdeveloperaliyuncomarticle1210407"></a> [EMO：结合 CNN 和 Transformer][<a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1210407">https://developer.aliyun.com/article/1210407</a>]</h1>
<h3 id="1-特征提取网络sd-ghostnet"><a class="markdownIt-Anchor" href="#1-特征提取网络sd-ghostnet"></a> 1. 特征提取网络（SD-Ghostnet）</h3>
<ul>
<li><strong>输入图像</strong>：原始图像作为输入。</li>
<li><strong>Conv(64,6,2,2)</strong>：首先通过一个卷积层，输出通道数为64，核大小为6x6，步长为2，填充为2。</li>
<li><strong>S-GhostConv (128,3,2)</strong> 和 <strong>SD-Ghost(128)</strong>：经过一系列的S-GhostConv和SD-Ghost模块，逐步增加通道数到128。</li>
<li><strong>S-GhostConv (256,3,2)</strong> 和 <strong>SD-Ghost(256)</strong>：进一步通过S-GhostConv和SD-Ghost模块，通道数增加到256。</li>
<li><strong>S-GhostConv (512,3,2)</strong> 和 <strong>SD-Ghost(512)</strong>：继续通过S-GhostConv和SD-Ghost模块，通道数增加到512。</li>
<li><strong>S-GhostConv (1024,3,2)</strong> 和 <strong>SD-Ghost(1024)</strong>：最后通过S-GhostConv和SD-Ghost模块，通道数增加到1024。</li>
<li><strong>SPPF(1024,5)</strong>：空间金字塔池化模块，进一步增强特征表示。</li>
</ul>
<h3 id="2-特征融合网络ffn"><a class="markdownIt-Anchor" href="#2-特征融合网络ffn"></a> 2. 特征融合网络（FFN）</h3>
<ul>
<li><strong>Concat(512)</strong>：将特征提取网络中不同层次的特征进行拼接，形成512通道的特征图。</li>
<li><strong>Upsample(256)</strong>：对特征图进行上采样，通道数减少到256。</li>
<li><strong>GSCovn (256,1,1)</strong>：通过一个1x1的卷积层调整通道数。</li>
<li><strong>VOVGSCSP (256)</strong>：通过VOVGSCSP模块进一步处理特征。</li>
<li><strong>GSCovn (256,3,2)</strong>：通过一个1x1的卷积层调整通道数。</li>
<li><strong>Concat(512)</strong>：再次拼接特征，形成512通道的特征图。</li>
<li><strong>VOVGSCSP (512)</strong>：通过VOVGSCSP模块进一步处理特征。</li>
<li><strong>GSCovn (512,3,2)</strong>：通过一个1x1的卷积层调整通道数。</li>
<li><strong>Concat(1024)</strong>：再次拼接特征，形成1024通道的特征图。</li>
<li><strong>VOVGSCSP (1024)</strong>：通过VOVGSCSP模块进一步处理特征。</li>
</ul>
<h3 id="3-多尺度检测网络mdn"><a class="markdownIt-Anchor" href="#3-多尺度检测网络mdn"></a> 3. 多尺度检测网络（MDN）</h3>
<ul>
<li><strong>CBAM (256)</strong>：通过CBAM注意力机制模块，增强特征表示。</li>
<li><strong>Conv2d (256)</strong>：通过一个卷积层，输出通道数为256。</li>
<li><strong>CBAM (512)</strong>：通过CBAM注意力机制模块，增强特征表示。</li>
<li><strong>Conv2d (512)</strong>：通过一个卷积层，输出通道数为512。</li>
<li><strong>CBAM (1024)</strong>：通过CBAM注意力机制模块，增强特征表示。</li>
<li><strong>Conv2d (1024)</strong>：通过一个卷积层，输出通道数为1024。</li>
<li><strong>输出图像</strong>：最终生成输出图像。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/" data-id="cm6yfcd2b0000mcv4hi073hzf" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E3%80%81model/" rel="tag">轻量化神经网络、model</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年2月5日-轻量化神经网络" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="article-date">
  <time class="post-time" datetime="2025-02-05T08:28:10.000Z" itemprop="datePublished">
    <span class="post-month">2月</span><br/>
    <span class="post-day">05</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">2025年2月5日 轻量化神经网络1</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h1>
<p><img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205162820154.png" alt="image-20250205162820154"></p>
<h1 id="知识蒸馏"><a class="markdownIt-Anchor" href="#知识蒸馏"></a> 知识蒸馏</h1>
<h2 id="soft-target"><a class="markdownIt-Anchor" href="#soft-target"></a> soft target</h2>
<img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205163735260.png" alt="image-20250205163735260" style="zoom:33%;">
<blockquote>
<p>更多信息+</p>
</blockquote>
<h4 id="蒸馏温度"><a class="markdownIt-Anchor" href="#蒸馏温度"></a> 蒸馏温度</h4>
<img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205164432943.png" alt="image-20250205164432943" style="zoom:50%;">
<img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205164308480.png" alt="image-20250205164308480" style="zoom:67%;">
<h4 id="训练"><a class="markdownIt-Anchor" href="#训练"></a> 训练</h4>
<img src="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20250205164454289.png" alt="image-20250205164454289" style="zoom:33%;">
<h1 id="量化"><a class="markdownIt-Anchor" href="#量化"></a> 量化</h1>
<h1 id="剪枝"><a class="markdownIt-Anchor" href="#剪枝"></a> 剪枝</h1>
<h2 id="定义"><a class="markdownIt-Anchor" href="#定义"></a> 定义</h2>
<h3 id="剪枝方法总结表"><a class="markdownIt-Anchor" href="#剪枝方法总结表"></a> <strong>剪枝方法总结表</strong></h3>
<table>
<thead>
<tr>
<th>剪枝方法</th>
<th>主要剪枝对象</th>
<th>优点</th>
<th>缺点</th>
<th>示例方法/应用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>权重剪枝（Weight Pruning）</strong></td>
<td>单个权重</td>
<td>剪枝率高，可应用于各种网络</td>
<td>需要稀疏矩阵优化，不适合硬件加速</td>
<td>TensorFlow <code>tf.sparsity</code>, PyTorch <code>torch.nn.utils.prune</code></td>
</tr>
<tr>
<td><strong>结构化剪枝（Structured Pruning）</strong></td>
<td>神经元、通道、卷积核</td>
<td>适合硬件加速</td>
<td>剪枝率受限，可能影响模型结构</td>
<td><code>Channel Pruning</code>, <code>Filter Pruning</code></td>
</tr>
<tr>
<td><strong>低秩分解剪枝（Low-Rank Approximation）</strong></td>
<td>整体权重矩阵</td>
<td>计算加速明显</td>
<td>需要额外的分解计算</td>
<td>SVD 分解, CP 分解, Tensor Train 分解</td>
</tr>
<tr>
<td><strong>剪枝 + 训练（Prune and Fine-tune）</strong></td>
<td>结合剪枝和微调</td>
<td>可恢复精度</td>
<td>训练时间增加</td>
<td>迭代剪枝（Iterative Pruning）, 一次性剪枝（One-shot Pruning）</td>
</tr>
<tr>
<td><strong>软剪枝（Soft Pruning）</strong></td>
<td>权重</td>
<td>更温和的剪枝方式</td>
<td>需要更多训练步骤</td>
<td>逐步缩小权重（Weight Decay），平滑剪枝（Gradual Magnitude Pruning）</td>
</tr>
<tr>
<td><strong>剪枝 + 蒸馏（Pruning with Distillation）</strong></td>
<td>剪枝后蒸馏</td>
<td>精度损失小</td>
<td>需要额外教师模型</td>
<td><code>Knowledge Distillation (KD)</code>, MobileBERT, TinyBERT</td>
</tr>
<tr>
<td><strong>幸运票剪枝（Lottery Ticket Hypothesis）</strong></td>
<td>子网络</td>
<td>保留重要子结构</td>
<td>训练步骤复杂</td>
<td>训练大模型后剪枝，重新初始化训练</td>
</tr>
<tr>
<td><strong>正则化剪枝（Regularization-based Pruning）</strong></td>
<td>L1/L2 约束</td>
<td>无需额外剪枝步骤</td>
<td>训练需额外超参数</td>
<td><code>L1 Regularization</code>, <code>Group Lasso Pruning</code></td>
</tr>
<tr>
<td><strong>动态剪枝（Movement Pruning）</strong></td>
<td>Transformer 模型</td>
<td>适合 NLP</td>
<td>计算复杂度高</td>
<td><code>BERT Pruning</code>, <code>MobileBERT</code></td>
</tr>
<tr>
<td><strong>自动剪枝（AutoML Pruning）</strong></td>
<td>NAS/强化学习</td>
<td>自动优化</td>
<td>计算成本高</td>
<td><code>AMC (AutoML for Model Compression)</code>, <code>Meta-Pruning</code></td>
</tr>
</tbody>
</table>
<img src="https://ucc.alicdn.com/yysinyik4knec/developer-article1644450/20241207/de25bb1591524da481677d9008ecc078.png?x-oss-process=image/resize,w_1400/format,webp" alt="image" style="zoom: 67%;">
<ul>
<li><strong>非结构化剪枝（Unstructured Pruning）</strong>：直接删除模型中的某些参数，通常基于参数的绝对值大小。这种方法可以实现较高的压缩比，但可能会破坏模型的整体结构。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 应用权重剪枝</span><br><span class="line">def apply_pruning(model, amount=0.2):</span><br><span class="line">    for name, module in model.named_modules():</span><br><span class="line">        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):</span><br><span class="line">            prune.l1_unstructured(module, name=&#x27;weight&#x27;, amount=amount)</span><br><span class="line">            print(f&quot;Applied pruning on &#123;name&#125;&quot;)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>结构化剪枝（Structured Pruning）</strong>：删除模型中的特定结构单元，如滤波器、通道或层。这种方法不会破坏模型的整体结构，更适合硬件加速。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">threshold = 0.01</span><br><span class="line">for name, module in model.named_modules():</span><br><span class="line">    if isinstance(module, nn.Conv2d):</span><br><span class="line">        # 计算每个卷积核的L2范数</span><br><span class="line">        kernel_norms = torch.norm(module.weight, dim=(1, 2, 3))</span><br><span class="line">        # 找到小于阈值的卷积核索引</span><br><span class="line">        prune_indices = torch.where(kernel_norms &lt; threshold)[0]</span><br><span class="line">        # 将这些卷积核的权重置零</span><br><span class="line">        module.weight[prune_indices] = 0</span><br></pre></td></tr></table></figure>
<ul>
<li>
<h4 id="基于梯度的剪枝"><a class="markdownIt-Anchor" href="#基于梯度的剪枝"></a> <strong>基于梯度的剪枝</strong></h4>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">def gradient_magnitude_pruning(weight, gradient, percentile=0.5):</span><br><span class="line">    &quot;&quot;&quot;基于梯度幅值剪枝权重&quot;&quot;&quot;</span><br><span class="line">    num_zeros = round(weight.numel() * percentile)  # 计算剪枝元素数量</span><br><span class="line">    threshold = gradient.abs().view(-1).kthvalue(num_zeros).values  # 计算剪枝阈值</span><br><span class="line">    mask = gradient.abs() &gt; threshold  # 生成掩码</span><br><span class="line">    weight.mul_(mask.to(weight.device))  # 应用掩码剪枝</span><br><span class="line">    return weight</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="注意力迁移"><a class="markdownIt-Anchor" href="#注意力迁移"></a> 注意力迁移</h1>
<p><a target="_blank" rel="noopener" href="https://github.com/szagoruyko/attention-transfer?tab=readme-ov-file">https://github.com/szagoruyko/attention-transfer?tab=readme-ov-file</a></p>
<h2 id="定义-2"><a class="markdownIt-Anchor" href="#定义-2"></a> 定义</h2>
<ul>
<li>注意力迁移的思想来源于知识蒸馏，但与<strong>传统知识蒸馏主要关注最后层的知识不同，注意力迁移关注训练过程中特征图中的知识</strong>。</li>
<li>其目的是通过将教师网络的注意力图迁移到学生网络，提升学生网络的性能，同时实现模型的轻量化。</li>
</ul>
<h2 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制"></a> 注意力机制</h2>
<ul>
<li><strong>空间域（Spatial Domain）</strong>：关注特征空间信息，决定空间中哪些区域重要。例如，通过动态注意力机制来选择性地关注图像中的特定区域。</li>
<li><strong>通道域（Channel Domain）</strong>：关注通道信息，如Squeeze-and-Excitation Networks（SENet）。SENet通过全局平均池化、降维再升维的方式为通道分配权重，增强重要通道的特征。</li>
<li><strong>混合域（Mixed Domain）</strong>：同时关注空间域和通道域，如CBAM等注意力机制，综合考虑特征空间和通道信息来生成注意力图。</li>
</ul>
<h2 id="算法部分"><a class="markdownIt-Anchor" href="#算法部分"></a> 算法部分</h2>
<ul>
<li><strong>基于激活的注意力迁移（Activation-based Attention Transfer）</strong>：
<ul>
<li>在前馈过程中，通过教师网络的激活特征图来引导学生网络的学习。</li>
<li>教师网络的激活特征图反映了输入数据在不同区域的重要性，<strong>学生网络通过模仿这些激活特征图</strong>来学习关注重要的区域。</li>
</ul>
</li>
<li><strong>基于梯度的注意力迁移（Gradient-based Attention Transfer）</strong>：
<ul>
<li>在反馈过程中，对教师网络和学生网络的交叉熵损失函数分别求梯度，<strong>将教师网络的梯度作为注意力图转移到学生网络</strong>。</li>
<li>关注那些对输出影响大的区域，通过构造损失函数，使得学生网络的梯度注意力图与教师网络的梯度注意力图接近，从而实现知识的迁移。</li>
</ul>
</li>
</ul>
<h1 id="低秩分解"><a class="markdownIt-Anchor" href="#低秩分解"></a> 低秩分解</h1>
<h1 id="轻量化网络结构"><a class="markdownIt-Anchor" href="#轻量化网络结构"></a> 轻量化网络结构</h1>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" data-id="cm6rncay50000xgv42v0x1l8p" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E3%80%81model/" rel="tag">轻量化神经网络、model</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年1月9日-语言模型" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time class="post-time" datetime="2025-01-07T16:22:05.000Z" itemprop="datePublished">
    <span class="post-month">1月</span><br/>
    <span class="post-day">08</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">2025年1月9日 语言模型</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li>预训练 浅层特征不变 高层改变
<ol>
<li>冻结</li>
<li>fine-tuning</li>
</ol>
</li>
</ol>
<h2 id="统计语言模型"><a class="markdownIt-Anchor" href="#统计语言模型"></a> 统计语言模型</h2>
<p><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250103124916040.png" alt="image-20250103124916040"></p>
<ol>
<li>马尔科夫链</li>
<li></li>
</ol>
<h2 id="神经网络语言模型"><a class="markdownIt-Anchor" href="#神经网络语言模型"></a> 神经网络语言模型</h2>
<p>word embedding 例子</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>word embedding 就是 预训练的frozen</p>
<p><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002222562.png" alt></p>
<p><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002349457.png" alt="image-20250108002349457" style="zoom:50%;"><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002355983.png" alt="image-20250108002355983"><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002359696.png" alt="image-20250108002359696" style="zoom:50%;"><img src="/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/image-20250108002402739.png" alt="image-20250108002402739" style="zoom:50%;"></p>
<h2 id="改进的注意力机制"><a class="markdownIt-Anchor" href="#改进的注意力机制"></a> 改进的注意力机制</h2>
<h3 id><a class="markdownIt-Anchor" href="#"></a> </h3>
<h3 id="1-lora-低秩近似在-transformer-中的应用"><a class="markdownIt-Anchor" href="#1-lora-低秩近似在-transformer-中的应用"></a> 1 LORA 低秩近似在 Transformer 中的应用</h3>
<p>在 Transformer 中，低秩近似主要应用于自注意力计算，特别是通过优化注意力矩阵的存储和计算来提高效率。以下是两种常见的实现方式：</p>
<ol>
<li>
<p><strong>Linformer</strong>：Linformer 是一种基于低秩近似的优化方法。Linformer 的核心思想是将标准自注意力中的注意力矩阵近似为低秩矩阵。Linformer 假设注意力矩阵可以用低秩矩阵来近似，因此将其从一个全连接矩阵（n×n）降为一个n×k  的矩阵（其中 kkk 是较小的值，通常比 nnn 小得多）。通过这种低秩近似，计算复杂度从</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>降低为</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo>⋅</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n \cdot k)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span></span></p>
<p>大大减少了计算量，特别是在长序列时效果显著。</p>
</li>
<li>
<p><strong>Performer</strong>：Performer 是另一种采用低秩近似的 Transformer 变种，它通过引入一种叫做 <strong>线性注意力</strong> 的方法，采用<strong>随机特征来近似注意力矩阵</strong>的乘积。这种方法能够将原本的</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>计算复杂度降低为</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span></span></p>
<p>，使得 Transformer 可以处理非常长的序列。</p>
</li>
</ol>
<h4 id="低秩近似的优点"><a class="markdownIt-Anchor" href="#低秩近似的优点"></a> 低秩近似的优点</h4>
<ul>
<li><strong>减少计算复杂度</strong>：通过将高秩矩阵分解为低秩矩阵，降低了计算复杂度，从而加快了训练和推理速度。</li>
<li><strong>节省内存</strong>：低秩矩阵的存储通常比原始矩阵所需的内存少，因此节省了计算过程中的内存消耗。</li>
<li><strong>适用于长序列</strong>：对于长序列，低秩近似可以大大提高 Transformer 的效率，使其能够处理更长的输入序列而不遇到内存瓶颈。</li>
</ul>
<h4 id="低秩近似的缺点"><a class="markdownIt-Anchor" href="#低秩近似的缺点"></a> 低秩近似的缺点</h4>
<ul>
<li><strong>性能损失</strong>：低秩近似虽然可以减少计算复杂度，但可能会带来一定的性能损失，尤其是在近似效果不佳时。较低的秩可能无法捕捉到原矩阵中的复杂关系，因此可能影响模型的精度。</li>
<li><strong>近似精度问题</strong>：低秩近似依赖于如何选择低秩矩阵的秩（rank）。如果选择的秩过小，可能会导致较大的误差，从而影响模型的效果。</li>
</ul>
<p>、</p>
<h3 id="lora-的应用步骤"><a class="markdownIt-Anchor" href="#lora-的应用步骤"></a> LoRA 的应用步骤</h3>
<h4 id="1-选择适当的层"><a class="markdownIt-Anchor" href="#1-选择适当的层"></a> 1. <strong>选择适当的层</strong></h4>
<ul>
<li>通常，LoRA 应用在 Transformer 中的关键层，如注意力层和前馈层。选择这些层是因为它们通常是最有影响力的层，影响模型的表达能力。</li>
</ul>
<h4 id="2-添加低秩矩阵"><a class="markdownIt-Anchor" href="#2-添加低秩矩阵"></a> 2. <strong>添加低秩矩阵</strong></h4>
<ul>
<li>对于每个需要修改的层（如注意力层中的权重矩阵），LoRA 在其上加上低秩矩阵。通常，这些低秩矩阵的秩较小，因此不会显著增加模型的复杂度。</li>
</ul>
<h4 id="3-训练低秩矩阵"><a class="markdownIt-Anchor" href="#3-训练低秩矩阵"></a> 3. <strong>训练低秩矩阵</strong></h4>
<ul>
<li>在微调过程中，仅训练低秩矩阵的参数，而保持原始的预训练权重不变。这意味着只有少量参数需要更新，从而加速训练并降低存储需求。</li>
</ul>
<h4 id="4-合成模型"><a class="markdownIt-Anchor" href="#4-合成模型"></a> 4. <strong>合成模型</strong></h4>
<ul>
<li>在微调结束后，最终的模型将包括原始的预训练权重和经过 LoRA 微调的低秩矩阵</li>
</ul>
<h3 id="代码实现"><a class="markdownIt-Anchor" href="#代码实现"></a> 代码实现</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="adapter"><a class="markdownIt-Anchor" href="#adapter"></a> Adapter</h2>
<p>适</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/01/08/2025%E5%B9%B41%E6%9C%889%E6%97%A5-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" data-id="cm6rncay70001xgv40x8a6tc6" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/llm/" rel="tag">llm</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年1月11日-视觉模型" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time class="post-time" datetime="2024-12-31T07:20:05.000Z" itemprop="datePublished">
    <span class="post-month">12月</span><br/>
    <span class="post-day">31</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/">2025年1月2日 视觉模型</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>端到端单阶段</p>
<p>两阶段的</p>
<p>RCNN</p>
<h2 id="rcnn"><a class="markdownIt-Anchor" href="#rcnn"></a> RCNN</h2>
<h3 id="rcnn-2"><a class="markdownIt-Anchor" href="#rcnn-2"></a> RCNN</h3>
<h4 id="0-原理"><a class="markdownIt-Anchor" href="#0-原理"></a> 0 原理</h4>
<p><strong><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184356637.png" alt="image-20250104184356637" style="zoom: 33%;"></strong></p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250221144723650.png" alt="image-20250221144723650" style="zoom:50%;"> 
<h4 id="1-ss算法"><a class="markdownIt-Anchor" href="#1-ss算法"></a> 1 ss算法</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184501872.png" alt="image-20250104184501872" style="zoom: 33%;">
<h4 id="2-提取特征"><a class="markdownIt-Anchor" href="#2-提取特征"></a> 2 提取特征</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184859288.png" alt="image-20250104184859288" style="zoom: 33%;">
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184531836.png" alt="image-20250104184531836" style="zoom:50%;">
<h4 id="3-svm"><a class="markdownIt-Anchor" href="#3-svm"></a> 3 SVM</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104184713372.png" alt="image-20250104184713372" style="zoom: 33%;">
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185007538.png" alt="image-20250104185007538" style="zoom: 33%;">
<p><strong>IOU</strong></p>
<blockquote>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185250090.png" alt="image-20250104185250090" style="zoom: 50%;"><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185256627.png" alt="image-20250104185256627" style="zoom: 25%;"></p>
</blockquote>
<blockquote>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185308808.png" alt="image-20250104185308808" style="zoom: 33%;"> <img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104185322806.png" alt="image-20250104185322806" style="zoom:33%;"></p>
</blockquote>
<h4 id="4-回归分类器"><a class="markdownIt-Anchor" href="#4-回归分类器"></a> 4 回归分类器</h4>
<p>pass</p>
<h4 id="优缺"><a class="markdownIt-Anchor" href="#优缺"></a> 优缺</h4>
<ul>
<li>冗余</li>
<li>慢</li>
<li>空间大</li>
</ul>
<h3 id="fast-rcnn"><a class="markdownIt-Anchor" href="#fast-rcnn"></a> Fast RCNN</h3>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104190121582.png" alt="image-20250104190121582" style="zoom:50%;">
<h4 id="0-原理-2"><a class="markdownIt-Anchor" href="#0-原理-2"></a> 0 原理</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250221152009699.png" alt="image-20250221152009699" style="zoom: 80%;">  
 <img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250221144938969.png" alt="image-20250221144938969" style="zoom:50%;"> 
<h4 id="1-减少重复计算特征"><a class="markdownIt-Anchor" href="#1-减少重复计算特征"></a> 1 减少重复计算特征</h4>
<p>通过全连接层进行</p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104191656317.png" alt="image-20250104191656317" style="zoom:33%;">
<p><strong>正负样本</strong></p>
<blockquote></blockquote>
<h4 id="2-分类器"><a class="markdownIt-Anchor" href="#2-分类器"></a> 2 分类器</h4>
<p>全连接层实现</p>
<h4 id="3-边界框回归器"><a class="markdownIt-Anchor" href="#3-边界框回归器"></a> 3 边界框回归器</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104192439278.png" alt="image-20250104192439278" style="zoom: 33%;">
<h4 id="4-损失计算"><a class="markdownIt-Anchor" href="#4-损失计算"></a> 4 损失计算</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104192659858.png" alt="image-20250104192659858" style="zoom:33%;">
<h3 id="faster-rcnn"><a class="markdownIt-Anchor" href="#faster-rcnn"></a> Faster RCNN</h3>
<h4 id="0-原理-3"><a class="markdownIt-Anchor" href="#0-原理-3"></a> 0 原理</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194051582.png" alt="image-20250104194051582" style="zoom:33%;"> 
<p><strong>就是用RPN替换SS算法</strong></p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194210537.png" alt="image-20250104194210537" style="zoom:33%;">  
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194406137.png" alt="image-20250104194406137" style="zoom: 33%;">  
<h4 id="1-rpn"><a class="markdownIt-Anchor" href="#1-rpn"></a> 1 RPN</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194441284.png" alt="image-20250104194441284" style="zoom: 50%;">	
<ul>
<li>3x3 卷积</li>
<li>在并联两个全连接层 生成:背景和前景 + 4个参数</li>
<li></li>
<li></li>
</ul>
<h4 id="2-anchor"><a class="markdownIt-Anchor" href="#2-anchor"></a> 2 anchor</h4>
<p><strong>实现原理</strong></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194722542.png" alt="image-20250104194722542" style="zoom:33%;"><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194733782.png" alt="image-20250104194733782" style="zoom:33%;"></p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104194922010.png" alt="image-20250104194922010" style="zoom: 25%;"> 
<p>anchor 个数</p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104195441622.png" alt="image-20250104195441622" style="zoom: 25%;">  
<p><strong>小感受野也可以预测大特征</strong></p>
<blockquote>
 <img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104195137512.png" alt="image-20250104195137512" style="zoom:33%;">  
</blockquote>
<h4 id="3-损失计算"><a class="markdownIt-Anchor" href="#3-损失计算"></a> 3 损失计算</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104200305676.png" alt="image-20250104200305676" style="zoom:33%;">
<h2 id="ssd"><a class="markdownIt-Anchor" href="#ssd"></a> SSD</h2>
<h3 id="原理"><a class="markdownIt-Anchor" href="#原理"></a> 原理</h3>
<p>在<strong>六个不同的层上预测不同大小的目标</strong>[ 因为:卷积程度越深 感受野越大 抽象的特征越大 那么细节就越少]</p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250221160156493.png" alt="image-20250221160156493" style="zoom:67%;">
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104171147389.png" alt="image-20250104171147389" style="zoom:33%;">
<ul>
<li>b预测小目标 🐱</li>
<li>C预测大目标 🐕</li>
</ul>
<h4 id="default-box"><a class="markdownIt-Anchor" href="#default-box"></a> default box</h4>
<p>从不同的特征层中产生 每个特征图（feature map）上的像素点为中心生成default box。中心点坐标为特征图位置的映射值，计算公式</p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104171745323.png" alt="image-20250104171745323" style="zoom:67%;">
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172055346.png" alt="image-20250104172055346" style="zoom:67%;">
<h3 id="训练"><a class="markdownIt-Anchor" href="#训练"></a> 训练</h3>
<h4 id="模型"><a class="markdownIt-Anchor" href="#模型"></a> 模型</h4>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104170756080.png" alt="image-20250104170756080"><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104170840590.png" alt="image-20250104170840590" style="zoom: 25%;"></p>
<h4 id="数据处理"><a class="markdownIt-Anchor" href="#数据处理"></a> 数据处理</h4>
<h4 id="损失计算"><a class="markdownIt-Anchor" href="#损失计算"></a> 损失计算</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172613364.png" alt="image-20250104172613364" style="zoom:50%;">
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172751053.png" alt="image-20250104172751053" style="zoom:33%;">
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172759925.png" alt="image-20250104172759925" style="zoom: 33%;">
<h4 id="预测"><a class="markdownIt-Anchor" href="#预测"></a> 预测</h4>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172201462.png" alt="image-20250104172201462"> ]</p>
<p>参数数目</p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104172401969.png" alt="image-20250104172401969" style="zoom: 33%;"> 
<h3 id="优缺-2"><a class="markdownIt-Anchor" href="#优缺-2"></a> 优缺</h3>
<h3 id="qa"><a class="markdownIt-Anchor" href="#qa"></a> QA</h3>
<h1 id="yolo"><a class="markdownIt-Anchor" href="#yolo"></a> YOLO</h1>
<h2 id="yolov1"><a class="markdownIt-Anchor" href="#yolov1"></a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43334693/article/details/129011644?spm=1001.2014.3001.5501">YOLOv1</a></h2>
<ul>
<li>端到端单阶段</li>
<li>目标检测问题看作回归问题</li>
</ul>
<h4 id="bounding-box"><a class="markdownIt-Anchor" href="#bounding-box"></a> bounding box</h4>
<ul>
<li>x——框中心的横坐标</li>
<li>y——框中心的纵坐标</li>
<li>w——框的宽度</li>
<li>h——框的高度</li>
<li>置信度（confidence）</li>
</ul>
<p>在YOLOV1中S = 7 , B = 2即将每个输入图片分成7 × 7 个网格，每个网格将生成2 个预测框，用来框出图片中的物体。 每个框会预测出5个变量值，所以一个网格生成两个框，一个框带有5个属性，所以一个格就需要预测出5 × 2 = 10 个变量值。<br>
在YOLOv1中有<strong>20个类别的物体的条件概率</strong>，所以输出结果的后20个值就表示每一个小网格（grid cell）对应每一类物体的概率，即由该网格生产的两个预测框对应每一类物体的概率。 由此，输出的7 × 7 × 30 向量的每一项含义便清楚了。<br>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104151446113.png" alt="image-20250104151446113" style="zoom: 67%;"></p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104154104316.png" alt="image-20250104154104316" style="zoom: 33%;">
<h4 id="训练-2"><a class="markdownIt-Anchor" href="#训练-2"></a> 训练</h4>
<h5 id="网络结构"><a class="markdownIt-Anchor" href="#网络结构"></a> 网络结构</h5>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/64c2116c3e9f6d55b5aa2a8fab982a26.png" alt="img"></p>
<p>YOLOV1的输入为448 × 448 × 3 图像，输出大小为7 × 7 × 30 向量</p>
<p>在网络结构的最后一层使用的是线性激活函数，其他层使用的是****leaky ReLU****激活函数，YOLOv1中采用的leaky ReLU定义公式如下</p>
<p><img src="https://i-blog.csdnimg.cn/direct/dba9296aa0d24233abe7b02e75e4b7e9.png" alt="img"></p>
<h5 id="数据处理-2"><a class="markdownIt-Anchor" href="#数据处理-2"></a> 数据处理</h5>
<h5 id="损失计算-2"><a class="markdownIt-Anchor" href="#损失计算-2"></a> 损失计算</h5>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104155000144.png" alt="image-20250104155000144" style="zoom:67%;">
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104155310820.png" alt="image-20250104155310820" style="zoom:33%;"> 大小目标对偏移影响不同</p>
<h5 id="预测极大值抑制"><a class="markdownIt-Anchor" href="#预测极大值抑制"></a> 预测–极大值抑制</h5>
<p>7X7X2个bounding box 进行 过滤与非极大值抑制</p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104152002611.png" alt></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/d358fa901b47a00baa710246af0ea197.gif" alt="img"></p>
<h4 id="优缺-3"><a class="markdownIt-Anchor" href="#优缺-3"></a> 优缺</h4>
<p>无法很好地处理小目标和重叠目标</p>
<h4 id="qa-2"><a class="markdownIt-Anchor" href="#qa-2"></a> QA</h4>
<ol>
<li>
<h5 id="为什么两个bounding-box"><a class="markdownIt-Anchor" href="#为什么两个bounding-box"></a> 为什么两个bounding box</h5>
</li>
</ol>
<p>每个 bounding box 都有一组独立的参数，包括中心坐标、宽度、高度和置信度，能够分别拟合不同的目标。</p>
<h2 id="yolov2"><a class="markdownIt-Anchor" href="#yolov2"></a> YOLOV2</h2>
<h4 id="1-bn-加入"><a class="markdownIt-Anchor" href="#1-bn-加入"></a> 1 BN 加入</h4>
<h4 id="2-anchor-2"><a class="markdownIt-Anchor" href="#2-anchor-2"></a> 2 anchor</h4>
<p>K-mean聚类实现</p>
<p>模型学习如何调整预定义的 anchor，而不是从零开始预测边界框的所有参数。</p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104164542277.png" alt="image-20250104164542277" style="zoom: 67%;"> 
<h4 id="3-pass-through-layer"><a class="markdownIt-Anchor" href="#3-pass-through-layer"></a> 3 pass through layer</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104160704522.png" alt="image-20250104160704522" style="zoom:67%;"> 
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104160931404.png" alt="image-20250104160931404" style="zoom:50%;"> 
<h5 id="4-多尺度数据输入"><a class="markdownIt-Anchor" href="#4-多尺度数据输入"></a> 4 多尺度数据输入</h5>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250104161259611.png" alt="image-20250104161259611" style="zoom:50%;"> 
<h4 id="faster"><a class="markdownIt-Anchor" href="#faster"></a> Faster</h4>
<p>1</p>
<h2 id="yolov3"><a class="markdownIt-Anchor" href="#yolov3"></a> YOLOV3</h2>
<h4 id="单标签分类改进为多标签分类"><a class="markdownIt-Anchor" href="#单标签分类改进为多标签分类"></a> 单标签分类改进为多标签分类</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105125615278.png" alt="image-20250105125615278" style="zoom:50%;"> 
<h4 id="pan"><a class="markdownIt-Anchor" href="#pan"></a> PAN</h4>
<h3 id="yolov4"><a class="markdownIt-Anchor" href="#yolov4"></a> YOLOV4</h3>
<h3 id="1-原理"><a class="markdownIt-Anchor" href="#1-原理"></a> 1 原理</h3>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105142450863.png" alt="image-20250105142450863"><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105142605476.png" alt="image-20250105142605476" style="zoom:67%;"></p>
<h3 id="2-输入端"><a class="markdownIt-Anchor" href="#2-输入端"></a> 2 输入端</h3>
<h5 id="sat自对抗训练"><a class="markdownIt-Anchor" href="#sat自对抗训练"></a> SAT自对抗训练</h5>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151656124.png" alt="image-20250105151656124" style="zoom:67%;">
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151712577.png" alt="image-20250105151712577" style="zoom:67%;">
<h5 id="label-smoothing类标签平滑"><a class="markdownIt-Anchor" href="#label-smoothing类标签平滑"></a> Label Smoothing类标签平滑</h5>
<h3 id="3-网络结构"><a class="markdownIt-Anchor" href="#3-网络结构"></a> 3 网络结构</h3>
<h4 id="1-backbone"><a class="markdownIt-Anchor" href="#1-backbone"></a> 1 Backbone</h4>
<h5 id="31-csp"><a class="markdownIt-Anchor" href="#31-csp"></a> 3.1 CSP</h5>
<h5 id="img-src2025年1月11日-视觉模型image-20250105130506026png-altimage-20250105130506026-stylezoom50"><a class="markdownIt-Anchor" href="#img-src2025年1月11日-视觉模型image-20250105130506026png-altimage-20250105130506026-stylezoom50"></a> <img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105130506026.png" alt="image-20250105130506026" style="zoom:50%;"></h5>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105152215756.png" alt="image-20250105152215756" style="zoom:50%;"> 
<h4 id="4-neck"><a class="markdownIt-Anchor" href="#4-neck"></a> 4 Neck</h4>
<p>一个颈部neck由几个自下而上的路径和几个自上而下的路径组成。具有该机制的网络包括特征金字塔网络(FPN)、路径汇聚网络(PAN)、BiFPN和NAS-FPN。</p>
<h5 id="41-fpn"><a class="markdownIt-Anchor" href="#41-fpn"></a> 4.1 FPN</h5>
<p>引入了自底向上的路径，使得底层信息更容易传到顶部</p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150718121.png" alt="image-20250105150718121"></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150726295.png" alt="image-20250105150726295"></p>
<h5 id="42-pan"><a class="markdownIt-Anchor" href="#42-pan"></a> 4.2 PAN</h5>
<p>特征层之间融合时是直接通过addition的方式进行融合的，而Yolov4中则采用在通道方向concat拼接操作融合的</p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150948205.png" alt="image-20250105150948205" style="zoom:67%;">
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150823004.png" alt="image-20250105150823004"></p>
<h5 id="43-spp"><a class="markdownIt-Anchor" href="#43-spp"></a> 4.3 SPP</h5>
<p>空间金字塔池化 特征提取池化</p>
<p>通过在输入特征图上<strong>采用不同尺度的池化窗口</strong>（如1×1、2×2、4×4 等），SPP 能够从不同的空间范围内有效地捕获图像中不同大小和比例的目标特征</p>
<blockquote>
<p>旨在解决卷积神经网络中固定大小输入的限制。它能够对任意大小的 输入特征图进行处理，并在不同尺度下提取特征，从而显著增强模型对不同大小目标的感 知能力</p>
</blockquote>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250303181539006.png" alt="image-20250303181539006"></p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105150606229.png" alt="image-20250105150606229" style="zoom:50%;">
<h3 id="4-bof"><a class="markdownIt-Anchor" href="#4-bof"></a> 4 BoF</h3>
<p>我们把这些只会改变培训策略或只增加培训成本的方法称为“bag of freebies”。</p>
<h4 id="1-数据增强"><a class="markdownIt-Anchor" href="#1-数据增强"></a> 1 数据增强</h4>
<h4 id="2-解决数据集中语义分布偏差问题"><a class="markdownIt-Anchor" href="#2-解决数据集中语义分布偏差问题"></a> 2 解决数据集中语义分布偏差问题</h4>
<p>不同类之间存在数据不平衡的问题</p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143153315.png" alt="image-20250105143153315" style="zoom: 67%;"> 
<h4 id="3-边界框bbox回归的目标函数"><a class="markdownIt-Anchor" href="#3-边界框bbox回归的目标函数"></a> 3 边界框(BBox)回归的目标函数 ??</h4>
<p>直接估计BBox中每个点的坐标值是要将这些点作为自变量来处理，但实际上并没有考虑对象本身的完整性</p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143449548.png" alt="image-20250105143449548" style="zoom:67%;">
<h3 id="5-bos"><a class="markdownIt-Anchor" href="#5-bos"></a> 5 BoS</h3>
<p>对于那些只增加少量推理成本但又能显著提高目标检测精度的插件模块和后处理方法，我们称它们为“bag of specials&quot;</p>
<h4 id="1-增强感受野"><a class="markdownIt-Anchor" href="#1-增强感受野"></a> 1 增强感受野</h4>
<p><strong>①改进的SPP模块</strong></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143750945.png" alt="image-20250105143750945"></p>
<p><strong>②ASPP模块</strong></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143836518.png" alt="image-20250105143836518"></p>
<p><strong>③RFB模块</strong></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143846925.png" alt="image-20250105143846925"></p>
<h4 id="2-注意力机制"><a class="markdownIt-Anchor" href="#2-注意力机制"></a> 2 注意力机制</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143912123.png" alt="image-20250105143912123" style="zoom:50%;"> 
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105143920723.png" alt="image-20250105143920723" style="zoom: 50%;"> 
<h4 id="3-特征融合"><a class="markdownIt-Anchor" href="#3-特征融合"></a> 3 特征融合</h4>
<p><strong>①SFAM：</strong> 主要思想是利用SE模块在多尺度的拼接特征图上进行信道级重加权。</p>
<p><strong>②ASFF：</strong> 使用softmax对多尺度拼接特征图在点维度进行加权。</p>
<p><strong>③BiFPN：</strong> 提出了多输入加权剩余连接来执行按比例的水平重加权，然后添加不同比例的特征图。</p>
<h4 id="4-激活函数"><a class="markdownIt-Anchor" href="#4-激活函数"></a> 4 激活函数</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105144012738.png" alt="image-20250105144012738" style="zoom:50%;"> 
<h3 id="6-注意力机制"><a class="markdownIt-Anchor" href="#6-注意力机制"></a> 6 注意力机制</h3>
<h4 id="61-cbamconvolutional-block-attention-module注意力机制"><a class="markdownIt-Anchor" href="#61-cbamconvolutional-block-attention-module注意力机制"></a> 6.1 **CBAM(Convolutional Block Attention Module)**注意力机制</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151035854.png" alt="image-20250105151035854" style="zoom: 50%;">
<h4 id="62-channel-attention-module通道注意力模块"><a class="markdownIt-Anchor" href="#62-channel-attention-module通道注意力模块"></a> 6.2 <strong>Channel attention module(通道注意力模块)</strong></h4>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151238032.png" alt="image-20250105151238032"></p>
<h4 id="63-attention-module空间注意力模块"><a class="markdownIt-Anchor" href="#63-attention-module空间注意力模块"></a> 6.3 <strong>attention module(空间注意力模块)</strong></h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105151404902.png" alt="image-20250105151404902" style="zoom:80%;">
<h3 id="dropblock正则化"><a class="markdownIt-Anchor" href="#dropblock正则化"></a> Dropblock正则化</h3>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105130645146.png" alt="image-20250105130645146" style="zoom: 50%;"> 
<blockquote>
<p>Q：全连接层上效果很好的Dropout在卷积层上效果并不好？</p>
<pre><code>中间Dropout的方式会随机的删减丢弃一些信息，但Dropblock的研究者认为，卷积层对于这种随机丢弃并不敏感，因为卷积层通常是三层连用：卷积+激活+池化层，池化层本身就是对相邻单元起作用。

而且即使随机丢弃，卷积层仍然可以从相邻的激活单元学习到相同的信息。因此，在全连接层上效果很好的Dropout在卷积层上效果并不好。所以右图Dropblock的研究者则干脆整个局部区域进行删减丢弃。
</code></pre>
</blockquote>
<h2 id="yolov5"><a class="markdownIt-Anchor" href="#yolov5"></a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43334693/article/details/129312409">YOLOV5</a></h2>
<h3 id="1-原理-2"><a class="markdownIt-Anchor" href="#1-原理-2"></a> 1 原理</h3>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105140339482.png" alt="image-20250105140339482" style="zoom: 80%;"> 
<h3 id="2-输入"><a class="markdownIt-Anchor" href="#2-输入"></a> 2 输入</h3>
<p>数据增强</p>
<h3 id="3-网络结构-2"><a class="markdownIt-Anchor" href="#3-网络结构-2"></a> 3 网络结构</h3>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250303181011801.png" alt></p>
<h4 id="31-backbone"><a class="markdownIt-Anchor" href="#31-backbone"></a> 3.1 Backbone</h4>
<h5 id="311-focus-结构"><a class="markdownIt-Anchor" href="#311-focus-结构"></a> 3.1.1 Focus 结构</h5>
<p>4×4的3通道图 像切片后变成2×2的12通道的特征图</p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141242384.png" alt="image-20250105141242384"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/009d2d69aae2b1cb6ecede41530f82bf.png" alt="img"></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141341837.png" alt="image-20250105141341837"></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141346413.png" alt="image-20250105141346413"></p>
<ul>
<li>高分辨率 图像的信息从空间维度转化到通道维度，这一转化不仅保留了大量输入信息，还缩减了输 入尺寸，有助于提升网络的训练和推理速度</li>
</ul>
<h5 id="312-csb"><a class="markdownIt-Anchor" href="#312-csb"></a> 3.1.2 CSB</h5>
<p>结合了卷积、批量归一化以及SiLU 激活函数，这种配置使得该模块能够有效地提取和传递特征信息，加快模型的收敛速度并 增强检测能力。</p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250303180658523.png" alt></p>
<h5 id="313-csp"><a class="markdownIt-Anchor" href="#313-csp"></a> 3.1.3 CSP</h5>
<p>一种用于构建特征提取网络的重要组件。通过引入<strong>跨阶段部分连接</strong>和通道分割来加强特征的传播和利 用，从而提高了模型的性能和效率。</p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250303180919670.png" alt="image-20250303180919670"></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141515679.png" alt="image-20250105141515679"></p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141525595.png" alt="image-20250105141525595" style="zoom:50%;"> 
<h5 id="314-sppf"><a class="markdownIt-Anchor" href="#314-sppf"></a> 3.1.4 SPPF</h5>
<p>SPPF将SPP原来并行的结构<strong>改进为串行结构</strong>，通过指定单一卷积核，<strong>每次池化后的输出直接作为下一个池化的输入</strong></p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250303182202107.png" alt="image-20250303182202107"></p>
<h4 id="32-neck"><a class="markdownIt-Anchor" href="#32-neck"></a> 3.2 Neck</h4>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141614203.png" alt="image-20250105141614203"></p>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105141619565.png" alt="image-20250105141619565" style="zoom: 50%;">
<h5 id="321-路径聚合网络panet"><a class="markdownIt-Anchor" href="#321-路径聚合网络panet"></a> 3.2.1 路径聚合网络（PANet）</h5>
<p>PAN 通过增加<strong>自下而上</strong>的路径来增强 FPN 的结构，</p>
<p>其主要目的是改善信息的流动和特征图的利用效率。</p>
<h5 id="322-特征金字塔网络fpnet"><a class="markdownIt-Anchor" href="#322-特征金字塔网络fpnet"></a> 3.2.2 特征金字塔网络（FPNet）</h5>
<p>FPNet多尺度特征融合的方法，它在提取的特征层之间建立<strong>自上而下</strong>的路径</p>
<p>高层次的语义信息能够与低层次的细节<strong>信息结合</strong> 改进对<strong>小尺寸</strong>目标的检测能力</p>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250303182750649.png" alt="image-20250303182750649"></p>
<h4 id="33-输出端"><a class="markdownIt-Anchor" href="#33-输出端"></a> 3.3 输出端</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250303183300954.png" alt="image-20250303183300954" style="zoom:80%;">
<p>当真实目标的中心点位于网格的左上角或右下角附近时，σ(tx)与σ(ty)的 值可能会接近0或1，这种极端值通常是网络难以实现的</p>
<p>对偏移量进行调整，将其<strong>从（0,1）缩放到（-0.5,1.5）</strong>，确保 模型输出的偏移量保持在0到1的范围</p>
<h3 id="4-损失函数"><a class="markdownIt-Anchor" href="#4-损失函数"></a> 4 损失函数</h3>
<p>总损失是定 位损失、分类损失和置信度损失的加权和，各损失的权重是通过调整超参数进行优化，以 平衡分类、定位和置信度之间的重要性</p>
<h3 id="5-训练策略"><a class="markdownIt-Anchor" href="#5-训练策略"></a> 5 训练策略</h3>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250105123929037.png" alt="image-20250105123929037" style="zoom: 50%;"> 
<h3 id="6-魔改"><a class="markdownIt-Anchor" href="#6-魔改"></a> 6 魔改</h3>
<h4 id="61-网络结构"><a class="markdownIt-Anchor" href="#61-网络结构"></a> 6.1 网络结构</h4>
<img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250303184319327.png" alt="image-20250303184319327" style="zoom:67%;">
<h1 id="fcos"><a class="markdownIt-Anchor" href="#fcos"></a> FCOS</h1>
<h2 id="fcos-2"><a class="markdownIt-Anchor" href="#fcos-2"></a> FCOS</h2>
<p>参考： <a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_46142822/article/details/123958529%E3%80%81">https://blog.csdn.net/weixin_46142822/article/details/123958529、</a></p>
<h3 id="2-fcos-网络框架"><a class="markdownIt-Anchor" href="#2-fcos-网络框架"></a> 2 FCOS 网络框架</h3>
<p><img src="/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/image-20250309153327923.png" alt="image-20250309153327923"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/12/31/2025%E5%B9%B41%E6%9C%8811%E6%97%A5-%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B/" data-id="cm8q1tfhe000bpcv4hr161vro" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/model/" rel="tag">model</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2024年4月18日-深度学习自制框架" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/" class="article-date">
  <time class="post-time" datetime="2024-04-18T12:15:29.000Z" itemprop="datePublished">
    <span class="post-month">4月</span><br/>
    <span class="post-day">18</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/">2024年4月18日 深度学习自制框架</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>b</p>
<p>本书结构</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418201605770.png" alt="image-20240418201605770" style="zoom:67%;">
<h1 id="第一阶段-自动微分"><a class="markdownIt-Anchor" href="#第一阶段-自动微分"></a> 第一阶段 自动微分</h1>
<h2 id="1-变量"><a class="markdownIt-Anchor" href="#1-变量"></a> 1 变量</h2>
<p>pass</p>
<h2 id="2-函数"><a class="markdownIt-Anchor" href="#2-函数"></a> 2 函数</h2>
<p>pass</p>
<h2 id="3-函数连续调用"><a class="markdownIt-Anchor" href="#3-函数连续调用"></a> 3 函数连续调用</h2>
<p>pass</p>
<h2 id="4-数值微分"><a class="markdownIt-Anchor" href="#4-数值微分"></a> 4 数值微分</h2>
<h3 id="1-导数"><a class="markdownIt-Anchor" href="#1-导数"></a> 1 导数</h3>
<p>导数表示</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235609679.png" alt="image-20240418235609679"></p>
<h3 id="2-数值微分"><a class="markdownIt-Anchor" href="#2-数值微分"></a> 2 数值微分</h3>
<p>计算机不能处理极限值 。 因此，这里的 h 表示一个近似值来计算 式 4. 1 就叫做数值微分</p>
<h4 id="21前向差分近似"><a class="markdownIt-Anchor" href="#21前向差分近似"></a> 2.1前向差分近似</h4>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235758166.png" alt="image-20240418235758166"></p>
<h4 id="22中心差分近似"><a class="markdownIt-Anchor" href="#22中心差分近似"></a> 2.2中心差分近似</h4>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235805977.png" alt="image-20240418235805977"></p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235810650.png" alt="image-20240418235810650" style="zoom:67%;">
<h2 id="5-反向传播"><a class="markdownIt-Anchor" href="#5-反向传播"></a> 5 反向传播</h2>
<p>y 对 z 的导数 11J 以用式子 5.1 表示：</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235920234.png" alt="image-20240418235920234"></p>
<p>也可写成：</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235944251.png" alt="image-20240418235944251"></p>
<p>求导流程</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419000026551.png" alt="image-20240419000026551" style="zoom:50%;">
<p>求导过程：</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418214342085.png" alt="image-20240418214342085" style="zoom:80%;">
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418212406502.png" alt="image-20240418212406502" style="zoom:80%;">
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418214212099.png" alt="image-20240418214212099"></p>
<p>正向传播</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418213741377.png" alt="image-20240418213741377"></p>
<p>反向传播</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418214157026.png" alt="image-20240418214157026"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418220753163.png" alt="image-20240418220753163"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418221125070.png" alt="image-20240418221125070"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418221120878.png" alt="image-20240418221120878"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418221115733.png" alt="image-20240418221115733"></p>
<p>\</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240418235104955.png" alt="image-20240418235104955"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419220559301.png" alt="image-20240419220559301"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419224326395.png" alt="image-20240419224326395"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419224320883.png" alt="image-20240419224320883"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419224730866.png" alt="image-20240419224730866"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240419225947503.png" alt="image-20240419225947503"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420153251259.png" alt="image-20240420153251259"></p>
<h1 id="2"><a class="markdownIt-Anchor" href="#2"></a> 2</h1>
<h2 id="217-内存管理和循环引用"><a class="markdownIt-Anchor" href="#217-内存管理和循环引用"></a> 2.17 内存管理和循环引用</h2>
<h3 id="1-内存管理"><a class="markdownIt-Anchor" href="#1-内存管理"></a> 1 内存管理</h3>
<ul>
<li>
<p>一种是引用计数</p>
</li>
<li>
<p>一种是分代垃圾凹收</p>
</li>
</ul>
<h3 id="2-计数方式"><a class="markdownIt-Anchor" href="#2-计数方式"></a> 2 计数方式</h3>
<p>​	每个对象在被创建时的引用计数为0，当它被另一个对象引用时引用计数加1，当引用停止时，引用计数减1。最终，当引用计数变为0时 python解释器会回收该对象。</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420155229195.png" alt="image-20240420155229195" style="zoom:67%;">
<p>当a = b = c = None时，对象之间的关系发生变化 此时a的引用计数变为O(b和c的引用计数为1) 对此. a立即被删除 删除 a 导致b的引用计数从1变成O. 所以b也被删除。</p>
<h3 id="3-循环引用"><a class="markdownIt-Anchor" href="#3-循环引用"></a> 3 循环引用</h3>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420155157415.png" alt="image-20240420155157415" style="zoom:67%;">
<p>采用 <code>分代垃圾回收</code>处理</p>
<h3 id="4-弱引用"><a class="markdownIt-Anchor" href="#4-弱引用"></a> 4 弱引用</h3>
<p>​	用weakref.ref函数来创建弱引用</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420155447235.png" alt="image-20240420155447235" style="zoom:67%;">
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420155452283.png" alt="image-20240420155452283" style="zoom:67%;">
<p>a=None 时，b虽然用了这个对象，但由于是弱引用，所以对引用计数没有影响</p>
<h3 id="5修改"><a class="markdownIt-Anchor" href="#5修改"></a> 5修改</h3>
<p><strong>对比：</strong></p>
<p>之前：</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420160208866.png" alt="image-20240420160208866"></p>
<p>之后：</p>
<img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420160154381.png" alt="image-20240420160154381" style="zoom:67%;">
<h2 id="218减少内存使用量的模式"><a class="markdownIt-Anchor" href="#218减少内存使用量的模式"></a> 2.18减少内存使用量的模式</h2>
<p>第1项改进是减少反向传播消耗的内存使用址， 这项改进提供了立即清除元用导数的机制。</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420160709236.png" alt="image-20240420160709236"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420161151386.png" alt="image-20240420161151386"></p>
<p>第2项改进是提供&quot;不需要反向 传播时的模式&quot;</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420161534975.png" alt="image-20240420161534975"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420161630351.png" alt="image-20240420161630351"></p>
<p>是否 <code>creator</code>也不需要了呢？</p>
<p>Constant</p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154131602.png" alt="image-20240420154131602"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154150170.png" alt="image-20240420154150170"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154244033.png" alt="image-20240420154244033"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154246451.png" alt="image-20240420154246451"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154312677.png" alt="image-20240420154312677"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154416108.png" alt="image-20240420154416108"></p>
<p><img src="/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/image-20240420154432668.png" alt="image-20240420154432668"></p>
<h1 id="3-高阶导数"><a class="markdownIt-Anchor" href="#3-高阶导数"></a> 3 高阶导数</h1>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/04/18/2024%E5%B9%B44%E6%9C%8818%E6%97%A5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%88%B6%E6%A1%86%E6%9E%B6/" data-id="clx4fkxnj000dn0v43cmx8t28" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/project/" rel="tag">project</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2024年3月29日-llm2" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/03/29/2024%E5%B9%B43%E6%9C%8829%E6%97%A5-llm2/" class="article-date">
  <time class="post-time" datetime="2024-03-29T04:40:45.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">29</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/03/29/2024%E5%B9%B43%E6%9C%8829%E6%97%A5-llm2/">2024年3月29日 llm2</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="2-llm2"><a class="markdownIt-Anchor" href="#2-llm2"></a> 2 LLM2</h1>
<h2 id="21处理流程"><a class="markdownIt-Anchor" href="#21处理流程"></a> 2.1处理流程</h2>
<h3 id="输入数据"><a class="markdownIt-Anchor" href="#输入数据"></a> <strong>输入数据</strong>：</h3>
<p>LLM的输入数据是一段文本，可以是一个句子或一段话。文本通常被表示成单词或字符的序列。</p>
<h3 id="tokenization"><a class="markdownIt-Anchor" href="#tokenization"></a> <strong>Tokenization</strong>：</h3>
<p>将文本进行Tokenization，将其切分成单词或字符，形成Token序列。</p>
<p>再将文本映射成模型可理解的输入形式，将文本序列转换为整数索引序列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">序列化-&gt; </span><br><span class="line">[&#x27;BOS&#x27;,&#x27;君&#x27;,&#x27;不&#x27;,&#x27;见&#x27;,&#x27;黄&#x27;,&#x27;河&#x27;,&#x27;之&#x27;,&#x27;水&#x27;,&#x27;天&#x27;,&#x27;上&#x27;,&#x27;来&#x27;,&#x27;，&#x27; ,&#x27;奔&#x27;,&#x27;流&#x27;,&#x27;到&#x27;...&#x27;与&#x27;,&#x27;尔&#x27;,&#x27;同&#x27;,&#x27;销&#x27;,&#x27;万&#x27;,&#x27;古&#x27;,&#x27;愁&#x27;,&#x27;EOS&#x27;]</span><br><span class="line"></span><br><span class="line">假设语料库索引化-&gt;</span><br><span class="line">[&#x27;BOS&#x27;,&#x27;10&#x27;,&#x27;3&#x27;,&#x27;67&#x27;,&#x27;89&#x27;,&#x27;21&#x27;,&#x27;45&#x27;,&#x27;55&#x27;,&#x27;61&#x27;,&#x27;4&#x27;,&#x27;324&#x27;,&#x27;565&#x27; ,&#x27;789&#x27;,&#x27;6567&#x27;,&#x27;786&#x27;...&#x27;7869&#x27;,&#x27;9&#x27;,&#x27;3452&#x27;,&#x27;563&#x27;,&#x27;56&#x27;,&#x27;66&#x27;,&#x27;77&#x27;,&#x27;EOS&#x27;]</span><br></pre></td></tr></table></figure>
<h3 id="embedding"><a class="markdownIt-Anchor" href="#embedding"></a> <strong>Embedding</strong>：</h3>
<p>将每个Token映射为一个实数向量，为Embeding Vector</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x27;BOS&#x27;-&gt; [p_&#123;00&#125;,p_&#123;01&#125;,p_&#123;02&#125;,...,p_&#123;0d-1&#125;]</span><br><span class="line">&#x27;10&#x27; -&gt; [p_&#123;10&#125;,p_&#123;11&#125;,p_&#123;12&#125;,...,p_&#123;1d-1&#125;]</span><br><span class="line">&#x27;3&#x27;  -&gt; [p_&#123;20&#125;,p_&#123;21&#125;,p_&#123;22&#125;,...,p_&#123;2d-1&#125;]</span><br><span class="line">...</span><br><span class="line">&#x27;EOS&#x27;-&gt; [p_&#123;n0&#125;,p_&#123;n1&#125;,p_&#123;n2&#125;,...,p_&#123;nd-1&#125;]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="位置编码"><a class="markdownIt-Anchor" href="#位置编码"></a> <strong>位置编码</strong>：</h3>
<p>对于Token序列中的每个位置，添加位置编码（Positional Encoding）向量，以提供关于Token在序列中位置的信息。</p>
<p>位置编码是为了区分不同位置的Token，并为模型提供上下文关系的信息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[p_&#123;00&#125;,p_&#123;01&#125;,p_&#123;02&#125;,...,p_&#123;0d-1&#125;]       [pe_&#123;00&#125;,pe_&#123;01&#125;,pe_&#123;02&#125;,...,pe_&#123;0d-1&#125;]</span><br><span class="line">[p_&#123;10&#125;,p_&#123;11&#125;,p_&#123;12&#125;,...,p_&#123;1d-1&#125;]       [pe_&#123;10&#125;,pe_&#123;11&#125;,pe_&#123;12&#125;,...,pe_&#123;1d-1&#125;]</span><br><span class="line">[p_&#123;20&#125;,p_&#123;21&#125;,p_&#123;22&#125;,...,p_&#123;2d-1&#125;]    +  [pe_&#123;20&#125;,pe_&#123;21&#125;,pe_&#123;22&#125;,...,pe_&#123;2d-1&#125;]</span><br><span class="line">...                                       ...  </span><br><span class="line">[p_&#123;n0&#125;,p_&#123;n1&#125;,p_&#123;n2&#125;,...,p_&#123;nd-1&#125;]       [pe_&#123;n0&#125;,pe_&#123;n1&#125;,pe_&#123;n2&#125; ,...,pe_&#123;nd-1&#125;]</span><br></pre></td></tr></table></figure>
<h3 id="transformer"><a class="markdownIt-Anchor" href="#transformer"></a> <strong>Transformer</strong> ：</h3>
<p>在生成任务中，模型只需要用到Transformer 的decoder阶段，即Decoder-Only，比如GPT、LLaMA 都是。</p>
<p><img src="/2024/03/29/2024%E5%B9%B43%E6%9C%8829%E6%97%A5-llm2/image-20240329125213908.png" alt="image-20240329125213908"></p>
<h3 id="自回归生成"><a class="markdownIt-Anchor" href="#自回归生成"></a> <strong>自回归生成</strong>：</h3>
<p>在生成任务中，使用自回归（Autoregressive）方式，逐个生成输出序列中的每个Token。</p>
<p>在解码过程中，每次生成一个Token时，使用前面已生成的内容作为上下文，来帮助预测下一个Token。</p>
<p><img src="/2024/03/29/2024%E5%B9%B43%E6%9C%8829%E6%97%A5-llm2/image-20240329125500103.png" alt="image-20240329125500103"></p>
<h2 id="22-相关技术"><a class="markdownIt-Anchor" href="#22-相关技术"></a> 2.2 相关技术</h2>
<h3 id="rope"><a class="markdownIt-Anchor" href="#rope"></a> <strong>RoPE</strong></h3>
<p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2104.09864.pdf">RoPE位置编码</a></p>
<p><img src="/2024/03/29/2024%E5%B9%B43%E6%9C%8829%E6%97%A5-llm2/image-20240329131119065.png" alt="image-20240329131119065"></p>
<h3 id="kv-cache-gqa"><a class="markdownIt-Anchor" href="#kv-cache-gqa"></a> <strong>KV Cache &amp; GQA</strong></h3>
<p>Attention计算时的KV</p>
<p>通过将每次计算的K和V缓存下来，之后新的序列进来时只需要从KV Cache中读取之前的KV值即可，就不需要再去重复计算之前的KV了。</p>
<p><img src="/2024/03/29/2024%E5%B9%B43%E6%9C%8829%E6%97%A5-llm2/image-20240329131434662.png" alt="image-20240329131434662"></p>
<p>至于为什么不用缓存Q？</p>
<p><strong>GQA</strong></p>
<p><img src="/2024/03/29/2024%E5%B9%B43%E6%9C%8829%E6%97%A5-llm2/image-20240329131658979.png" alt="image-20240329131658979"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/03/29/2024%E5%B9%B43%E6%9C%8829%E6%97%A5-llm2/" data-id="clx4fkxni0007n0v4cpjj3kck" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/llm/" rel="tag">llm</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2024年3月3日-pythons刷题" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/03/13/2024%E5%B9%B43%E6%9C%883%E6%97%A5-pythons%E5%88%B7%E9%A2%98/" class="article-date">
  <time class="post-time" datetime="2024-03-13T12:51:35.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">13</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/03/13/2024%E5%B9%B43%E6%9C%883%E6%97%A5-pythons%E5%88%B7%E9%A2%98/">2024年3月3日 python内存管理</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="python-内存管理"><a class="markdownIt-Anchor" href="#python-内存管理"></a> python 内存管理</h1>
<h2 id="1-内存管理"><a class="markdownIt-Anchor" href="#1-内存管理"></a> 1 内存管理</h2>
<h2 id="2-记数引用"><a class="markdownIt-Anchor" href="#2-记数引用"></a> 2 记数引用</h2>
<h2 id="3-弱引用"><a class="markdownIt-Anchor" href="#3-弱引用"></a> 3 弱引用</h2>
<p>在不增加引用计数的情况下引用另一个对象的功能</p>
<img src="/2024/03/13/2024%E5%B9%B43%E6%9C%883%E6%97%A5-pythons%E5%88%B7%E9%A2%98/image-20240419235445781.png" alt="image-20240419235445781" style="zoom:67%;">
<img src="/2024/03/13/2024%E5%B9%B43%E6%9C%883%E6%97%A5-pythons%E5%88%B7%E9%A2%98/image-20240419235504536.png" alt="image-20240419235504536" style="zoom:67%;">
<p><img src="/2024/03/13/2024%E5%B9%B43%E6%9C%883%E6%97%A5-pythons%E5%88%B7%E9%A2%98/image-20240419235820695.png" alt="image-20240419235820695"></p>
<h2 id="4-memory-profiler"><a class="markdownIt-Anchor" href="#4-memory-profiler"></a> 4 memory profiler</h2>
<p>外部库来监测 Python 中的内存使用情况</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/03/13/2024%E5%B9%B43%E6%9C%883%E6%97%A5-pythons%E5%88%B7%E9%A2%98/" data-id="clx4fkxni0009n0v46qrdakx6" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2024年3月3日-面试更新——代码模型" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0%E2%80%94%E2%80%94%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time class="post-time" datetime="2024-03-03T06:16:37.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">03</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0%E2%80%94%E2%80%94%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B/">2024年3月3日 面试更新——代码模型</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="代码模型"><a class="markdownIt-Anchor" href="#代码模型"></a> 代码模型</h1>
<h2 id="模型加密"><a class="markdownIt-Anchor" href="#模型加密"></a> 模型加密</h2>
<p>模型加密的几个方式：</p>
<ul>
<li>模型文件直接加密，把模型的二进制文件直接加密，一般都会有加密算法，对模型的前xx字节进行加密，解密的时候对前xx字节进行解密即可，这种加密只在load时候做，会影响模型加载速度，但是不影响运行速度</li>
<li>模型结构不加密，模型权重加密，有的可以采用类似于模型压缩的方法把权重压缩了，推理时以自定义协议读取加载推理</li>
<li>也需要对解密模型的代码进行加密，代码混淆要做，不过这样会影响解密代码也就是load模型过程，会变慢，就看你代码混淆做到什么程度</li>
</ul>
<h2 id="模型转换"><a class="markdownIt-Anchor" href="#模型转换"></a> 模型转换</h2>
<p>模型可能是各种格式的：</p>
<ul>
<li>Caffe</li>
<li>ONNX</li>
<li>Pytorch</li>
<li>TFLITE</li>
<li>NCNN、MNN</li>
</ul>
<h4 id="模型转换后一般要做"><a class="markdownIt-Anchor" href="#模型转换后一般要做"></a> 模型转换后一般要做</h4>
<ul>
<li>转换后看一下模型的输入输出类型、维度、名称、数量啥的是否和之前一致</li>
<li>转换后首先跑一张训练时的图（或者一批图），看下新模型的输出和旧模型差多少，一定要保证最终输入到模型的tensor一致（也可以使用random输入或者ones输入测试，不过对于模型权重分布特殊的模型来说，对于这种输入可能评测不是很准确）</li>
<li>批量跑测试集测一下精度是否一致</li>
<li>benchmark转换后模型的速度是否符合预期</li>
</ul>
<h4 id="常见的问题"><a class="markdownIt-Anchor" href="#常见的问题"></a> 常见的问题</h4>
<ul>
<li>转换后模型精度问题，输出为nan、精度完全错乱</li>
<li>转换后模型batch=1正常，多batch结果错乱</li>
<li>转换后输入/输出类型维度啥的错误</li>
<li>转换后模型速度未达到预期</li>
<li>未完待续</li>
</ul>
<h2 id="模型优化"><a class="markdownIt-Anchor" href="#模型优化"></a> 模型优化</h2>
<p>小到优化一个<a target="_blank" rel="noopener" href="https://blog.csdn.net/agq358/article/details/125095432"><strong>op</strong></a>（Op就是Kernel的集合，一个Op代表的是有一定共性的多个Kernel便于在<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2306404">计算图和图优化</a>中进行表示），大概优化整个推理pipeline，可以干的事情很多。</p>
<h3 id="合并-替换op算子"><a class="markdownIt-Anchor" href="#合并-替换op算子"></a> 合并、替换op算子</h3>
<p>很多框架在导出的时候就会<strong>自动合并一些操作</strong>，比如torch.onnx在导出<strong>conv+bn</strong>的时候会将bn吸到前面的conv中，比较常见了。<br>
但也有一些<strong>可以合并的操作，<strong>假如框架代码还没有实现该pattern则不会合并，不过我们也可以自己合并，这里需要经验了，需要我们熟知各种op的合并方式。<br>
可以自己合并一些操作，比如下图中的</strong>convTranspose+Add+BN</strong>，是不常见的Squence(序列)的pattern，如果自己愿意的话，可以直接在ONNX中进行合并，把权重关系搞对就行</p>
<p><img src="/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0%E2%80%94%E2%80%94%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B/image-20240303145240993.png" alt="image-20240303145240993"></p>
<p>列举一些合并的例子，总之就是将多个op合成大op，节省计算量以及数据搬运的时间：</p>
<ul>
<li>conv/transposeConv+bn</li>
<li>多个支路的conv合并为group conv</li>
<li>gemm + bias -&gt; conv</li>
</ul>
<p><img src="/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0%E2%80%94%E2%80%94%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B/image-20240303145305875.png" alt="image-20240303145305875"></p>
<p>多路合并</p>
<p><img src="/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0%E2%80%94%E2%80%94%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B/image-20240303145254628.png" alt="image-20240303145254628"></p>
<p>既可以融合一些算子，当然也可以替换一些算子：</p>
<ul>
<li>relu6替换为max(0,6)</li>
</ul>
<h3 id="蒸馏-剪枝"><a class="markdownIt-Anchor" href="#蒸馏-剪枝"></a> 蒸馏、剪枝</h3>
<p>剪枝后的模型比未剪枝的同等size大小精度更高。<br>
具体的可以参考这篇：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.01878">https://arxiv.org/abs/1710.01878</a></p>
<p>剪枝的方法可以看zomi总结的ppt(来自 <a target="_blank" rel="noopener" href="https://github.com/chenzomi12/DeepLearningSystem">https://github.com/chenzomi12/DeepLearningSystem</a>)：</p>
<p><img src="/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0%E2%80%94%E2%80%94%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B/image-20240303145428861.png" alt="image-20240303145428861"></p>
<p>​</p>
<p>蒸馏可以使同结构的小模型精度提升接近大模型的精度。</p>
<h4 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h4>
<p>剪枝类似于模型搜索，如果直接<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/127194745">NAS</a>的话，就没有必要剪枝了。</p>
<h4 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h4>
<ul>
<li>to prune or not to prune exploring the efficacy of pruning for model compression</li>
<li>DAMO-YOLO</li>
</ul>
<h3 id="量化"><a class="markdownIt-Anchor" href="#量化"></a> 量化</h3>
<p>量化目前比较成熟，也有很好的教程（PPQ），很成熟的库（PPQ）</p>
<ul>
<li>量化基本概念，与硬件的关系</li>
<li>PTQ量化和QAT量化，两种量化还有很多方法。PTQ有  EasyQuant（EQ）、；QAT有LSQ(Learned Step Size Quantization)、DSQ(Differentiable Soft Quantization)</li>
</ul>
<p>不是所有模型、所有op都适合量化：</p>
<ul>
<li>重参数量化 <a target="_blank" rel="noopener" href="https://tech.meituan.com/2022/09/22/yolov6-quantization-in-meituan.html">https://tech.meituan.com/2022/09/22/yolov6-quantization-in-meituan.html</a></li>
<li>量化模型直接输入int8 进行测试</li>
</ul>
<p>注意点：</p>
<ul>
<li>有些模型量化后，虽然整体指标没有变化（某个评价标准，比如coco的mAP），但是实际使用中，发现之前的一些效果变差了，这种情况大多是调用模型的策略效果与这个模型的耦合度比较高了。举个例子，比如之前这个模型对小目标检测效果好，但是量化后，小目标检测效果差了（然而中目标效果好了）所以导致与小目标耦合度比较高的策略兼容度不高，导致算法的整体精度下降。这种情况就比较尴尬，你可以调整策略，或者重新量化模型，加上一些约束使其在某些场景下尽可能和原始模型表现一致，但这个需要时间去优化了，有较高的时间成本。</li>
</ul>
<h4 id="参考-2"><a class="markdownIt-Anchor" href="#参考-2"></a> 参考</h4>
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg3ODU2MzY5MA==&amp;mid=2247488318&amp;idx=1&amp;sn=048c1b78f3b2cb25c05abb115f20d6c6&amp;chksm=cf108b3bf867022d1b214928102d65ed691c81955b59ca02bccdee92584ad9aa8e390e1d2978&amp;token=1097456929&amp;lang=zh_CN&amp;scene=21#wechat_redirect">必看部署系列~懂你的神经网络量化教程：第一讲！</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg3ODU2MzY5MA==&amp;mid=2247488838&amp;idx=1&amp;sn=56107c468d5b683a574e6046af3a541f&amp;chksm=cf108d43f8670455736a83546eb5ed81abc9194d7d4c2359af393f26e3bddd1379f777e35f35&amp;token=1097456929&amp;lang=zh_CN&amp;scene=21#wechat_redirect">量化番外篇——TensorRT-8的量化细节</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg3ODU2MzY5MA==&amp;mid=2247489317&amp;idx=1&amp;sn=797e32276bd4f55948d992f455415943&amp;chksm=cf108f20f8670636b27be2431d5a4fdef1689eaa672e59ffc7d6181d2afb13a9a050d9b6b4a5&amp;token=1097456929&amp;lang=zh_CN&amp;scene=21#wechat_redirect">实践torch.fx第二篇——基于FX的PTQ量化实操</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/openppl-public/ppq">https://github.com/openppl-public/ppq</a></li>
</ul>
<h3 id="算子op优化"><a class="markdownIt-Anchor" href="#算子op优化"></a> 算子op优化</h3>
<p>性能计算的一些入门问题，可以看下这个的回答：</p>
<ul>
<li>想进大厂的高性能计算岗位需要做哪些准备？</li>
</ul>
<p>大部分优化op的场景，很多原因是<strong>原生op的实现可能不是最优</strong>的，有很大的优化空间。<br>
比如LayerNorm这个操作，Pytorch原生的实现比较慢，于是就有了优化空间：</p>
<ul>
<li>CUDA优化之LayerNorm性能优化实践</li>
</ul>
<p>同理，很多CUDA实现的OP可能不是最优的，只有你有精力，就可以进行优化。也要考虑是这个优化值不值，在整个模型中的占比大不大，投入产出比怎么样blabla。</p>
<p>对于CUDA还好些，资料很多，很多op网上都有开源的不错的实现（尤其是gemm），抄抄改改就可以了。</p>
<p>不过对于一些没有CUDA那么火的平台或者语言，比如arm平台的neon或者npu，这些开源的算子实现少一些，大部分需要自己手写。分析模型哪些op慢之后，手动优化一下。</p>
<p>知乎上也有很多优化系列的教程，跟着一步一步来吧：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/478846788">cuda 入门的正确姿势：how-to-optimize-gemm</a></li>
<li>深入浅出GPU优化系列：elementwise优化及CUDA工具链介绍</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/441146275">[施工中] CUDA GEMM 理论性能分析与 kernel 优化</a></li>
<li>深入浅出GPU优化系列：reduce优化</li>
</ul>
<p>有几种可以自动生成op的框架：</p>
<ul>
<li>TVM</li>
<li>triton（此triton非彼triton）</li>
</ul>
<h3 id="调优可视化工具"><a class="markdownIt-Anchor" href="#调优可视化工具"></a> 调优可视化工具</h3>
<p>可视化工具</p>
<ul>
<li>画模型图的工具，graphvis</li>
<li>NVIDIA的nsight system和nsight compute</li>
<li>pytorch的profiler</li>
</ul>
<h2 id="更多推理框架ai编译器"><a class="markdownIt-Anchor" href="#更多推理框架ai编译器"></a> 更多推理框架/AI编译器</h2>
<p><a target="_blank" rel="noopener" href="https://github.com/merrymercy/awesome-tensor-compilers">https://github.com/merrymercy/awesome-tensor-compilers</a></p>
<h3 id="onnx"><a class="markdownIt-Anchor" href="#onnx"></a> ONNX</h3>
<h4 id="相关文章"><a class="markdownIt-Anchor" href="#相关文章"></a> 相关文章：</h4>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/daquexian/onnx-simplifier">https://github.com/daquexian/onnx-simplifier</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ZhangGe6/onnx-modifier">https://github.com/ZhangGe6/onnx-modifier</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeon">https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeon</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/onnx/onnx">https://github.com/onnx/onnx</a></li>
<li>模型部署入门教程（五）：ONNX 模型的修改与调试</li>
<li><a target="_blank" rel="noopener" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md">https://github.com/onnx/onnx/blob/main/docs/Operators.md</a></li>
</ul>
<h3 id="tvm"><a class="markdownIt-Anchor" href="#tvm"></a> TVM</h3>
<ul>
<li>如何评测模型的速度</li>
<li>如何benchmark模型各层的错误</li>
<li>解析trtexec中的benchmark</li>
<li>解析TVM中的graph和VM</li>
</ul>
<h3 id="tensorrt"><a class="markdownIt-Anchor" href="#tensorrt"></a> TensorRT</h3>
<ul>
<li>python端口调用</li>
<li>C++端口调用</li>
<li>多线程调用</li>
<li>各种模型转换TensorRT（ONNX、Pytorch、TensorFLow）</li>
<li>各种和TensorRT相关的转换库</li>
</ul>
<h4 id="自定义插件"><a class="markdownIt-Anchor" href="#自定义插件"></a> 自定义插件</h4>
<p>如果模型中保存TensorRT不支持的算子，就需要自己实现cuda操作并且集成到TensorRT中。<br>
现在也有很多可以生成插件的工具：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA-AI-IOT/tensorrt_plugin_generator">https://github.com/NVIDIA-AI-IOT/tensorrt_plugin_generator</a></li>
</ul>
<p>相关资料：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/trt-samples-for-hackathon-cn">https://github.com/NVIDIA/trt-samples-for-hackathon-cn</a></li>
</ul>
<h3 id="libtorch"><a class="markdownIt-Anchor" href="#libtorch"></a> libtorch</h3>
<p>简单好用的对Pytorch模型友好的C++推理库。</p>
<ul>
<li>torch.jit.trace</li>
<li>torch.jit.script</li>
<li>python导出libtorch模型，C++加载libtorch模型</li>
</ul>
<h3 id="aitemplate"><a class="markdownIt-Anchor" href="#aitemplate"></a> AITemplate</h3>
<p>AITemplate 加速Stable Diffusion的效果比TensorRT要好不少。<br>
测试了一个res50的模型，利用<code>TensorRT-8.5.1.7</code>和<code>AITemplate-0.1dev</code>转化后简单测试了下速度，精度都是FP16，显卡是A4000。</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">4x3x224x224</th>
<th style="text-align:left">8x3x224x224</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">TensorRT</td>
<td style="text-align:left">2.07885 ms</td>
<td style="text-align:left">3.49877 ms</td>
</tr>
<tr>
<td style="text-align:left">AITemplate</td>
<td style="text-align:left">1.36401 ms</td>
<td style="text-align:left">2.38946 ms</td>
</tr>
</tbody>
</table>
<h2 id="高性能计算"><a class="markdownIt-Anchor" href="#高性能计算"></a> 高性能计算</h2>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0%E2%80%94%E2%80%94%E4%BB%A3%E7%A0%81%E6%A8%A1%E5%9E%8B/" data-id="cltgreey5000rw8v4e1zv3zw6" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2024年3月3日-面试更新" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0/" class="article-date">
  <time class="post-time" datetime="2024-03-03T04:42:53.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">03</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0/">2024年3月3日 面试更新——大模型</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="大模型面试总结"><a class="markdownIt-Anchor" href="#大模型面试总结"></a> 大模型面试总结</h1>
<h2 id="大模型"><a class="markdownIt-Anchor" href="#大模型"></a> 大模型</h2>
<h3 id="项目"><a class="markdownIt-Anchor" href="#项目"></a> 项目</h3>
<p>现在简历上搞一些什么使用unet训练一个分割网络实现某个任务，或者说使用yolov7检测某个目标已经不是什么亮点了。不过这种也不是不行，但你需要<strong>更多的深度</strong>我才会感兴趣：</p>
<ul>
<li>网络结构有无值得说明的改进</li>
<li>为什么这样做可以明确说出原因和数据证明</li>
<li>对使用这个方法以及和其他方法做过比较详细的对比，选择这个模型是有理由的</li>
</ul>
<h3 id="推理相关"><a class="markdownIt-Anchor" href="#推理相关"></a> 推理相关</h3>
<p>要求：</p>
<ul>
<li>搞上层编译器的（类似于torch-tensorrt的利用pytorch生态和TensorRT生态的在nvidia显卡加速的编译器，不需要自己写codegen），会针对不同的后端（比如onnx和torchscript）写parser，针对计算图写一些pass；也有搞基于MLIR的编译器的，在自己的公司硬件上跑，前端中端后端需要都搞</li>
<li>搞推理框架的，就是优化训练和部署中的一些性能问题、精度溢出问题；有些公司喜欢搞统一的框架（训练和部署都解决了），不喜欢用现有的轮子，要自己造；对于加速类的推理框架，会实现比如模拟量化功能、精度对比功能等等</li>
<li>搞加速的，就是对任务中各种瓶颈的算子进行加速，C<ins>转cuda，python转c</ins>等等，使用C++封装一些项目blabla</li>
<li>项目优化op的细节</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2024/03/03/2024%E5%B9%B43%E6%9C%883%E6%97%A5-%E9%9D%A2%E8%AF%95%E6%9B%B4%E6%96%B0/" data-id="cltgreey3000lw8v49zyk0xav" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/5/">&amp;laquo; pre</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/7/">next &amp;raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Weakliy_Blog</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>102</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>31</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="Github">
          Github
        </a>
      
    </div>

    <div class="friend-link">
      <h2>联系我</h2>
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2024 - 2025 Weakliy<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">首页</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">总览</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">xxx</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">xxxx</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>