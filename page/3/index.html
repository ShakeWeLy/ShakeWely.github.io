<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Weakliy_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Weakliy_Blog">
<meta property="og:url" content="https://shakewely.github.io/page/3/index.html">
<meta property="og:site_name" content="Weakliy_Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Weakliy">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Weakliy_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>92</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>29</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main">
  
    <article id="post-2025年3月15日-模型评价指标" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/14/2025%E5%B9%B43%E6%9C%8815%E6%97%A5-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/" class="article-date">
  <time class="post-time" datetime="2025-03-13T16:26:50.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">14</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/14/2025%E5%B9%B43%E6%9C%8815%E6%97%A5-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/">2025年3月15日 模型评价指标</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="计算量与参数量"><a class="markdownIt-Anchor" href="#计算量与参数量"></a> 计算量与参数量</h1>
<h2 id="1-定义"><a class="markdownIt-Anchor" href="#1-定义"></a> 1 定义</h2>
<ol>
<li>计算量-时间复杂度  <strong>乘法和加发的操作次数</strong></li>
<li>参数量-空间复杂度</li>
</ol>
<h3 id="卷积层"><a class="markdownIt-Anchor" href="#卷积层"></a> 卷积层</h3>
<p><strong>计算量</strong>: (KxKxWxH) x C_in x C_out</p>
<blockquote>
<p>W\H: 输出feature map 的size</p>
<p>回忆卷积操作过程</p>
</blockquote>
<p><strong>参数量</strong>: KxKxC_inxC_out</p>
<blockquote>
<p>卷积核的weight</p>
</blockquote>
<h3 id="池化层"><a class="markdownIt-Anchor" href="#池化层"></a> 池化层</h3>
<p><strong>计算量</strong>: 不同池化操作不同 Cin x Cout x W x H x K xK</p>
<blockquote></blockquote>
<p><strong>参数量</strong>  无</p>
<h3 id="全连接层"><a class="markdownIt-Anchor" href="#全连接层"></a> 全连接层</h3>
<p>参数量 weight_in*weight_out</p>
<p>计算量＝ 2 x Cin x Cout</p>
<h3 id="batchnorm"><a class="markdownIt-Anchor" href="#batchnorm"></a> BatchNorm</h3>
<p>计算量: 4WHC</p>
<blockquote></blockquote>
<p>参数量: 2C</p>
<blockquote>
<p>(y=ax+b) xC</p>
</blockquote>
<h3 id="激活函数"><a class="markdownIt-Anchor" href="#激活函数"></a> 激活函数</h3>
<p>计算量: H×W×C</p>
<blockquote>
<p>path个数</p>
</blockquote>
<h2 id="硬件需求"><a class="markdownIt-Anchor" href="#硬件需求"></a> 硬件需求</h2>
<p>计算量的要求是在于芯片的__（指的是gpu的运算能力）</p>
<p>参数量取决于__大小</p>
<h3 id="计算量和参数量查看"><a class="markdownIt-Anchor" href="#计算量和参数量查看"></a> 计算量和参数量查看</h3>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40507857/article/details/118764782">https://blog.csdn.net/qq_40507857/article/details/118764782</a></p>
<h3 id="输入数据对模型的参数量和计算量的影响"><a class="markdownIt-Anchor" href="#输入数据对模型的参数量和计算量的影响"></a> 输入数据对模型的参数量和计算量的影响</h3>
<h1 id="tf-fp-fn-tn"><a class="markdownIt-Anchor" href="#tf-fp-fn-tn"></a> TF FP FN TN</h1>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wzk4869/article/details/127879761">https://blog.csdn.net/wzk4869/article/details/127879761</a></p>
<img src="https://picx.zhimg.com/70/v2-895d6f8e80c0078c92244158dec97bfc_1440w.image?source=172ae18b&biz_tag=Post" alt="深挖一下F1 score (F-measure, F-score)[根据公式分析]" style="zoom:50%;">
<h2 id="1-准确率precision"><a class="markdownIt-Anchor" href="#1-准确率precision"></a> 1 准确率（Precision）</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="2-召回率-recall"><a class="markdownIt-Anchor" href="#2-召回率-recall"></a> 2 召回率 (Recall)</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="目标检测的评价指标"><a class="markdownIt-Anchor" href="#目标检测的评价指标"></a> 目标检测的评价指标</h1>
<h2 id="1-iou"><a class="markdownIt-Anchor" href="#1-iou"></a> 1: IoU</h2>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="2-f1-score"><a class="markdownIt-Anchor" href="#2-f1-score"></a> 2: F1 Score</h2>
<p><strong>定义</strong>: F Score 是 Precision 和 Recall 的调和平均数 (harmonic mean)</p>
<p><img src="/2025/03/14/2025%E5%B9%B43%E6%9C%8815%E6%97%A5-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/image-20250314011150884.png" alt="image-20250314011150884"></p>
<blockquote>
<p>Precision 与 Recall 看起来很相似，实际上这两个是“冤家”。为什么这么说呢？因为在大多数情况下，这两者有一定的互斥性。****</p>
</blockquote>
<p><strong>作用:</strong></p>
<h2 id="平均准确度-average-precisionap"><a class="markdownIt-Anchor" href="#平均准确度-average-precisionap"></a> 平均准确度 (Average Precision，AP)</h2>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/14/2025%E5%B9%B43%E6%9C%8815%E6%97%A5-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/" data-id="cm8q1tfhp000xpcv44db75i16" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月12日-onnx5-算子" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/" class="article-date">
  <time class="post-time" datetime="2025-03-12T14:42:57.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">12</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/">2025年3月12日 onnx问答</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zhaoyqcsdn/article/details/135512992%E3%80%81">https://blog.csdn.net/zhaoyqcsdn/article/details/135512992、</a></p>
<h1 id="1-算子不兼容"><a class="markdownIt-Anchor" href="#1-算子不兼容"></a> 1 算子不兼容</h1>
<p>onnx算子是否支持<br>
<a target="_blank" rel="noopener" href="https://github.com/onnx/onnx/blob/main/docs/Operators.md">https://github.com/onnx/onnx/blob/main/docs/Operators.md</a></p>
<h2 id="11-pytorch中有onnx中也有的算子"><a class="markdownIt-Anchor" href="#11-pytorch中有onnx中也有的算子"></a> 1.1 pytorch中有，onnx中也有的算子</h2>
<h2 id="12-pytorch中有onnx中无的算子"><a class="markdownIt-Anchor" href="#12-pytorch中有onnx中无的算子"></a> 1.2 pytorch中有，onnx中无的算子</h2>
<p>继承<code>torch.autograd.Function</code>实现自定义算子</p>
<h3 id="1-案例示例-focus层的切片操作"><a class="markdownIt-Anchor" href="#1-案例示例-focus层的切片操作"></a> <strong>1 案例示例</strong>： <code>Focus</code>层的切片操作</h3>
<blockquote>
<p>通过其他变换来改成兼容的算子</p>
</blockquote>
<p>在目标检测项目中，将PyTorch训练的YOLOv5模型转换为ONNX时，需处理<code>Focus</code>层的切片操作兼容性问题，通过重构为<code>Conv</code>层解决，将size减少一半通道数增加一倍</p>
<h3 id="2-实际案例动态切片问题"><a class="markdownIt-Anchor" href="#2-实际案例动态切片问题"></a> 2 <strong>实际案例：动态切片问题</strong></h3>
<p>静态图无法处理随机性</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 原始PyTorch代码（无法导出）</span><br><span class="line">x_slice = x[:, :, start_idx:start_idx+10]</span><br><span class="line"></span><br><span class="line"># 修改为ONNX兼容方式</span><br><span class="line">indices = torch.arange(start_idx, start_idx+10, device=x.device)</span><br><span class="line">x_slice = torch.index_select(x, dim=2, index=indices)</span><br></pre></td></tr></table></figure>
<h3 id="3-案例示例创建新的算子-手动实现"><a class="markdownIt-Anchor" href="#3-案例示例创建新的算子-手动实现"></a> 3 案例示例：创建新的算子 手动实现</h3>
<blockquote>
<p>使用支持的操作来手动实现算子</p>
</blockquote>
<ul>
<li>
<p>****：部分框架特定操作（如PyTorch自定义层）需替换为ONNX标准算子或自定义实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.onnx</span><br><span class="line"><span class="keyword">from</span> torch.onnx <span class="keyword">import</span> register_custom_op_symbolic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 定义自定义算子</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomRelu</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播：自定义的ReLU操作&quot;&quot;&quot;</span></span><br><span class="line">        ctx.save_for_backward(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.maximum(<span class="built_in">input</span>, torch.tensor(<span class="number">0.5</span>))  <span class="comment"># 比普通ReLU多了一个偏移</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;反向传播：ReLU的梯度计算&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">input</span>, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[<span class="built_in">input</span> &lt; <span class="number">0.5</span>] = <span class="number">0</span>  <span class="comment"># 低于0.5的部分梯度置零</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建 ONNX 计算图中的算子</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">symbolic_custom_relu</span>(<span class="params">g, <span class="built_in">input</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;定义 ONNX 计算图中的 custom_relu&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> g.op(<span class="string">&quot;custom_domain::CustomRelu&quot;</span>, <span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 绑定 ONNX 导出</span></span><br><span class="line">register_custom_op_symbolic(<span class="string">&quot;::CustomRelu&quot;</span>, symbolic_custom_relu, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 使用自定义算子</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomModel</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> CustomRelu.apply(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 实例化模型</span></span><br><span class="line">model = CustomModel()</span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 导出为 ONNX（确保 opset 版本支持）</span></span><br><span class="line">torch.onnx.export(</span><br><span class="line">    model, x, <span class="string">&quot;custom_relu.onnx&quot;</span>,</span><br><span class="line">    opset_version=<span class="number">11</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    operator_export_type=torch.onnx.OperatorExportTypes.ONNX</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="问题动态batch或可变输入尺寸导致转换失败"><a class="markdownIt-Anchor" href="#问题动态batch或可变输入尺寸导致转换失败"></a> <strong>问题</strong>：动态Batch或可变输入尺寸导致转换失败。</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.onnx.export(</span><br><span class="line">    model, dummy_input, &quot;yolov5_dynamic.onnx&quot;,</span><br><span class="line">    opset_version=11,</span><br><span class="line">    input_names=[&quot;input&quot;], output_names=[&quot;output&quot;],</span><br><span class="line">    dynamic_axes=&#123;</span><br><span class="line">        &quot;input&quot;: &#123;0: &quot;batch_size&quot;&#125;,   # 让 input 的 batch 维度 (dim=0) 变为动态</span><br><span class="line">        &quot;output&quot;: &#123;0: &quot;batch_size&quot;&#125;   # 让 output 的 batch 维度 (dim=0) 变为动态</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="2-写占位符号替换乱七八糟的算子"><a class="markdownIt-Anchor" href="#2-写占位符号替换乱七八糟的算子"></a> 2 写占位符号替换乱七八糟的算子</h1>
<p><img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/image-20250315101551480.png" alt="image-20250315101551480" style="zoom: 50%;"> <img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/image-20250315101542696.png"></p>
<h2 id="代码怎么写"><a class="markdownIt-Anchor" href="#代码怎么写"></a> 代码怎么写</h2>
<h3 id="todo"><a class="markdownIt-Anchor" href="#todo"></a> TODO</h3>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx5-%E7%AE%97%E5%AD%90/" data-id="cmanj8o23000dlcv4dnxrcuh0" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/onnx/" rel="tag">onnx</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月12日-onnx4-图优化" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/" class="article-date">
  <time class="post-time" datetime="2025-03-12T14:14:32.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">12</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/">2025年3月12日 onnx3</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="图优化"><a class="markdownIt-Anchor" href="#图优化"></a> 图优化</h1>
<h3 id="1"><a class="markdownIt-Anchor" href="#1"></a> 1</h3>
<p><img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/image-20250312222559294.png" alt="image-20250312222559294"></p>
<p><strong>引擎能够针对特定硬件进行深度优化，实现最佳的性能和效率</strong></p>
<p><img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/image-20250312224327684.png" alt="image-20250312224327684"></p>
<h3 id="3-查看netron节点"><a class="markdownIt-Anchor" href="#3-查看netron节点"></a> 3 查看netron节点</h3>
<p>ONNX的optimizer模块提供部分图优化的功能，例如最常用的：fuse_bn_into_conv，fuse_pad_into_conv等等。</p>
<p><img src="/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/image-20250312232520596.png" alt="image-20250312232520596"></p>
<h3 id="2-为什么需要forward_fuse"><a class="markdownIt-Anchor" href="#2-为什么需要forward_fuse"></a> 2. 为什么需要forward_fuse？</h3>
<ul>
<li>
<p>forward_fuse通常用于把卷积和BN层合并，或者把多个卷积分支合并，减少计算量，提高推理速度。</p>
</li>
<li>
<p>如果你的模块没有BN层，或者结构很简单，不需要合并，也应该定义一个forward_fuse，让它和forward一样。</p>
</li>
</ul>
<h3 id="4-onnxslim-模块未安装简化失败"><a class="markdownIt-Anchor" href="#4-onnxslim-模块未安装简化失败"></a> <code>4 onnxslim</code> 模块未安装，简化失败</h3>
<h4 id="简化-onnx-的主要作用"><a class="markdownIt-Anchor" href="#简化-onnx-的主要作用"></a> ✅ 简化 ONNX 的主要作用：</h4>
<table>
<thead>
<tr>
<th>好处</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>📦 减少模型大小</td>
<td>去除冗余算子与中间变量，减小 <code>.onnx</code> 文件大小</td>
</tr>
<tr>
<td>🚀 加速推理速度</td>
<td>简化计算图后，ONNX Runtime / TensorRT 推理更快</td>
</tr>
<tr>
<td>🔧 提高兼容性</td>
<td>某些部署平台（如 OpenVINO、MNN）对简化后的模型兼容性更强</td>
</tr>
<tr>
<td>🧩 易于可视化分析</td>
<td>模型结构更清晰，利于在 Netron 中查看和理解</td>
</tr>
</tbody>
</table>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/12/2025%E5%B9%B43%E6%9C%8812%E6%97%A5-onnx4-%E5%9B%BE%E4%BC%98%E5%8C%96/" data-id="cmanj8o210008lcv42fxu34el" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/onnx/" rel="tag">onnx</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月11日-yolov5-5-0训练" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/11/2025%E5%B9%B43%E6%9C%8811%E6%97%A5-yolov5-5-0%E8%AE%AD%E7%BB%83/" class="article-date">
  <time class="post-time" datetime="2025-03-11T03:59:58.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">11</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/11/2025%E5%B9%B43%E6%9C%8811%E6%97%A5-yolov5-5-0%E8%AE%AD%E7%BB%83/">2025年3月11日 yolov5 5.0训练</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="sad"><a class="markdownIt-Anchor" href="#sad"></a> sad</h2>
<h2 id="报错"><a class="markdownIt-Anchor" href="#报错"></a> 报错</h2>
<p>库的版本要匹配上 否则会出现不确定错误</p>
<ol>
<li>
<p>pydantic_core._pydantic_core.ValidationError: 1 validation error for Settings<br>
anonymous<br>
Input should be ‘allow’, ‘must’ or ‘never’ [type=literal_error, input_value=‘true’, input_type=str]<br>
For further information visit <a target="_blank" rel="noopener" href="https://errors.pydantic.dev/2.10/v/literal_error">https://errors.pydantic.dev/2.10/v/literal_error</a></p>
<p>建议：wandb 下降版本<code>pip install wandb==0.12.10</code></p>
</li>
<li>
<p>You are using <code>torch.load</code> with <code>weights_only=False</code> (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling</p>
<p>修改代码中加载模型权重的部分</p>
<p><code> run_id = torch.load(weights, weights_only=True).get('wandb_id')  # 添加weights_only=True</code></p>
</li>
<li>
<p>File “F:\Pydata\DL_NEW\YOLO\yolov5-5.0\utils\datasets.py”, line 411, in <strong>init</strong><br>
bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index</p>
</li>
</ol>
<p><code>pip install numpy==1.22.4       # 部分新库兼容的中间版本</code></p>
<ol start="4">
<li>
<p>TypeError: Descriptors cannot be created directly.<br>
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc &gt;= 3.19.0.<br>
If you cannot immediately regenerate your protos, some other possible workarounds are:</p>
<ol>
<li>Downgrade the protobuf package to 3.20.x or lower.</li>
<li>Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).</li>
</ol>
<p><code>pip install protobuf==3.20.1 </code></p>
</li>
<li>
<p>是</p>
</li>
</ol>
<p>代码出现的问题:</p>
<ol>
<li>
<p>手动添加SSF层</p>
</li>
<li>
<p>缺少logger</p>
<p>手动添加 <code>logger = logging.getLogger(__name__)</code></p>
</li>
<li></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/11/2025%E5%B9%B43%E6%9C%8811%E6%97%A5-yolov5-5-0%E8%AE%AD%E7%BB%83/" data-id="cm8q1tfhp000upcv4f52t1sn8" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/yolo/" rel="tag">yolo</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月10日-onnx3进阶使用与常见问题" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-onnx3%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" class="article-date">
  <time class="post-time" datetime="2025-03-10T13:15:13.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">10</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-onnx3%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/">2025年3月10日 onnx2</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li></li>
</ul>
<h2 id="导出报错"><a class="markdownIt-Anchor" href="#导出报错"></a> 导出报错</h2>
<p>Unsupported: ONNX export of convolution for kernel of unknown shape”，这通常与动态形状或无法推断的卷积核尺寸有</p>
<ol>
<li>
<p>静态化Reshape操作</p>
</li>
<li>
<p>修复多级融合的TracerWarning fused_cls = sum(w * c for w, c in zip(weights_cls, preds_cls))</p>
<p><code>sum(w * c for w, c in zip(...))</code>中的迭代操作会被PyTorch的JIT Tracer识别为动态控制流，导致ONNX导出时无法生成静态计算图。这种Python层的迭代操作在模型跟踪阶段会被视为潜在动态行为，从而触发TracerWarning</p>
</li>
</ol>
<h3 id="2-importerror-dll-load-failed-while-importing-onnx_cpp2py_export-动态链接库dll初始化例程失败"><a class="markdownIt-Anchor" href="#2-importerror-dll-load-failed-while-importing-onnx_cpp2py_export-动态链接库dll初始化例程失败"></a> 2 ImportError: DLL load failed while importing onnx_cpp2py_export: 动态链接库(DLL)初始化例程失败。</h3>
<blockquote>
<p>重新安装 onnx</p>
</blockquote>
<h2 id="结构报错"><a class="markdownIt-Anchor" href="#结构报错"></a> 结构报错</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="1-为什么导出的onnx会有那么多identity这是什么怎么消除"><a class="markdownIt-Anchor" href="#1-为什么导出的onnx会有那么多identity这是什么怎么消除"></a> 1 为什么导出的onnx会有那么多Identity，这是什么，怎么消除</h3>
<p><img src="/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-onnx3%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20250310215555781.png" alt="image-20250310215555781"></p>
<ol>
<li><strong>数据传递占位符</strong> Identity节点的核心功能是将输入张量原样输出，不进行任何计算</li>
<li><strong>框架转换机制缺陷</strong></li>
<li><strong>自定义算子副作用</strong></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-onnx3%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" data-id="cmanj8o1s0006lcv45hyj3669" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/onnx/" rel="tag">onnx</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月10日-C-记录" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-C-%E8%AE%B0%E5%BD%95/" class="article-date">
  <time class="post-time" datetime="2025-03-10T05:29:15.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">10</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-C-%E8%AE%B0%E5%BD%95/">2025年3月10日 C++记录</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="c"><a class="markdownIt-Anchor" href="#c"></a> ✨C++</h1>
<h2 id="基础知识"><a class="markdownIt-Anchor" href="#基础知识"></a> 基础知识</h2>
<h3 id="1-变量作用域"><a class="markdownIt-Anchor" href="#1-变量作用域"></a> 1 变量作用域</h3>
<ol>
<li>什么是局部变量 ☑️</li>
<li>什么是全局变量 ☑️</li>
<li>什么是块作用域，如何实现？</li>
<li>类？</li>
</ol>
<h3 id="2-常量"><a class="markdownIt-Anchor" href="#2-常量"></a> 2 常量？</h3>
<ol>
<li>定义？</li>
<li>如何定义常量</li>
</ol>
<h3 id="3-修饰符"><a class="markdownIt-Anchor" href="#3-修饰符"></a> 3 修饰符</h3>
<ol>
<li>
<p>修饰符类型</p>
</li>
<li>
<p>类型限定符：是什么？</p>
<table>
<thead>
<tr>
<th>static</th>
<th>用于定义静态变量，表示该变量的作用域仅限于当前文件或当前函数内，不会被其他文件或函数访问。</th>
</tr>
</thead>
<tbody>
<tr>
<td>const</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li></li>
</ol>
<h3 id="4-c-存储类"><a class="markdownIt-Anchor" href="#4-c-存储类"></a> 4 C++ 存储类</h3>
<p>控制变量和函数生命周期及可见性的手段。？？？</p>
<ul>
<li><strong>extern</strong> 都有什么用？全局变量，具有外部链接，默认存储类为extern</li>
<li><strong>auto</strong></li>
<li><strong>static</strong></li>
</ul>
<h3 id="5-运算符"><a class="markdownIt-Anchor" href="#5-运算符"></a> 5 运算符</h3>
<ul>
<li>
<p>逻辑运算符</p>
</li>
<li>
<h4 id="运算符优先级"><a class="markdownIt-Anchor" href="#运算符优先级"></a> 运算符优先级</h4>
</li>
</ul>
<h3 id="6-lambda-函数与表达式"><a class="markdownIt-Anchor" href="#6-lambda-函数与表达式"></a> 6 Lambda 函数与表达式</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[](int x, int y) -&gt; int &#123; int z = x + y; return z + x; &#125;</span><br></pre></td></tr></table></figure>
<p>递归+lamda</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">auto dfs = [&amp;](this auto&amp;&amp; dfs, int i, int j) -&gt; int &#123;   // 递归逻辑  &#125;;</span><br></pre></td></tr></table></figure>
<h3 id="7-c-引用"><a class="markdownIt-Anchor" href="#7-c-引用"></a> 7 C++ 引用</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int a = 10;</span><br><span class="line">int &amp;ref = a;  // ref 是 a 的引用</span><br></pre></td></tr></table></figure>
<ul>
<li><code>int &amp;ref</code> 表示 <code>ref</code> 是一个 <code>int</code> 类型的引用。</li>
<li><code>ref</code> 是 <code>a</code> 的别名，对 <code>ref</code> 的操作会直接作用于 <code>a</code>。</li>
</ul>
<h2 id="code-细节"><a class="markdownIt-Anchor" href="#code-细节"></a> code 细节</h2>
<h4 id="1-越界"><a class="markdownIt-Anchor" href="#1-越界"></a> 1 越界</h4>
<ul>
<li><strong>先判断空栈，再取栈顶元素</strong>。<code>if(val &lt; min_stack.back() || min_stack.empty())</code></li>
</ul>
<h2 id="std"><a class="markdownIt-Anchor" href="#std"></a> std</h2>
<h3 id="1-map-和-set"><a class="markdownIt-Anchor" href="#1-map-和-set"></a> 1 map 和 set</h3>
<table>
<thead>
<tr>
<th>特点</th>
<th>unordered_map</th>
</tr>
</thead>
<tbody>
<tr>
<td>存储</td>
<td>键值对 (key, value)</td>
</tr>
<tr>
<td>使用场景</td>
<td>需要存储键值对，例如统计频率，映射关系</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>map[key]</code></td>
<td>访问 / 插入元素，若 key 不存在会默认插入一个默认值</td>
</tr>
<tr>
<td><code>map.at(key)</code></td>
<td>访问元素，key 不存在会抛异常</td>
</tr>
<tr>
<td><code>map.insert(&#123;key, value&#125;)</code></td>
<td>插入键值对</td>
</tr>
<tr>
<td><code>map.emplace(key, value)</code></td>
<td>就地构造，效率比 <code>insert</code> 更高</td>
</tr>
<tr>
<td><code>map.erase(key)</code></td>
<td>删除键为 <code>key</code> 的元素</td>
</tr>
<tr>
<td><code>map.clear()</code></td>
<td>清空所有元素</td>
</tr>
<tr>
<td><code>map.count(key)</code></td>
<td>判断 key 是否存在，存在返回 1，不存在返回 0</td>
</tr>
<tr>
<td><code>map.find(key)</code></td>
<td>查找 key，返回迭代器，等于 <code>map.end()</code> 表示没找到</td>
</tr>
<tr>
<td><code>map.size()</code></td>
<td>返回元素个数</td>
</tr>
<tr>
<td><code>map.empty()</code></td>
<td>判断是否为空</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>set.insert(key)</code></td>
<td>插入元素</td>
</tr>
<tr>
<td><code>set.emplace(key)</code></td>
<td>就地构造，效率更高</td>
</tr>
<tr>
<td><code>set.erase(key)</code></td>
<td>删除元素</td>
</tr>
<tr>
<td><code>set.clear()</code></td>
<td>清空元素</td>
</tr>
<tr>
<td><code>set.count(key)</code></td>
<td>判断元素是否存在，存在返回 1</td>
</tr>
<tr>
<td><code>set.find(key)</code></td>
<td>查找元素，返回迭代器</td>
</tr>
<tr>
<td><code>set.size()</code></td>
<td>返回元素个数</td>
</tr>
<tr>
<td><code>set.empty()</code></td>
<td>判断是否为空</td>
</tr>
</tbody>
</table>
<h3 id="2-vector"><a class="markdownIt-Anchor" href="#2-vector"></a> 2 vector</h3>
<table>
<thead>
<tr>
<th>功能类别</th>
<th>函数名</th>
<th>作用描述</th>
<th>时间复杂度</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>插入</strong></td>
<td><code>push_back(val)</code></td>
<td>在 vector 尾部插入元素 <code>val</code></td>
<td><strong>摊销 O(1)</strong></td>
</tr>
<tr>
<td><strong>删除</strong></td>
<td><code>pop_back()</code></td>
<td>删除 vector 尾部元素</td>
<td><strong>O(1)</strong></td>
</tr>
<tr>
<td><strong>访问</strong></td>
<td><code>back()</code></td>
<td>返回 vector 的最后一个元素（不删除）</td>
<td><strong>O(1)</strong></td>
</tr>
<tr>
<td></td>
<td><code>front()</code></td>
<td>返回 vector 的第一个元素（不删除）</td>
<td><strong>O(1)</strong></td>
</tr>
<tr>
<td></td>
<td><code>at(index)</code></td>
<td>返回指定下标元素，带边界检查</td>
<td><strong>O(1)</strong></td>
</tr>
<tr>
<td></td>
<td><code>operator[]</code></td>
<td>返回指定下标元素（不带边界检查）</td>
<td><strong>O(1)</strong></td>
</tr>
<tr>
<td><strong>状态</strong></td>
<td><code>empty()</code></td>
<td>检查 vector 是否为空</td>
<td><strong>O(1)</strong></td>
</tr>
<tr>
<td></td>
<td><code>size()</code></td>
<td>返回 vector 中元素个数</td>
<td><strong>O(1)</strong></td>
</tr>
<tr>
<td><strong>清空</strong></td>
<td><code>clear()</code></td>
<td>清空 vector 所有元素</td>
<td><strong>O(n)</strong></td>
</tr>
<tr>
<td><strong>其他</strong></td>
<td><code>resize(n)</code></td>
<td>调整 vector 大小为 <code>n</code>，默认填充值为零</td>
<td><strong>O(n)</strong></td>
</tr>
<tr>
<td></td>
<td><code>reserve(n)</code></td>
<td>预留空间，避免多次扩容</td>
<td><strong>O(n)</strong></td>
</tr>
</tbody>
</table>
<h3 id="3-字符串操作函数"><a class="markdownIt-Anchor" href="#3-字符串操作函数"></a> 3、字符串操作函数</h3>
<table>
<thead>
<tr>
<th>函数</th>
<th>功能</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>s.length()</code> / <code>s.size()</code></td>
<td>字符串长度</td>
<td></td>
</tr>
<tr>
<td><code>s.substr(pos, len)</code></td>
<td>子串</td>
<td><code>s.substr(0, 3)</code></td>
</tr>
<tr>
<td><code>s.find(sub)</code></td>
<td>查找子串位置</td>
<td><code>s.find(&quot;abc&quot;)</code></td>
</tr>
<tr>
<td><code>s.rfind(sub)</code></td>
<td>反向查找子串位置</td>
<td></td>
</tr>
<tr>
<td><code>s.erase(pos, len)</code></td>
<td>删除子串</td>
<td></td>
</tr>
<tr>
<td><code>s.insert(pos, sub)</code></td>
<td>插入子串</td>
<td></td>
</tr>
<tr>
<td><code>s.replace(pos, len, sub)</code></td>
<td>替换子串</td>
<td></td>
</tr>
<tr>
<td><code>reverse(s.begin(), s.end())</code></td>
<td>字符串反转</td>
<td></td>
</tr>
<tr>
<td><code>sort(s.begin(), s.end())</code></td>
<td>字符串排序</td>
<td></td>
</tr>
<tr>
<td><code>toupper(ch)</code> / <code>tolower(ch)</code></td>
<td>字符大小写转换</td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="4-数字cmath"><a class="markdownIt-Anchor" href="#4-数字cmath"></a> 4、数字（<cmath>`）</cmath></h3>
<table>
<thead>
<tr>
<th>函数</th>
<th>功能</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>abs(x)</code></td>
<td>绝对值</td>
<td><code>abs(-3) // 3</code></td>
</tr>
<tr>
<td><code>pow(a, b)</code></td>
<td>幂</td>
<td><code>pow(2, 3) // 8</code></td>
</tr>
<tr>
<td><code>sqrt(x)</code></td>
<td>开方</td>
<td><code>sqrt(16) // 4</code></td>
</tr>
<tr>
<td><code>log(x)</code></td>
<td>自然对数</td>
<td></td>
</tr>
<tr>
<td><code>log10(x)</code></td>
<td>以 10 为底的对数</td>
<td></td>
</tr>
<tr>
<td><code>ceil(x)</code></td>
<td>向上取整</td>
<td><code>ceil(2.3) // 3</code></td>
</tr>
<tr>
<td><code>floor(x)</code></td>
<td>向下取整</td>
<td><code>floor(2.7) // 2</code></td>
</tr>
<tr>
<td><code>round(x)</code></td>
<td>四舍五入</td>
<td><code>round(2.5) // 3</code></td>
</tr>
<tr>
<td><code>max(a, b)</code> / <code>min(a, b)</code></td>
<td>最大/最小值</td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="5-算法algorithm"><a class="markdownIt-Anchor" href="#5-算法algorithm"></a> 5 算法（<code>&lt;algorithm&gt;</code>）</h3>
<table>
<thead>
<tr>
<th>函数</th>
<th>功能</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>sort(start, end)</code></td>
<td>排序</td>
<td></td>
</tr>
<tr>
<td><code>reverse(start, end)</code></td>
<td>反转</td>
<td></td>
</tr>
<tr>
<td><code>next_permutation(start, end)</code></td>
<td>下一个排列</td>
<td></td>
</tr>
<tr>
<td><code>prev_permutation(start, end)</code></td>
<td>上一个排列</td>
<td></td>
</tr>
<tr>
<td><code>lower_bound(start, end, val)</code></td>
<td>二分查找，返回 ≥val 的首元素迭代器</td>
<td></td>
</tr>
<tr>
<td><code>upper_bound(start, end, val)</code></td>
<td>二分查找，返回 &gt;val 的首元素迭代器</td>
<td></td>
</tr>
<tr>
<td><code>count(start, end, val)</code></td>
<td>统计元素出现次数</td>
<td></td>
</tr>
<tr>
<td><code>find(start, end, val)</code></td>
<td>查找元素</td>
<td></td>
</tr>
<tr>
<td><code>accumulate(start, end, init)</code></td>
<td>元素累加 (需 <code>&lt;numeric&gt;</code>)</td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="力扣刷题"><a class="markdownIt-Anchor" href="#力扣刷题"></a> 🚀力扣刷题</h1>
<h2 id="算法设计"><a class="markdownIt-Anchor" href="#算法设计"></a> 算法设计</h2>
<h3 id="1-快慢指针算法"><a class="markdownIt-Anchor" href="#1-快慢指针算法"></a> 1 快慢指针算法</h3>
<ol>
<li>判断循环</li>
<li>遍历</li>
</ol>
<h3 id="2-贪心算法"><a class="markdownIt-Anchor" href="#2-贪心算法"></a> 2 贪心算法</h3>
<ol>
<li>一般用在有cost的</li>
</ol>
<h3 id="3-动态规划"><a class="markdownIt-Anchor" href="#3-动态规划"></a> 3 动态规划</h3>
<ol>
<li>后面的前面已经解决过了// 重后面开始算起，简单的算起</li>
<li>背包问题 爬楼梯</li>
<li>滚动数组</li>
<li>递归【枚举判断初始条件是否正确】–&gt; 变成动态规划  存储前状态变量</li>
</ol>
<h3 id="4-滑动窗口思想总结"><a class="markdownIt-Anchor" href="#4-滑动窗口思想总结"></a> 4 滑动窗口思想总结</h3>
<p><strong>核心思想：</strong><br>
滑动窗口是一种高效解决「子数组 / 子区间 / 子串」问题的技巧，</p>
<p>维护窗口大小，缩小当前维护与扩展窗口</p>
<p>通常用于：</p>
<ul>
<li><strong>连续子序列</strong>：比如最长不重复子串、子数组和等。</li>
<li></li>
</ul>
<h3 id="5-用栈追溯"><a class="markdownIt-Anchor" href="#5-用栈追溯"></a> 5 用栈追溯</h3>
<h3 id="5-链表"><a class="markdownIt-Anchor" href="#5-链表"></a> 5 链表</h3>
<ol>
<li>呀节点 避免nullptr的判断 <code>return dummy-&gt;next</code> 即可</li>
</ol>
<h2 id="日期记录"><a class="markdownIt-Anchor" href="#日期记录"></a> 🌏日期记录</h2>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/10/2025%E5%B9%B43%E6%9C%8810%E6%97%A5-C-%E8%AE%B0%E5%BD%95/" data-id="cm8q1tfhn000ppcv4eds1bem1" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C/" rel="tag">C++</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月7日-loss汇总" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/06/2025%E5%B9%B43%E6%9C%887%E6%97%A5-loss%E6%B1%87%E6%80%BB/" class="article-date">
  <time class="post-time" datetime="2025-03-06T04:44:46.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">06</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/06/2025%E5%B9%B43%E6%9C%887%E6%97%A5-loss%E6%B1%87%E6%80%BB/">2025年3月7日 loss汇总</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/06/2025%E5%B9%B43%E6%9C%887%E6%97%A5-loss%E6%B1%87%E6%80%BB/" data-id="cm8q1tfhy001cpcv43gu2ejcs" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月6日-多尺度特征" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/06/2025%E5%B9%B43%E6%9C%886%E6%97%A5-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81/" class="article-date">
  <time class="post-time" datetime="2025-03-06T02:22:16.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">06</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/06/2025%E5%B9%B43%E6%9C%886%E6%97%A5-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81/">2025年3月6日 多尺度特征</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="混合特征学习feature-fusion"><a class="markdownIt-Anchor" href="#混合特征学习feature-fusion"></a> 混合特征学习（Feature Fusion）</h1>
<p><strong>混合特征学习（Feature Fusion）</strong> 是指将来自不同来源或不同尺度的特征信息结合在一起，从而提升深度学习模型的表达能力。常见的特征融合方法包括 加权融合（Weighted Fusion） 和 级联融合（Concatenation Fusion）。</p>
<ol>
<li>
<p><strong>加权融合（Weighted Fusion）</strong><br>
加权融合是一种<strong>将多个特征图进行加权合并</strong>的方式。不同来源或不同尺度的特征图按照一定的权重加权后合并，从而突出重要的特征。</p>
</li>
<li>
<p><strong>级联融合（Concatenation Fusion）</strong><br>
级联融合是将多个特征图在<strong>某一维度（通常是通道维度）上拼接</strong>起来。级联融合的优势是它不会丢失任何信息，所有特征图都被保留下来，虽然拼接后的特征图会变得更加庞大。</p>
</li>
</ol>
<h2 id="多尺度卷积神经网络ms-cnn"><a class="markdownIt-Anchor" href="#多尺度卷积神经网络ms-cnn"></a> <strong>多尺度卷积神经网络（MS-CNN）</strong></h2>
<p>通过将图像<strong>输入多个卷积层或卷积核以不同的尺度处理，可以让模型同时捕获到不同尺寸的特征</strong></p>
<h3 id="原理"><a class="markdownIt-Anchor" href="#原理"></a> 原理</h3>
<p><strong>MS-CNN</strong> 通过以下几种方式来实现多尺度特征提取：</p>
<ul>
<li><strong>使用多个卷积核：不同的卷积核（大小、步长等）可以提取不同尺度的特征。</strong></li>
<li><strong>多层次网络结构：不同的层次使用不同尺度的卷积操作来处理输入图像，从而提取多尺度信息。</strong></li>
<li><strong>输入图像的多尺度处理：将同一张图像通过不同尺度（例如不同的图像缩放比例）进行处理，结合多个尺度的特征。</strong></li>
</ul>
<h3 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> 实现</h3>
<ol>
<li>使用合适的填充和步长，确保不同卷积核提取的特征图在空间维度上一致。</li>
<li>在通道维度上拼接特征图，避免空间维度的变化。</li>
<li>使用1×1卷积进行特征融合，进一步整合多尺度信息。</li>
<li>使用全局池化将特征图调整为固定尺寸，确保输出的一致性</li>
</ol>
<h2 id="空间金字塔池化spatial-pyramid-pooling-spp"><a class="markdownIt-Anchor" href="#空间金字塔池化spatial-pyramid-pooling-spp"></a> 空间金字塔池化（Spatial Pyramid Pooling, SPP）</h2>
<h3 id="原理-2"><a class="markdownIt-Anchor" href="#原理-2"></a> 原理</h3>
<p>在多个尺度上提取特征</p>
<ul>
<li><strong>划分不同大小的网格</strong>：将输入特征图划分为多个不同尺寸的子区域（例如，1x1、2x2、4x4等）。</li>
<li><strong>在每个子区域上执行池化操作</strong>：对每个子区域使用池化操作（如最大池化或平均池化），生成不同尺度下的特征。</li>
<li><strong>拼接池化结果</strong>：将所有尺度上的池化结果<strong>展平并</strong>拼接成一个向量，作为最终的特征表示。</li>
</ul>
<h2 id="多尺度注意力机制multi-scale-attention-mechanism"><a class="markdownIt-Anchor" href="#多尺度注意力机制multi-scale-attention-mechanism"></a> 多尺度注意力机制（Multi-Scale Attention Mechanism）</h2>
<h3 id="原理-3"><a class="markdownIt-Anchor" href="#原理-3"></a> 原理</h3>
<p>通过注意力机制对图像的不同尺度或区域进行<strong>加权</strong>，帮助网络聚焦于关键区域，从而更有效地提取特征的方法</p>
<h3 id="实现-2"><a class="markdownIt-Anchor" href="#实现-2"></a> 实现</h3>
<h4 id="non-local-attention"><a class="markdownIt-Anchor" href="#non-local-attention"></a> <strong>Non-local Attention</strong></h4>
<h4 id="squeeze-and-excitation-networks-se-net"><a class="markdownIt-Anchor" href="#squeeze-and-excitation-networks-se-net"></a> Squeeze-and-Excitation Networks (SE-Net)</h4>
<p>SE-Net）是一种通过引入自适应的<strong>通道注意力机制</strong>来提升模型性能的网络。它通过“压缩”和“激励”两个操作来对不同通道的特征进行加权，使得网络能够自适应地学习哪些通道对特定任务更为重要。</p>
<h5 id="原理-4"><a class="markdownIt-Anchor" href="#原理-4"></a> 原理</h5>
<ul>
<li><strong>Squeeze：通过全局平均池化（Global Average Pooling），将每个通道的空间信息压缩成一个标量。</strong></li>
<li><strong>Excitation：通过一个全连接层（或者更深的网络）生成通道的权重，这些权重用于调整每个通道的特征响应。</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.AdaptiveAvgPool2d(1)</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/06/2025%E5%B9%B43%E6%9C%886%E6%97%A5-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81/" data-id="cm8q1tfhr0013pcv4fmixa517" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月6日-多尺度训练" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/06/2025%E5%B9%B43%E6%9C%886%E6%97%A5-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%AE%AD%E7%BB%83/" class="article-date">
  <time class="post-time" datetime="2025-03-06T01:50:49.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">06</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/06/2025%E5%B9%B43%E6%9C%886%E6%97%A5-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%AE%AD%E7%BB%83/">2025年3月6日 多尺度训练</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/2025/03/06/2025%E5%B9%B43%E6%9C%886%E6%97%A5-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%AE%AD%E7%BB%83/image-20250306095133429.png" alt="image-20250306095133429"></p>
<h2 id="全卷积"><a class="markdownIt-Anchor" href="#全卷积"></a> 全卷积</h2>
<p>除了最后的分类层是全连接层，而特征提取部分都是卷积或者池化操作，它们可以自适应各种尺寸的图像输入。</p>
<h2 id="spp-net"><a class="markdownIt-Anchor" href="#spp-net"></a> SPP-Net</h2>
<p>现有的（传统的） CNNs 由于有全连接层所以必须需要固定输入图片的尺寸，比如 224 × 224 。本文为传统的网络结构增加了一个池化策略，即空间金字塔池化，来突破全连接层对整个网络输入图像的约束。无论输入图像的尺寸是多少，SPP-Net 能够产生一个固定长度的特征向量，且能够适应形变，在分类和物体检测任务中都有很好的表现</p>
<h3 id="空间金字塔池化-spatial-pyramid-pooling"><a class="markdownIt-Anchor" href="#空间金字塔池化-spatial-pyramid-pooling"></a> 空间金字塔池化 spatial pyramid pooling</h3>
<p>用于解决传统卷积神经网络（CNN）中输入图像尺寸必须固定的问题。通过将特征图划分为不同粒度的区域，并对每个区域进行池化操作，SPP能够生成固定长度的特征向量，从而允许网络处理任意尺寸的输入图像</p>
<p>空间金字塔池化的加入，使得模型在预测/测试时可以不限定输入图像的大小，同时在训练阶段，也允许模型实现多尺度训练，这一点很有利于增强尺度不变性并降低过拟合的风险。</p>
<p><strong>输入特征图的尺寸无关，只与池化级别和通道数有关</strong></p>
<h4 id="原理"><a class="markdownIt-Anchor" href="#原理"></a> <strong>原理</strong></h4>
<p>SPP将特征图划分为多个不同大小的区域（如1×1、2×2、3×3、6×6等），并对每个区域进行最大池化或平均池化操作。这些池化后的特征被展平并拼接在一起，形成一个固定长度的特征向量</p>
<h4 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> <strong>实现</strong></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpatialPyramidPooling2d</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_level, pool_type=<span class="string">&#x27;max_pool&#x27;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">        num_level: 池化层的级别数量（例如，[1, 2, 4]表示3个级别）</span></span><br><span class="line"><span class="string">        pool_type: 池化类型（&#x27;max_pool&#x27; 或 &#x27;avg_pool&#x27;）</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(SpatialPyramidPooling2d, self).__init__()</span><br><span class="line">        self.num_level = num_level</span><br><span class="line">        self.pool_type = pool_type</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        N, C, H, W = x.size()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_level):</span><br><span class="line">            level = i + <span class="number">1</span></span><br><span class="line">            kernel_size = (math.ceil(H / level), math.ceil(W / level))</span><br><span class="line">            stride = (math.ceil(H / level), math.ceil(W / level))</span><br><span class="line">            padding = (</span><br><span class="line">                math.floor((kernel_size[<span class="number">0</span>] * level - H + <span class="number">1</span>) / <span class="number">2</span>),</span><br><span class="line">                math.floor((kernel_size[<span class="number">1</span>] * level - W + <span class="number">1</span>) / <span class="number">2</span>)</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">if</span> self.pool_type == <span class="string">&#x27;max_pool&#x27;</span>:</span><br><span class="line">                tensor = F.max_pool2d(x, kernel_size=kernel_size, stride=stride, padding=padding).view(N, -<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                tensor = F.avg_pool2d(x, kernel_size=kernel_size, stride=stride, padding=padding).view(N, -<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                res = tensor</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res = torch.cat((res, tensor), <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h3 id="2-自适应池化adaptive-pooling"><a class="markdownIt-Anchor" href="#2-自适应池化adaptive-pooling"></a> 2. <strong>自适应池化（Adaptive Pooling）</strong></h3>
<h4 id="原理-2"><a class="markdownIt-Anchor" href="#原理-2"></a> 原理</h4>
<p><strong>自适应池化的目标是根据目标输出尺寸自动调整池化窗口和步长，使得输出尺寸保持一致，不依赖于输入的尺寸</strong>。</p>
<h4 id="实现-2"><a class="markdownIt-Anchor" href="#实现-2"></a> 实现</h4>
<p><code>nn.AdaptiveAvgPool2d((32, 32))</code></p>
<p><code>nn.AdaptiveMaxPool2d((32, 32))</code></p>
<h3 id="3-全局平均池化或全局最大池化global-pooling"><a class="markdownIt-Anchor" href="#3-全局平均池化或全局最大池化global-pooling"></a> 3. <strong>全局平均池化或全局最大池化（Global Pooling）</strong></h3>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/06/2025%E5%B9%B43%E6%9C%886%E6%97%A5-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%AE%AD%E7%BB%83/" data-id="cm8q1tfhs0017pcv4eo49boxo" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-2025年3月5日-图像匹配" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/03/05/2025%E5%B9%B43%E6%9C%885%E6%97%A5-%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/" class="article-date">
  <time class="post-time" datetime="2025-03-05T02:23:20.000Z" itemprop="datePublished">
    <span class="post-month">3月</span><br/>
    <span class="post-day">05</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/05/2025%E5%B9%B43%E6%9C%885%E6%97%A5-%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/">2025年3月5日 图像匹配</a>
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="图像匹配"><a class="markdownIt-Anchor" href="#图像匹配"></a> 图像匹配</h1>
<h2 id="行人重识别"><a class="markdownIt-Anchor" href="#行人重识别"></a> 行人重识别</h2>
<h3 id="什么是reid"><a class="markdownIt-Anchor" href="#什么是reid"></a> 什么是ReID</h3>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40608730/article/details/115431791%E3%80%81">https://blog.csdn.net/qq_40608730/article/details/115431791、</a></p>
<p>判断在不同时间段、不同监控下出现的行人图像是否属于同一人员的技术。行人重识别是最近几年在视频分析领域下热门的研究领域，可以看做是人脸识别应用的拓展。</p>
<p>本质上可以看做是图像匹配任务，比如给你一张要匹配的行人的图，要你从数据库中搜索出此人的其他照片。</p>
<h4 id="发展"><a class="markdownIt-Anchor" href="#发展"></a> 发展</h4>
<p>在行人重识别方向上，2005年到2013年间，传统算法一直都占据主要地位；</p>
<p>自2014年起，深度学习开始慢慢出现在人们的视线中，并在行人再识别研究中取得了显著性的突破，性能指标远超传统算法。</p>
<p>但是根据最近的发展来看，虽然最新的算法达到甚至超越了人类的水平，但是性能指标又到达了一个平台期，目前的研究方向主要是复杂环境、开放环境以及无监督学习领域。</p>
<h4 id="难点"><a class="markdownIt-Anchor" href="#难点"></a> <strong>难点</strong></h4>
<p>数据集<br>
评价指标<br>
实现思路<br>
研究方式</p>
<p>未来方向</p>
<hr>
<h3 id="一般流程"><a class="markdownIt-Anchor" href="#一般流程"></a> 一般流程</h3>
<p><img src="/2025/03/05/2025%E5%B9%B43%E6%9C%885%E6%97%A5-%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/image-20250305102441329.png" alt="image-20250305102441329"></p>
<h3 id="实现思路"><a class="markdownIt-Anchor" href="#实现思路"></a> 实现思路</h3>
<ol>
<li>先抽取特征再进行比对</li>
<li>检索图经过网络抽取图片特征（Feature）</li>
<li>检索库里的所有图片全部抽取图片特征（Feature）</li>
<li>将检索图与检索库图的特征计算距离（例如欧式距离）</li>
<li>根据计算距离进行排序，排序越靠前表示是相似率越高</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/03/05/2025%E5%B9%B43%E6%9C%885%E6%97%A5-%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/" data-id="cm8q1tfhx001bpcv4fxdaau4f" class="article-share-link">分享</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
</article>




  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/2/">&amp;laquo; pre</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/4/">next &amp;raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Weakliy_Blog</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>92</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>29</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="Github">
          Github
        </a>
      
    </div>

    <div class="friend-link">
      <h2>联系我</h2>
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2024 - 2025 Weakliy<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">首页</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">总览</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">xxx</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">xxxx</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>