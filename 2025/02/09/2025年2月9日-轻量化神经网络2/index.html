<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>2025年2月9日 轻量化神经网络2 | Weakliy_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="SqueezeNet  Fire Module Fire Module：每个 Fire Module 由两个主要部分组成：  Squeeze层：一个1x1的卷积层，用来减少特征图的深度。 Expand层：两个分支，一个是1x1卷积，另一个是3x3卷积，用来增加特征图的深度。  通过这种结构，SqueezeNet能够有效地减少参数量，而不牺牲太多的准确度。 减少全连接层的参数：SqueezeNet">
<meta property="og:type" content="article">
<meta property="og:title" content="2025年2月9日 轻量化神经网络2">
<meta property="og:url" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/index.html">
<meta property="og:site_name" content="Weakliy_Blog">
<meta property="og:description" content="SqueezeNet  Fire Module Fire Module：每个 Fire Module 由两个主要部分组成：  Squeeze层：一个1x1的卷积层，用来减少特征图的深度。 Expand层：两个分支，一个是1x1卷积，另一个是3x3卷积，用来增加特征图的深度。  通过这种结构，SqueezeNet能够有效地减少参数量，而不牺牲太多的准确度。 减少全连接层的参数：SqueezeNet">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209162740618.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209172824970.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209172918099.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209173848541.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174104028.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209180216944.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174529781.png">
<meta property="og:image" content="https://pic2.zhimg.com/v2-7c42cff2fa3c346d2e41be95848fc619_1440w.jpg">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174719710.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209183640934.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209184403579.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209184638406.png">
<meta property="og:image" content="https://pic4.zhimg.com/v2-31d05dfac01c6ae64bd5bf4e52ffc069_1440w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/v2-dc2339ac78de452e286317dd259070f5_1440w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-104058d724746316b12298ec27fafe26_1440w.jpg">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224653761.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209190732084.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209223353104.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224903212.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224555819.png">
<meta property="og:image" content="https://pic4.zhimg.com/v2-faec285a27615d8829af43172d9d1385_1440w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/v2-a0f1319eae0571829c79b1a70d4fc1b9_1440w.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/v2-032dfea7e52345c3f26a543e3dbcc6fd_1440w.jpg">
<meta property="og:image" content="https://pic1.zhimg.com/v2-4f1414b59ea6700387f0dea2dac0d878_1440w.jpg">
<meta property="og:image" content="https://pica.zhimg.com/v2-646a538d15c17d28145024953ff90eda_1440w.jpg">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209230157789.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209230342459.png">
<meta property="og:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209231222947.png">
<meta property="article:published_time" content="2025-02-09T07:21:36.000Z">
<meta property="article:modified_time" content="2025-02-09T15:30:23.813Z">
<meta property="article:author" content="Weakliy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209162740618.png">
  
    <link rel="alternate" href="/atom.xml" title="Weakliy_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>79</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>17</strong><br>标签</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main"><article id="post-2025年2月9日-轻量化神经网络2" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/" class="article-date">
  <time class="post-time" datetime="2025-02-09T07:21:36.000Z" itemprop="datePublished">
    <span class="post-month">2月</span><br/>
    <span class="post-day">09</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      2025年2月9日 轻量化神经网络2
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="squeezenet"><a class="markdownIt-Anchor" href="#squeezenet"></a> SqueezeNet</h1>
<h3 id="fire-module"><a class="markdownIt-Anchor" href="#fire-module"></a> Fire Module</h3>
<p><strong>Fire Module</strong>：每个 Fire Module 由两个主要部分组成：</p>
<ul>
<li><strong>Squeeze层</strong>：一个1x1的卷积层，用来减少特征图的深度。</li>
<li><strong>Expand层</strong>：两个分支，一个是1x1卷积，另一个是3x3卷积，用来增加特征图的深度。</li>
</ul>
<p>通过这种结构，SqueezeNet能够有效地减少参数量，而不牺牲太多的准确度。</p>
<p><strong>减少全连接层的参数</strong>：SqueezeNet中没有传统的全连接层，而是使用全局平均池化（Global Average Pooling）来替代。这样大大减少了参数数量，且仍然保留了模型的表现力。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat([x1, x2], 1)</span><br></pre></td></tr></table></figure>
<h1 id="mobilenethttpsblogcsdnnetqq_37555071articledetails108393809"><a class="markdownIt-Anchor" href="#mobilenethttpsblogcsdnnetqq_37555071articledetails108393809"></a> [MobileNet][<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37555071/article/details/108393809">https://blog.csdn.net/qq_37555071/article/details/108393809</a>]</h1>
<h2 id="深度可分离卷积depthwise-separable-convolutions"><a class="markdownIt-Anchor" href="#深度可分离卷积depthwise-separable-convolutions"></a> 深度可分离卷积(Depthwise Separable Convolutions)</h2>
<p>（Depthwise Separable Convolutions）</p>
<p><strong>深度卷积（Depthwise Convolution）</strong>：对每个输入通道独立进行卷积操作，而不是像传统卷积那样对所有通道进行卷积。这大大减少了计算量。</p>
<p><strong>逐点卷积（Pointwise Convolution）</strong>：即1x1卷积，用于将深度卷积的输出进行线性组合，融合通道信息。</p>
<p><strong>宽度和分辨率的可调性</strong>： MobileNet引入了两个超参数，分别是<strong>宽度系数（Width Multiplier）**和**分辨率系数（Resolution Multiplier）</strong>，使得网络的大小和计算量可以根据实际需求进行调整。</p>
<ul>
<li><strong>宽度系数（α）</strong>：用于控制网络每一层的通道数。通过减小α的值，可以降低网络的复杂度和参数数量。</li>
<li><strong>分辨率系数（ρ）</strong>：用于控制输入图像的分辨率，通过减小分辨率来减少计算量。</li>
</ul>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209162740618.png" alt="image-20250209162740618"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, groups=in_channels, bias=<span class="literal">False</span>)</span><br><span class="line">// groups=in_channels</span><br></pre></td></tr></table></figure>
<h1 id="shufflenet"><a class="markdownIt-Anchor" href="#shufflenet"></a> ShuffleNet</h1>
<p><strong>深度可分离卷积（Depthwise Separable Convolution） 和</strong></p>
<h2 id="通道混洗channel-shuffle"><a class="markdownIt-Anchor" href="#通道混洗channel-shuffle"></a> <strong>通道混洗（Channel Shuffle）</strong></h2>
<p>通道混洗技术会在<strong>每个卷积层的输出中打乱通道的顺序</strong>，使得不同通道的特征能够进行更好的融合，从而提高模型的表达能力和准确率。</p>
<h2 id="分组卷积grouped-convolution"><a class="markdownIt-Anchor" href="#分组卷积grouped-convolution"></a> <strong>分组卷积（Grouped Convolution）</strong></h2>
<p>为了进一步提高网络的计算效率，ShuffleNet 采用了 <strong>分组卷积（Grouped Convolution）</strong>。分组卷积将输入通道分成多个组，每个组内的通道与一个独立的卷积核进行卷积，从而减少了卷积运算的计算量。</p>
<h1 id="googlenet"><a class="markdownIt-Anchor" href="#googlenet"></a> GoogLeNet</h1>
<h2 id="inception块"><a class="markdownIt-Anchor" href="#inception块"></a> Inception块</h2>
<p>各种模块全都要</p>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209172824970.png" alt="image-20250209172824970" style="zoom:50%;">
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209172918099.png" alt="image-20250209172918099" style="zoom:67%;">
<h2 id="xception-块"><a class="markdownIt-Anchor" href="#xception-块"></a> <strong>Xception 块</strong></h2>
<p>极限情况</p>
<h1 id="efficientnet"><a class="markdownIt-Anchor" href="#efficientnet"></a> EfficientNet</h1>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209173848541.png" alt="image-20250209173848541" style="zoom: 80%;"><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174104028.png" alt="image-20250209174104028" style="zoom: 67%;"></p>
<h2 id="原理"><a class="markdownIt-Anchor" href="#原理"></a> 原理</h2>
<h3 id="网络架构搜索nas"><a class="markdownIt-Anchor" href="#网络架构搜索nas"></a> <strong>网络架构搜索（NAS）</strong>：</h3>
<ul>
<li>EfficientNet 使用了 <strong>神经架构搜索</strong>（NAS）来自动化地找到最适合的卷积神经网络架构。在这个过程中，作者通过 NAS 来寻找一个 <strong>基础架构</strong>，该架构在计算效率和性能之间取得了最佳的平衡。</li>
</ul>
<h3 id="优化网络的宽度-深度和分辨率"><a class="markdownIt-Anchor" href="#优化网络的宽度-深度和分辨率"></a> <strong>优化网络的宽度、深度和分辨率</strong>：</h3>
<ul>
<li>EfficientNet 在进行网络扩展时，并不是简单地增加网络的层数或通道数，而是采用了更加 <strong>均衡的增长策略</strong>。通过在深度、宽度和输入图像分辨率上都进行扩展，模型能够获得更强的表达能力，同时保持较低的计算成本。</li>
</ul>
<h3 id="高效的卷积操作"><a class="markdownIt-Anchor" href="#高效的卷积操作"></a> <strong>高效的卷积操作</strong>：</h3>
<ul>
<li>EfficientNet 采用了高效的卷积操作，如 <strong>Depthwise Separable Convolution</strong>，以进一步减少计算量。</li>
</ul>
<p>通过结构搜索（NAS, Neural Architecture Search）和优化策略，在精度和计算效率之间找到最好的平衡。</p>
<h2 id="mbconvefficientnet块"><a class="markdownIt-Anchor" href="#mbconvefficientnet块"></a> MBConv/EfficientNet块</h2>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209180216944.png" alt="image-20250209180216944"></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174529781.png" alt="image-20250209174529781"></p>
<h3 id="倒残差结构inverted-residuals"><a class="markdownIt-Anchor" href="#倒残差结构inverted-residuals"></a> 倒残差结构（Inverted Residuals)</h3>
<p><img src="https://pic2.zhimg.com/v2-7c42cff2fa3c346d2e41be95848fc619_1440w.jpg" alt="img"></p>
<blockquote>
<p>使用逐通道卷积和逐点卷积来提高计算效率。</p>
</blockquote>
<h2 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制"></a> 注意力机制</h2>
<h3 id="se模块squeeze-and-excitation-block"><a class="markdownIt-Anchor" href="#se模块squeeze-and-excitation-block"></a> SE模块（Squeeze-and-Excitation Block）</h3>
<p>来源于人类视觉系统中的注意机制：大脑会根据不同的视觉刺激，<strong>自动聚焦于最重要的信息，并忽略不相关的部分</strong>。SE模块通过类似的机制，<strong>自动为每个通道分配不同的重要性</strong>，从而增强模型对重要特征的敏感度。</p>
<ul>
<li>
<p><strong>queeze-and-Excitation</strong>（SE）模块，提升了特征通道之间的依赖关系.仅在 <strong>通道维度</strong> 上进行加权</p>
</li>
<li>
<p>通过一个 <strong>“Squeeze”</strong> 操作来压缩空间维度信息，再通过 <strong>“Excitation”</strong> 操作生成通道权重</p>
</li>
</ul>
<p><strong>Squeeze（压缩）</strong>：</p>
<ul>
<li>输入是一个 <strong>H×W×C</strong> 的特征图，其中 H和 W 分别是空间维度的高度和宽度，C 是通道数。</li>
<li><strong>通过全局平均池化</strong>（Global Average Pooling）对每个通道进行压缩。即对每个通道的空间维度（H×W）求平均，得到一个 <strong>C</strong> 维的向量，表示每个通道的“全局特征”。</li>
</ul>
<p><strong>Excitation（激励）</strong>：</p>
<ul>
<li>对通道的全局特征向量进行<strong>两层全连接层操作</strong>，其中第二层是激活函数（通常是 <strong>Sigmoid</strong>），生成每个通道的 <strong>注意力系数</strong>。</li>
<li>第一个全连接层是 <strong>瓶颈层（bottleneck layer）</strong>，通常通过降低维度来减少计算量。然后通过第二个全连接层，将输出恢复到原始通道数，得到每个通道的权重。</li>
</ul>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209174719710.png" alt="image-20250209174719710" style="zoom:67%;">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_make_se_block</span>(<span class="params">self, channels, se_ratio</span>):</span><br><span class="line">        reduction = <span class="built_in">int</span>(channels * se_ratio)</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">            nn.AdaptiveAvgPool2d(<span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(channels, reduction, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(reduction, channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h4 id="空间注意力机制"><a class="markdownIt-Anchor" href="#空间注意力机制"></a> 空间注意力机制</h4>
<p>对特征图的<strong>每个位置</strong>分配一个权重来决定哪些空间区域应该被网络更多关注</p>
<blockquote>
<p>人类的视觉注意力更多的是<strong>空间注意力</strong>，也就是对图片上不同区域赋予不同的权重</p>
</blockquote>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209183640934.png" alt="image-20250209183640934" style="zoom:67%;">
<h4 id="cbam注意力"><a class="markdownIt-Anchor" href="#cbam注意力"></a> CBAM注意力</h4>
<p>CBAM 通过融合 <strong>通道注意力机制</strong> 和 <strong>空间注意力机制</strong></p>
<h4 id="视觉自注意力non-local"><a class="markdownIt-Anchor" href="#视觉自注意力non-local"></a> 视觉自注意力(Non Local))</h4>
<p>用来在不引入过多计算量的基础上提高CNN网络的<strong>远程依赖</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209184403579.png" alt="image-20250209184403579"></p>
<blockquote>
<p>我可能先识别到篮球，然后在其周围找到人和篮筐，并根据他们的位置我们才能判断这个图是不是表达人在灌篮这个动作。其中，篮球位置可以理解为<strong>查询点</strong>，周边（可能离得较远）的人和篮筐就是<strong>查询点对应的关联区域</strong>。</p>
</blockquote>
<p>查询点到关联区域的对应可以加深CNN网络对场景<strong>从局部到整体</strong>的理解，因此可以有效提高CNN网络在视觉任务的效率。</p>
<ul>
<li>
<p>该模块建立了图像中<strong>每个像素/区域之间的关联</strong>，有效提升了CNN网络的感受野</p>
</li>
<li>
<p>对每个空间位置生成与所有其他位置的<strong>相似度</strong>。</p>
</li>
<li>
<p>基于<strong>相似度进行加权</strong>，使得每个位置可以融合其他位置的信息。</p>
</li>
</ul>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209184638406.png" alt="image-20250209184638406"></p>
<blockquote>
<p>其大概的运算过程是：</p>
<p>（1）为了降低运算量，采用三个不同1x1卷积层进行维度减半，即图上的 x→ϕ(x),θ(x),g(x) ;</p>
<p>（2）为 ϕ(x),θ(x),g(x) 按照w,h维度进行铺平，即图上三个flatten；</p>
<p>（3）利用铺平的 ϕ(x),θ(x) 进行矩阵乘法运算，并通过softmax获得各空间位置之间的<strong>关联图</strong>（即图中的 vc ），很明显这个关联图的大小为 (w×h,w×h) ，表征着各个像素点（区域）之间的联系；</p>
<p>（4）将铺平转置的 g(x) 与vc进行矩阵乘法，获得 y ；</p>
<p>（5）对y进行展开与特征提取（Conv4），获得注意力（refined）;</p>
<p>（6）利用注意力调整原始输入的分布，Over!!!</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/350760243">https://zhuanlan.zhihu.com/p/350760243</a></p>
</blockquote>
<h4 id="non-local改进版-gcnet"><a class="markdownIt-Anchor" href="#non-local改进版-gcnet"></a> Non Local改进版 — GCNet</h4>
<p>原因:<strong>不同查询点（区域）居然对应相同的attention map</strong></p>
<img src="https://pic4.zhimg.com/v2-31d05dfac01c6ae64bd5bf4e52ffc069_1440w.jpg" alt="img" style="zoom: 33%;">
<p>与查询（点）无关的依赖（query-independent dependency）。那么这是否意味着原始Non Local中<strong>query分支可以剪去不要</strong>呢</p>
<img src="https://pic4.zhimg.com/v2-dc2339ac78de452e286317dd259070f5_1440w.jpg" alt="img" style="zoom: 50%;">
<img src="https://pic3.zhimg.com/v2-104058d724746316b12298ec27fafe26_1440w.jpg" alt="img" style="zoom:50%;">
<h1 id="efficientdet"><a class="markdownIt-Anchor" href="#efficientdet"></a> EfficientDet</h1>
<h2 id="结构概述"><a class="markdownIt-Anchor" href="#结构概述"></a> <strong>结构概述</strong></h2>
<ol>
<li><strong>Backbone（EfficientNet）</strong>
<ul>
<li>EfficientDet 的 backbone 使用了 EfficientNet 作为特征提取器。EfficientNet 是一种使用<strong>复合缩放</strong>策略的高效网络，在目标检测任务中，EfficientDet 对 EfficientNet 进行调整和优化，使得其能更好地适应目标检测的要求。</li>
</ul>
</li>
<li><strong>BiFPN（双向特征金字塔网络）</strong>
<ul>
<li>BiFPN 通过对低层和高层特征的加权融合，使得低层和高层的特征能够互相补充，提升了多尺度特征的利用率。</li>
</ul>
</li>
<li><strong>Head</strong>
<ul>
<li><strong>分类头</strong>：用于对目标进行分类，预测每个框的类别。</li>
<li><strong>回归头</strong>：用于回归目标的边界框坐标。</li>
</ul>
</li>
<li><strong>复合缩放</strong>
<ul>
<li>EfficientDet 通过复合缩放策略调整模型的深度、宽度和输入分辨率，使得模型可以在不同的硬件环境下进行灵活的调整，同时提升了精度和效率。</li>
</ul>
</li>
</ol>
<h2 id="fpn到bifpn"><a class="markdownIt-Anchor" href="#fpn到bifpn"></a> FPN.到BiFPN</h2>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224653761.png" style="zoom: 80%;">
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209190732084.png" style="zoom: 80%;">
<blockquote>
<p>a. 网络只是针对某一特点的分辨率进行训练, 如果只是在测试和推理阶段使用图像金字塔的话, 可能导致训练和测试推理过程不匹配</p>
<p>b. 利用单个高层特征图(主干网络产生)进行物体的分类和bounding box的回归</p>
<p>c. 在 <strong>多个不同尺度的特征图（如 38×38、19×19、10×10）</strong> 上直接预测目标框。</p>
<p>d 尽管在SSD中我们已经使用了特征金字塔, 但该金字塔中的所有要素都处于不同的比例, 并且由于网络中层的深度不同而存在巨大的语义鸿沟. 高分辨率地图具有低级语义特征, 而低分辨率地图具有较高的语义特征, 这会损害其对象识别的表示能力.</p>
</blockquote>
<img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209223353104.png" alt="image-20250209223353104" style="zoom:50%;">
<blockquote>
<p>先对高阶特征进行上采样, 然后使用横向连接将其与低阶特征进行组合, 该横向连接基本上是1x1卷积, 然后进行求和,</p>
</blockquote>
<h3 id="fully-connected-fpn-and-nas-fpn"><a class="markdownIt-Anchor" href="#fully-connected-fpn-and-nas-fpn"></a> Fully connected FPN and NAS-FPN</h3>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224903212.png" alt="image-20250209224903212"></p>
<blockquote>
<p>a. 传统fpn</p>
<p>b. 全连接网络</p>
<p>c. NAS</p>
</blockquote>
<h3 id="panet"><a class="markdownIt-Anchor" href="#panet"></a> PANet</h3>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209224555819.png" alt="image-20250209224555819"></p>
<blockquote>
<p>添加<strong>自下而上的路径</strong>以增强FPN中的自上而下的路径</p>
</blockquote>
<h3 id="simplified-fpn-and-bifpn"><a class="markdownIt-Anchor" href="#simplified-fpn-and-bifpn"></a> Simplified FPN and BiFPN</h3>
<p><img src="https://pic4.zhimg.com/v2-faec285a27615d8829af43172d9d1385_1440w.jpg" alt="img"></p>
<blockquote>
<p>a. 如果一个节点只有一个输入边并且没有特征融合, 那么它对特征网络的融合贡献较小, 这个节点可以删除(Simplified PANET)</p>
<p>b. 添加一条额外的连接路径,融合更多功能(BiFPN). 这点其实跟skip connection很相似</p>
<p>c. 重复叠加相同的特征网络层 复合缩放</p>
</blockquote>
<h2 id="权重计算"><a class="markdownIt-Anchor" href="#权重计算"></a> 权重计算</h2>
<p>快速归一化融合特征网络.计算路径,计算出不同特征节点的输入最合适的权值</p>
<p><img src="https://pic4.zhimg.com/v2-a0f1319eae0571829c79b1a70d4fc1b9_1440w.jpg" alt="img"></p>
<h2 id="compound-scaling"><a class="markdownIt-Anchor" href="#compound-scaling"></a> Compound Scaling</h2>
<p>复合缩放的目标是在任何给定的资源约束下最大化模型精度, 因此可以表述为优化问题.</p>
<p><strong>对网络深度、宽度和分辨率中的任何尺度进行缩放都可以提高精度, 但是当模型足够大时, 这种放大的收益会减弱。</strong></p>
<p><strong>FLOPS</strong>是floating point operations per second的缩写, 意指每秒浮点运算次数, 理解为计算速度. 是一个衡量硬件性能的指标. 我们假设我们能使用的FLOPS是2.</p>
<p><img src="https://pic2.zhimg.com/v2-032dfea7e52345c3f26a543e3dbcc6fd_1440w.jpg" alt="img"></p>
<blockquote>
<p>a. 对于网络模型depth来说, 加倍深度会使得FLOPS加倍.</p>
</blockquote>
<p><img src="https://pic1.zhimg.com/v2-4f1414b59ea6700387f0dea2dac0d878_1440w.jpg" alt="img"></p>
<blockquote>
<p>b. 对于网络模型width来说, 由于width(#channel)的增加导致卷积计算的路径平方级增加, 因此加倍宽度会使得FLOPS加4倍.</p>
</blockquote>
<p><img src="https://pica.zhimg.com/v2-646a538d15c17d28145024953ff90eda_1440w.jpg" alt="img"></p>
<blockquote>
<p>c. 对于网络模型resolution来说, 和width的情况一样, 由于resolution的增加会导致feather map呈现平方级扩张, 因此加倍图像分辨率也会使得FLOPS加4倍.</p>
</blockquote>
<p><strong>复合缩放公式:</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209230157789.png" alt="image-20250209230157789"></p>
<p><strong>网格搜索</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209230342459.png" alt></p>
<p><strong>复合缩放的总结图:</strong></p>
<p><img src="/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/image-20250209231222947.png" alt="image-20250209231222947"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/02/09/2025%E5%B9%B42%E6%9C%889%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2/" data-id="cm6yfcd2b0000mcv4hi073hzf" class="article-share-link">分享</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2025/02/05/2025%E5%B9%B42%E6%9C%885%E6%97%A5-%E8%BD%BB%E9%87%8F%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">2025年2月5日 轻量化神经网络1</div>
    </a>
  
</nav>

  
</article>



</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Weakliy_Blog</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>主页</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>归档</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>分类</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>标签</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>79</strong><br>文章</div></a>
      <a href="/categories"><div><strong>0</strong><br>分类</div></a>
      <a href="/tags"><div><strong>17</strong><br>标签</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="Github">
          Github
        </a>
      
    </div>

    <div class="friend-link">
      <h2>联系我</h2>
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2024 - 2025 Weakliy<br>
      由<a href="http://hexo.io/" target="_blank">Hexo</a>强力驱动 | 
      主题-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">首页</a>
          
            <a href="/tags" title="" class="menuItem">标签</a>
          
            <a href="/categories" title="" class="menuItem">分类</a>
          
            <a href="/archives" title="" class="menuItem">总览</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">xxx</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">xxxx</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>苟利</span></li> 
    <li><span>国家</span></li> 
    <li><span>生死以</span></li> 
    <li><span>岂能</span></li> 
    <li><span>祸福</span></li> 
    <li><span>趋避之</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>