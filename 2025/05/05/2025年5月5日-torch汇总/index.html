<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>2025å¹´5æœˆ5æ—¥ torchæ±‡æ€» | Weakliy_Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Module mymodule&#x3D; MyModule() Mymodule.bn.weight mymodule.bn.weight.data  parameters å·ç§¯æ ¸ï¼ˆnn.Conv2dï¼‰çš„æƒé‡ç»´åº¦æ˜¯ [out_channels, in_channels, kernel_height, kernel_width]  RuntimeError: Given groups&#x3D;1, weight">
<meta property="og:type" content="article">
<meta property="og:title" content="2025å¹´5æœˆ5æ—¥ torchæ±‡æ€»">
<meta property="og:url" content="https://shakewely.github.io/2025/05/05/2025%E5%B9%B45%E6%9C%885%E6%97%A5-torch%E6%B1%87%E6%80%BB/index.html">
<meta property="og:site_name" content="Weakliy_Blog">
<meta property="og:description" content="Module mymodule&#x3D; MyModule() Mymodule.bn.weight mymodule.bn.weight.data  parameters å·ç§¯æ ¸ï¼ˆnn.Conv2dï¼‰çš„æƒé‡ç»´åº¦æ˜¯ [out_channels, in_channels, kernel_height, kernel_width]  RuntimeError: Given groups&#x3D;1, weight">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-05-05T02:35:44.000Z">
<meta property="article:modified_time" content="2025-06-25T10:49:52.249Z">
<meta property="article:author" content="Weakliy">
<meta property="article:tag" content="dl">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Weakliy_Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/plugin/bganimation/bg.css">

  

  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <div class="widget-wrap mobile-header">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>102</strong><br>æ–‡ç« </div></a>
      <a href="/categories"><div><strong>0</strong><br>åˆ†ç±»</div></a>
      <a href="/tags"><div><strong>30</strong><br>æ ‡ç­¾</div></a>
    </div>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>ä¸»é¡µ</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>å½’æ¡£</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>åˆ†ç±»</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>æ ‡ç­¾</li>
          </a>
        
    </ul>
  </div>
</div>

        <section id="main"><article id="post-2025å¹´5æœˆ5æ—¥-torchæ±‡æ€»" class="wow slideInRight article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2025/05/05/2025%E5%B9%B45%E6%9C%885%E6%97%A5-torch%E6%B1%87%E6%80%BB/" class="article-date">
  <time class="post-time" datetime="2025-05-05T02:35:44.000Z" itemprop="datePublished">
    <span class="post-month">5æœˆ</span><br/>
    <span class="post-day">05</span>
  </time>
</a>
   
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      2025å¹´5æœˆ5æ—¥ torchæ±‡æ€»
    </h1>
  

        <div>
          
          
              

          
        </div>
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="module"><a class="markdownIt-Anchor" href="#module"></a> Module</h1>
<p>mymodule= MyModule()</p>
<p><code>Mymodule.bn.weight</code></p>
<p>mymodule.bn.weight.data</p>
<h1 id="parameters"><a class="markdownIt-Anchor" href="#parameters"></a> parameters</h1>
<p>å·ç§¯æ ¸ï¼ˆ<code>nn.Conv2d</code>ï¼‰çš„æƒé‡ç»´åº¦æ˜¯ <strong>[out_channels, in_channels, kernel_height, kernel_width]</strong></p>
<blockquote>
<p>RuntimeError: Given groups=1, weight of size [6, 3, 3, 3], expected input[1, 640, 640, 3] to have 3 channels, but got 640 channels instead</p>
</blockquote>
<p><strong>model.parameters()</strong></p>
<h1 id="grad"><a class="markdownIt-Anchor" href="#grad"></a> Grad</h1>
<h3 id="requires_grad"><a class="markdownIt-Anchor" href="#requires_grad"></a> requires_grad</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.bn.weight.requires_grad</span><br></pre></td></tr></table></figure>
<h1 id="é’©å­å‡½æ•°"><a class="markdownIt-Anchor" href="#é’©å­å‡½æ•°"></a> é’©å­å‡½æ•°</h1>
<blockquote>
<p><strong>é’©å­å‡½æ•°ï¼ˆHook Functionï¼‰*<em>æ˜¯å¯ä»¥ç»‘å®šåˆ° <code>nn.Module</code> çš„æŸä¸€å±‚ï¼ˆLayerï¼‰ä¸Šçš„å‡½æ•°ï¼Œåœ¨*<em>å‰å‘ä¼ æ’­ï¼ˆforwardï¼‰æˆ–åå‘ä¼ æ’­ï¼ˆbackwardï¼‰æ—¶è‡ªåŠ¨æ‰§è¡Œ</em></em>ï¼Œç”¨æ¥</strong>æå–ä¸­é—´ç‰¹å¾ã€ä¿®æ”¹æ¢¯åº¦æˆ–ä¸­é—´è¾“å‡ºã€è°ƒè¯•æ¨¡å‹ç­‰**ã€‚</p>
<h3 id="ä»€ä¹ˆæ˜¯é’©å­å‡½æ•°hook-function"><a class="markdownIt-Anchor" href="#ä»€ä¹ˆæ˜¯é’©å­å‡½æ•°hook-function"></a> âœ… ä»€ä¹ˆæ˜¯é’©å­å‡½æ•°ï¼ˆHook Functionï¼‰ï¼Ÿ</h3>
<p>åœ¨ PyTorch ä¸­ï¼Œ<strong>é’©å­å‡½æ•°ï¼ˆHook Functionï¼‰*<em>æ˜¯å¯ä»¥ç»‘å®šåˆ° <code>nn.Module</code> çš„æŸä¸€å±‚ï¼ˆLayerï¼‰ä¸Šçš„å‡½æ•°ï¼Œåœ¨*<em>å‰å‘ä¼ æ’­ï¼ˆforwardï¼‰æˆ–åå‘ä¼ æ’­ï¼ˆbackwardï¼‰æ—¶è‡ªåŠ¨æ‰§è¡Œ</em></em>ï¼Œç”¨æ¥</strong>æå–ä¸­é—´ç‰¹å¾ã€ä¿®æ”¹æ¢¯åº¦æˆ–ä¸­é—´è¾“å‡ºã€è°ƒè¯•æ¨¡å‹ç­‰**ã€‚</p>
<hr>
<h3 id="pytorch-ä¸­çš„é’©å­ç§ç±»"><a class="markdownIt-Anchor" href="#pytorch-ä¸­çš„é’©å­ç§ç±»"></a> ğŸ“Œ PyTorch ä¸­çš„é’©å­ç§ç±»ï¼š</h3>
<table>
<thead>
<tr>
<th>ç±»å‹</th>
<th>æ–¹æ³•</th>
<th>ä½œç”¨</th>
</tr>
</thead>
<tbody>
<tr>
<td>å‰å‘é’©å­</td>
<td><code>register_forward_hook()</code></td>
<td>åœ¨è¯¥å±‚ <strong>forwardè¾“å‡ºå</strong> è‡ªåŠ¨è°ƒç”¨</td>
</tr>
<tr>
<td>å‰å‘å‰é’©å­</td>
<td><code>register_forward_pre_hook()</code></td>
<td>åœ¨è¯¥å±‚ <strong>forwardè¾“å…¥å‰</strong> è°ƒç”¨</td>
</tr>
<tr>
<td>åå‘é’©å­</td>
<td><code>register_backward_hook()</code>ï¼ˆä¸æ¨èï¼‰æˆ– <code>register_full_backward_hook()</code></td>
<td>åœ¨è¯¥å±‚ <strong>backwardæ‰§è¡Œæ—¶</strong> è°ƒç”¨</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="ä¸ºä»€ä¹ˆè¦æ³¨å†Œé’©å­å‡½æ•°"><a class="markdownIt-Anchor" href="#ä¸ºä»€ä¹ˆè¦æ³¨å†Œé’©å­å‡½æ•°"></a> ğŸ§  ä¸ºä»€ä¹ˆè¦æ³¨å†Œé’©å­å‡½æ•°ï¼Ÿ</h3>
<p>ä½ è¿™æ®µä»£ç ä¸­ä½¿ç”¨ <code>register_forward_hook()</code>ï¼Œæ˜¯ä¸ºäº†åœ¨<strong>è’¸é¦è¿‡ç¨‹ä¸­æå–æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹æŸäº›å±‚çš„è¾“å‡ºç‰¹å¾</strong>ï¼Œè®¡ç®—ç‰¹å¾ä¹‹é—´çš„å·®å¼‚ä½œä¸ºè’¸é¦æŸå¤±ã€‚</p>
</blockquote>
<p><code>.data</code></p>
<h1 id="tensor"><a class="markdownIt-Anchor" href="#tensor"></a> tensor</h1>
<p>1ï¸âƒ£ view(shape)âœ…<br>
æ”¹å˜å¼ é‡å½¢çŠ¶ï¼ˆreshapeï¼‰ï¼Œä½†ä¸æ”¹å˜å†…å­˜å¸ƒå±€ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(2,3,4)</span><br><span class="line">y = x.view(6,4)</span><br><span class="line">print(y.shape)  # torch.Size([6, 4])</span><br></pre></td></tr></table></figure>
<hr>
<p>2ï¸âƒ£ <strong>reshape(shape)</strong><br>
ç±»ä¼¼ <code>view</code>ï¼Œä½†æ›´çµæ´»ï¼Œæ”¯æŒéè¿ç»­å†…å­˜ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3,4)</span><br><span class="line">y = x.reshape(6,4)</span><br><span class="line">print(y.shape)  # torch.Size([6, 4])</span><br></pre></td></tr></table></figure>
<hr>
<p>3ï¸âƒ£ <strong>squeeze(dim=None)</strong><br>
å»æ‰æ‰€æœ‰ä¸º1çš„ç»´åº¦ï¼Œæˆ–è€…æŒ‡å®šç»´åº¦çš„1ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,1,3)</span><br><span class="line">y = x.squeeze()</span><br><span class="line">print(y.shape)  # torch.Size([2,3])</span><br><span class="line">y2 = x.squeeze(1)</span><br><span class="line">print(y2.shape)  # torch.Size([2,3])</span><br></pre></td></tr></table></figure>
<hr>
<p>4ï¸âƒ£ <strong>unsqueeze(dim)</strong><br>
åœ¨æŒ‡å®šä½ç½®æ’å…¥ç»´åº¦1ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3)</span><br><span class="line">y = x.unsqueeze(1)</span><br><span class="line">print(y.shape)  # torch.Size([2,1,3])</span><br></pre></td></tr></table></figure>
<hr>
<p>5ï¸âƒ£ **transpose(dim0, dim1)**âœ…<br>
åªäº¤æ¢ä¸¤ä¸ªç»´åº¦ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(2,3,4)</span><br><span class="line">y = x.transpose(1,2)</span><br><span class="line">print(y.shape)  # torch.Size([2,4,3])</span><br></pre></td></tr></table></figure>
<hr>
<p>6ï¸âƒ£ **permute(dims)**âœ…<br>
ä»»æ„ç»´åº¦æ¢åºã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(2,3,4)</span><br><span class="line">y = x.permute(0,2,1)</span><br><span class="line">print(y.shape)  # torch.Size([2,4,3])</span><br></pre></td></tr></table></figure>
<hr>
<p>7ï¸âƒ£ <strong>contiguous()</strong><br>
è¿”å›å†…å­˜è¿ç»­çš„ tensorï¼ˆä¸€èˆ¬ <code>view</code> å‰ç”¨ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3,4).transpose(1,2)</span><br><span class="line">y = x.contiguous().view(2,12)</span><br><span class="line">print(y.shape)  # torch.Size([2,12])</span><br></pre></td></tr></table></figure>
<hr>
<p>8ï¸âƒ£ <strong>to(device)</strong><br>
è½¬ç§»åˆ°æŒ‡å®šè®¾å¤‡ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3)</span><br><span class="line">y = x.to(&#x27;cuda&#x27;)</span><br></pre></td></tr></table></figure>
<hr>
<p>9ï¸âƒ£ <strong>cpu() / cuda()</strong><br>
ç®€å†™ç‰ˆçš„ to(â€˜cpuâ€™) æˆ– to(â€˜cudaâ€™)</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3).cuda()</span><br><span class="line">y = x.cpu()</span><br></pre></td></tr></table></figure>
<hr>
<p>ğŸ”Ÿ <strong>clone()</strong><br>
å¤åˆ¶ tensorï¼ˆæ–°å¼€å†…å­˜ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3)</span><br><span class="line">y = x.clone()</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£1ï¸âƒ£ <strong>detach()</strong><br>
è¿”å›ä¸€ä¸ªä¸å‚ä¸è®¡ç®—å›¾çš„æ–° tensorã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3, requires_grad=True)</span><br><span class="line">y = x.detach()</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£2ï¸âƒ£ <strong>item()</strong><br>
è¿”å›å•å…ƒç´  tensor çš„ python æ•°å€¼ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.tensor([3.14])</span><br><span class="line">v = x.item()  # 3.14 (float)</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£3ï¸âƒ£ <strong>numpy()</strong><br>
è½¬ä¸º numpy æ•°ç»„ï¼ˆå…±äº«å†…å­˜ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3)</span><br><span class="line">arr = x.numpy()</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£4ï¸âƒ£ <strong>size(dim=None)</strong><br>
è¿”å›ç»´åº¦å¤§å°ï¼Œdim=None è¿”å›å…¨éƒ¨ shapeã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3,4)</span><br><span class="line">print(x.size())     # torch.Size([2,3,4])</span><br><span class="line">print(x.size(1))    # 3</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£5ï¸âƒ£ <strong>shape</strong><br>
å±æ€§ï¼Œç­‰ä»·äº <code>size()</code>ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3,4)</span><br><span class="line">print(x.shape)  # torch.Size([2,3,4])</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£6ï¸âƒ£ <strong>numel()</strong><br>
å¼ é‡å…ƒç´ æ€»æ•°ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.randn(2,3,4)</span><br><span class="line">print(x.numel())  # 24</span><br></pre></td></tr></table></figure>
<h1 id="torchcuda"><a class="markdownIt-Anchor" href="#torchcuda"></a> torch.cuda</h1>
<p>1ï¸âƒ£ <strong>torch.cuda.is_available()</strong><br>
æ£€æŸ¥å½“å‰ PyTorch æ˜¯å¦å¯ä»¥ä½¿ç”¨ GPUã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.cuda.is_available()  # True / False</span><br></pre></td></tr></table></figure>
<hr>
<p>2ï¸âƒ£ <strong>torch.cuda.device_count()</strong><br>
è¿”å›å¯ç”¨çš„ GPU æ•°é‡ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.cuda.device_count()  # å¦‚ 2</span><br></pre></td></tr></table></figure>
<hr>
<p>3ï¸âƒ£ <strong>torch.cuda.get_device_name(device=0)</strong><br>
è·å–æŒ‡å®š GPU çš„åç§°ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.cuda.get_device_name(0)  # &#x27;NVIDIA GeForce RTX 4090&#x27;</span><br></pre></td></tr></table></figure>
<hr>
<p>4ï¸âƒ£ <strong>torch.cuda.current_device()</strong><br>
è¿”å›å½“å‰é»˜è®¤è®¾å¤‡çš„ç´¢å¼•ï¼ˆintï¼‰ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.cuda.current_device()  # å¦‚ 0</span><br></pre></td></tr></table></figure>
<hr>
<p>5ï¸âƒ£ <strong>torch.cuda.set_device(device)</strong><br>
è®¾ç½®å½“å‰é»˜è®¤ä½¿ç”¨çš„ GPUã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.cuda.set_device(1)</span><br></pre></td></tr></table></figure>
<hr>
<p>6ï¸âƒ£ <strong>torch.cuda.memory_allocated(device=0)</strong><br>
è¿”å›å½“å‰åˆ†é…ç»™å¼ é‡çš„æ˜¾å­˜å¤§å°ï¼ˆå•ä½ï¼šå­—èŠ‚ï¼‰ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.cuda.memory_allocated(0) / 1024**2  # å•ä½ï¼šMB</span><br></pre></td></tr></table></figure>
<hr>
<p>7ï¸âƒ£ <strong>torch.cuda.memory_reserved(device=0)</strong><br>
è¿”å›ä¸ºåˆ†é…é¢„ç•™çš„æ˜¾å­˜ï¼ˆç”¨äºç¼“å­˜æœºåˆ¶ï¼‰ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.cuda.memory_reserved(0) / 1024**2  # å•ä½ï¼šMB</span><br></pre></td></tr></table></figure>
<hr>
<p>8ï¸âƒ£ <strong>torch.cuda.empty_cache()</strong><br>
é‡Šæ”¾æœªä½¿ç”¨çš„æ˜¾å­˜ç¼“å­˜ï¼ˆä¸ä¼šé‡Šæ”¾å·²ä½¿ç”¨çš„æ˜¾å­˜ï¼‰ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure>
<hr>
<p>9ï¸âƒ£ <strong>torch.cuda.synchronize(device=None)</strong><br>
ç­‰å¾…æ‰€æœ‰ GPU æ“ä½œå®Œæˆï¼ˆç”¨äºè®¡æ—¶æ—¶ç²¾å‡†ï¼‰ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.cuda.synchronize()</span><br></pre></td></tr></table></figure>
<hr>
<p>ğŸ”Ÿ <strong>torch.cuda.Stream / torch.cuda.Event</strong><br>
ç”¨äºæ‰‹åŠ¨æ§åˆ¶ CUDA æ“ä½œé¡ºåºï¼ˆé«˜çº§ç”¨æ³•ï¼‰ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘stream = torch.cuda.Stream()</span><br><span class="line">event = torch.cuda.Event()</span><br></pre></td></tr></table></figure>
<h1 id="model"><a class="markdownIt-Anchor" href="#model"></a> model</h1>
<p><strong><code>m.weight</code></strong>ï¼šè·å–<code>BatchNorm2d</code>å±‚çš„æƒé‡å‚æ•°ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w = m.weight.abs().detach()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b = m.bias.abs().detach()</span><br></pre></td></tr></table></figure>
<p>1ï¸âƒ£ **<code>model.parameters()</code>**âœ…<br>
è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼ŒåªåŒ…å«æ¨¡å‹ä¸­æ‰€æœ‰å‚æ•°ï¼ˆ<code>nn.Parameter</code> ç±»å‹ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for param in model.parameters():</span><br><span class="line">    print(param.shape)</span><br><span class="line">    param.nelement() * param.element_size()</span><br></pre></td></tr></table></figure>
<hr>
<p>2ï¸âƒ£ <strong><code>model.named_parameters()</code></strong> âœ…<br>
è¿”å› <code>(name, param)</code> å…ƒç»„çš„ç”Ÿæˆå™¨ï¼Œå¸¦æœ‰åå­—ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">]for name, param in model.named_parameters():</span><br><span class="line">    print(name, param.shape)</span><br></pre></td></tr></table></figure>
<hr>
<p>3ï¸âƒ£ <strong><code>model.children()</code></strong><br>
è¿”å›æ¨¡å‹çš„<strong>ç¬¬ä¸€å±‚å­æ¨¡å—</strong>ï¼Œä¸é€’å½’ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘for child in model.children():</span><br><span class="line">    print(child)  # åªæ˜¯ä¸€å±‚ï¼Œä¾‹å¦‚ Conv, ReLU, Linear</span><br></pre></td></tr></table></figure>
<hr>
<p>4ï¸âƒ£ <strong><code>model.named_children()</code></strong><br>
è¿”å› <code>(name, module)</code> çš„ç”Ÿæˆå™¨ï¼Œç¬¬ä¸€å±‚å­æ¨¡å—å¸¦åå­—ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘for name, module in model.named_children():</span><br><span class="line">    print(name, module)</span><br></pre></td></tr></table></figure>
<hr>
<p>5ï¸âƒ£ <strong><code>model.modules()</code></strong><br>
è¿”å›æ¨¡å‹ä¸­æ‰€æœ‰æ¨¡å—ï¼ˆåŒ…æ‹¬è‡ªèº«å’Œé€’å½’å­æ¨¡å—ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘for module in model.modules():</span><br><span class="line">    print(type(module))</span><br></pre></td></tr></table></figure>
<hr>
<p>6ï¸âƒ£ <strong><code>model.named_modules()</code></strong><br>
è¿”å› <code>(name, module)</code> å½¢å¼çš„æ‰€æœ‰æ¨¡å—ï¼ˆé€’å½’ + åŒ…æ‹¬è‡ªèº«ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘for name, module in model.named_modules():</span><br><span class="line">    print(name, module)</span><br></pre></td></tr></table></figure>
<hr>
<p>7ï¸âƒ£ <strong><code>model.state_dict()</code></strong><br>
è¿”å›åŒ…å«æ‰€æœ‰å‚æ•°å’Œç¼“å†²åŒºï¼ˆå¦‚ <code>running_mean</code>ï¼‰çš„å­—å…¸ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘for name, tensor in model.state_dict().items():</span><br><span class="line">    print(name, tensor.shape)</span><br></pre></td></tr></table></figure>
<hr>
<p>8ï¸âƒ£ <strong><code>model.load_state_dict(state_dict)</code></strong><br>
åŠ è½½ <code>.pth</code> æ–‡ä»¶ä¿å­˜çš„æƒé‡ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">model.load_state_dict(torch.load(&#x27;xxx.pth&#x27;))</span><br></pre></td></tr></table></figure>
<hr>
<p>9ï¸âƒ£ <strong><code>model.eval()</code> / <code>model.train()</code></strong><br>
åˆ‡æ¢æ¨¡å‹æ¨¡å¼ï¼ˆå½±å“ Dropout / BatchNorm ç­‰ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘model.eval()   # æ¨ç†æ¨¡å¼</span><br><span class="line">model.train()  # è®­ç»ƒæ¨¡å¼</span><br></pre></td></tr></table></figure>
<hr>
<p>ğŸ”Ÿ <strong><code>model.zero_grad()</code></strong><br>
æ¸…ç©ºæ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ï¼ˆç­‰æ•ˆäº <code>optimizer.zero_grad()</code>ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">model.zero_grad()</span><br></pre></td></tr></table></figure>
<h1 id="torch"><a class="markdownIt-Anchor" href="#torch"></a> torch</h1>
<p><code>torch.sort</code> æ˜¯ PyTorch ä¸­ç”¨äºå¯¹å¼ é‡è¿›è¡Œæ’åºçš„å‡½æ•°ã€‚</p>
<ul>
<li><code>descending=True</code> è¡¨ç¤ºæŒ‰é™åºæ’åºã€‚</li>
<li>è¿™ä¸ªå‡½æ•°è¿”å›ä¸€ä¸ªå…ƒç»„ <code>(sorted_tensor, indices)</code>ï¼Œå…¶ä¸­ <code>sorted_tensor</code> æ˜¯æ’åºåçš„å¼ é‡ï¼Œ<code>indices</code> æ˜¯æ’åºåçš„ç´¢å¼•ã€‚</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># åˆ›å»ºä¸€ä¸ªäºŒç»´å¼ é‡</span><br><span class="line">tensor = torch.tensor([[0.1, 0.5, 0.3], [0.9, 0.7, 0.2]])</span><br><span class="line"></span><br><span class="line"># è®¾ç½®æ¡ä»¶</span><br><span class="line">condition = tensor &gt; 0.4</span><br><span class="line"></span><br><span class="line"># ä½¿ç”¨ torch.where æ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„å…ƒç´ çš„ç´¢å¼•</span><br><span class="line">indices = torch.where(condition)</span><br><span class="line"></span><br><span class="line">print(&quot;åŸå§‹å¼ é‡:&quot;, tensor)</span><br><span class="line">print(&quot;æ¡ä»¶:&quot;, condition)</span><br><span class="line">print(&quot;è¿”å›çš„ç´¢å¼•:&quot;, indices)</span><br></pre></td></tr></table></figure>
<p>1ï¸âƒ£ <strong>torch.stack(preds_cls)</strong><br>
æŠŠ <code>preds_cls</code> åˆ—è¡¨æ‹¼èµ·æ¥ï¼Œå¢åŠ ä¸€ä¸ªæ–°ç»´åº¦ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘preds_cls = [cls1, cls2, cls3]  # æ¯ä¸ª cls shape (B, C, H, W)</span><br><span class="line">torch.stack(preds_cls) â†’ (3, B, C, H, W)</span><br></pre></td></tr></table></figure>
<p>ç­‰ä»·äº <code>torch.stack(preds_cls, dim=0)</code></p>
<hr>
<p>2ï¸âƒ£ <strong>weights_cls.view(-1,1,1,1,1)</strong><br>
æŠŠ <code>(N,)</code> çš„æƒé‡ reshape æˆ <code>(N,1,1,1,1)</code>ï¼Œä¸ºäº†å’Œ <code>(N, B, C, H, W)</code> å¹¿æ’­ç›¸ä¹˜ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘weights_cls = torch.tensor([0.2, 0.3, 0.5])  # (3,)</span><br><span class="line">weights_cls.view(-1,1,1,1,1) â†’ (3,1,1,1,1)</span><br></pre></td></tr></table></figure>
<hr>
<p>3ï¸âƒ£ <strong>torch.sum(â€¦, dim=0)</strong><br>
æ²¿ç¬¬0ç»´ï¼ˆåˆ†æ”¯ç»´åº¦ï¼‰æ±‚å’Œï¼Œå¾—åˆ°èåˆåçš„æœ€ç»ˆé¢„æµ‹ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">final_out = torch.sum(preds_cls * weights_cls, dim=0)  # (B, C, H, W)</span><br></pre></td></tr></table></figure>
<hr>
<p>4ï¸âƒ£ <strong>einsum è®¡ç®—</strong><br>
ç”¨ <code>torch.einsum</code> è¡¨è¾¾æ›´ç´§å‡‘çš„è®¡ç®—ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.einsum(&#x27;n,nbchw-&gt;bchw&#x27;, weights_cls, preds_cls)</span><br></pre></td></tr></table></figure>
<p>ç­‰ä»·äºï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.sum(weights_cls.view(-1,1,1,1,1) * preds_cls, dim=0)</span><br></pre></td></tr></table></figure>
<hr>
<p>5ï¸âƒ£ <strong><em>*init*</em>(512) â†’ forward(z, x)</strong><br>
åˆå§‹åŒ– <code>SiameseRPN</code>ï¼Œ512 æ˜¯ Conv3 çš„é€šé“æ•°ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘self.rpn3 = SiameseRPN(512)</span><br><span class="line">cls_out, reg_out = self.rpn3(z, x)  # z, x æ˜¯ Conv3 ç‰¹å¾</span><br></pre></td></tr></table></figure>
<hr>
<p>6ï¸âƒ£ <strong>torch.chunk(x, 2, dim=1)</strong><br>
æŠŠ <code>x</code> åœ¨é€šé“ç»´ï¼ˆdim=1ï¼‰ä¸€åˆ†ä¸ºäºŒã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x1, x2 = torch.chunk(x, 2, dim=1)</span><br><span class="line"># x1, x2 â†’ (B, C//2, H, W)</span><br></pre></td></tr></table></figure>
<hr>
<p>7ï¸âƒ£ <strong>torch.eye(H, device=x.device, dtype=x.dtype)</strong><br>
ç”Ÿæˆä¸€ä¸ª H Ã— H çš„å•ä½çŸ©é˜µã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I = torch.eye(H, device=x.device, dtype=x.dtype)  # (H, H)</span><br></pre></td></tr></table></figure>
<p>8ï¸âƒ£ <strong>torch.cat(tensors, dim)</strong><br>
æŠŠ tensor åˆ—è¡¨æŒ‰æŒ‡å®šç»´æ‹¼æ¥èµ·æ¥ï¼ˆä¸å¢åŠ æ–°ç»´åº¦ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘tensors = [t1, t2, t3]  # æ¯ä¸ª t shape (B, C, H, W)</span><br><span class="line">torch.cat(tensors, dim=1) â†’ (B, C*3, H, W)</span><br></pre></td></tr></table></figure>
<hr>
<p>9ï¸âƒ£ <strong>torch.unsqueeze(x, dim)</strong><br>
åœ¨ dim ä½ç½®å¢åŠ ä¸€ä¸ªæ–°ç»´åº¦ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x.shape â†’ (B, C, H, W)</span><br><span class="line">torch.unsqueeze(x, dim=1) â†’ (B, 1, C, H, W)</span><br></pre></td></tr></table></figure>
<hr>
<p>ğŸ”Ÿ <strong>torch.squeeze(x, dim)</strong><br>
å»æ‰ dim ç»´åº¦ä¸Šçš„1ç»´ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x.shape â†’ (B, 1, C, H, W)</span><br><span class="line">torch.squeeze(x, dim=1) â†’ (B, C, H, W)</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£1ï¸âƒ£ <strong>torch.permute(x, dims)</strong><br>
äº¤æ¢ç»´åº¦é¡ºåºã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x.shape â†’ (B, C, H, W)</span><br><span class="line">torch.permute(x, (0,2,3,1)) â†’ (B, H, W, C)</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£2ï¸âƒ£ <strong>torch.transpose(x, dim0, dim1)</strong><br>
äº¤æ¢ä¸¤ä¸ªç»´åº¦ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x.shape â†’ (B, C, H, W)</span><br><span class="line">torch.transpose(x, 1, 2) â†’ (B, H, C, W)</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£3ï¸âƒ£ <strong>torch.mean(x, dim, keepdim=False)</strong><br>
åœ¨æŒ‡å®šç»´æ±‚å¹³å‡ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x.shape â†’ (B, C, H, W)</span><br><span class="line">torch.mean(x, dim=2) â†’ (B, C, W)</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£4ï¸âƒ£ <strong>torch.max(x, dim, keepdim=False)</strong><br>
åœ¨æŒ‡å®šç»´å–æœ€å¤§å€¼ï¼ˆè¿”å›å€¼å’Œç´¢å¼•ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘vals, idxs = torch.max(x, dim=2)</span><br><span class="line">vals.shape â†’ (B, C, W)</span><br><span class="line">idxs.shape â†’ (B, C, W)</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£5ï¸âƒ£ <strong>torch.clamp(x, min, max)</strong><br>
æŠŠå€¼è£å‰ªåˆ° [min, max] åŒºé—´ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.tensor([-1, 0.5, 2])</span><br><span class="line">torch.clamp(x, 0, 1) â†’ tensor([0., 0.5, 1.])</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£6ï¸âƒ£ <strong>torch.where(condition, x, y)</strong><br>
æŒ‰æ¡ä»¶é€‰æ‹©ï¼Œcondition=True å– xï¼Œå¦åˆ™å– yã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘a = torch.tensor([1, 2, 3])</span><br><span class="line">b = torch.tensor([10, 20, 30])</span><br><span class="line">cond = a &gt; 1</span><br><span class="line">torch.where(cond, a, b) â†’ tensor([10, 2, 3])</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£7ï¸âƒ£ <strong>torch.linspace(start, end, steps)</strong><br>
ç”Ÿæˆç­‰é—´éš”åºåˆ—ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.linspace(0,1,5) â†’ tensor([0., 0.25, 0.5, 0.75, 1.])</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£8ï¸âƒ£ <strong>torch.arange(start, end, step)</strong><br>
ç”Ÿæˆç­‰æ­¥é•¿åºåˆ—ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.arange(0,5,1) â†’ tensor([0,1,2,3,4])</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£9ï¸âƒ£ <strong>torch.nn.functional.one_hot(indices, num_classes)</strong><br>
æŠŠç´¢å¼•è½¬ä¸º one-hot ç¼–ç ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘idx = torch.tensor([0,2,1])</span><br><span class="line">torch.nn.functional.one_hot(idx, num_classes=3) â†’ </span><br><span class="line">tensor([[1,0,0],</span><br><span class="line">        [0,0,1],</span><br><span class="line">        [0,1,0]])</span><br></pre></td></tr></table></figure>
<hr>
<p>2ï¸âƒ£0ï¸âƒ£ <strong>x.view_as(y)</strong><br>
æŠŠ x reshape æˆå’Œ y ç›¸åŒçš„å½¢çŠ¶ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘x = torch.arange(6)</span><br><span class="line">y = torch.zeros(2,3)</span><br><span class="line">x.view_as(y) â†’ shape (2,3)</span><br></pre></td></tr></table></figure>
<p>1ï¸âƒ£5ï¸âƒ£ <strong>torch.cuda.amp.autocast</strong><br>
æ··åˆç²¾åº¦æ¨ç† / è®­ç»ƒã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonå¤åˆ¶ç¼–è¾‘with torch.cuda.amp.autocast():</span><br><span class="line">    output = model(input)</span><br></pre></td></tr></table></figure>
<hr>
<p>1ï¸âƒ£6ï¸âƒ£ <strong>torch.nn.utils.clip_grad_norm_</strong><br>
æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰ã€‚</p>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¤åˆ¶ç¼–è¾‘</span><br><span class="line">torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)</span><br></pre></td></tr></table></figure>
<p>inplace=False</p>
<p>RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [32, 2048, 32, 32]], which is output 0 of ReluBackward0, is at version 3; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).</p>
<p>RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR</p>
<p>GPU å†…å­˜ä¸è¶³æˆ– CUDA æ“ä½œä¸å½“å¯¼è‡´çš„ã€‚è®©æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ–¹å¼è§£å†³è¿™ä¸ªé—®é¢˜</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    if is_pretrain:</span><br><span class="line"></span><br><span class="line">â€‹      \# é¢„è®­ç»ƒæ—¶ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡</span><br><span class="line"></span><br><span class="line">â€‹      self.optimizer = optim.Adam(model.parameters(), lr=1e-5)</span><br><span class="line"></span><br><span class="line">â€‹    else:</span><br><span class="line"></span><br><span class="line">â€‹      \# å¾®è°ƒæ—¶ä½¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡</span><br><span class="line"></span><br><span class="line">â€‹      self.optimizer = optim.Adam(model.parameters(), lr=1e-4)</span><br></pre></td></tr></table></figure>
<h3 id="å°ç»“"><a class="markdownIt-Anchor" href="#å°ç»“"></a> ğŸ“ å°ç»“</h3>
<table>
<thead>
<tr>
<th>å ç”¨éƒ¨åˆ†</th>
<th>æ¨ç†å æ¯”</th>
<th>è®­ç»ƒå æ¯”</th>
</tr>
</thead>
<tbody>
<tr>
<td>å‚æ•°</td>
<td>âœ…</td>
<td>âœ…</td>
</tr>
<tr>
<td>ç‰¹å¾å›¾</td>
<td>âœ…</td>
<td>âœ…âœ…âœ…</td>
</tr>
<tr>
<td>æ¢¯åº¦</td>
<td>âŒ</td>
<td>âœ…</td>
</tr>
<tr>
<td>ä¼˜åŒ–å™¨çŠ¶æ€</td>
<td>âŒ</td>
<td>âœ…</td>
</tr>
<tr>
<td>æ•°æ®ç¼“å­˜</td>
<td>âœ…ï¼ˆCPUï¼‰</td>
<td>âœ…ï¼ˆCPUï¼‰</td>
</tr>
</tbody>
</table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">ğŸŒŸ æ·±åº¦å­¦ä¹ ä¸­ï¼Œå“ªäº›å› ç´ å’Œå†…å­˜ï¼ˆmemoryï¼Œå æ¯”ï¼‰æœ‰å…³ï¼Ÿ</span><br><span class="line">è¿™é‡Œè¯´çš„å†…å­˜ä¸»è¦æŒ‡ æ˜¾å­˜ï¼ˆGPU memoryï¼‰ï¼Œä½†æœ‰äº›åŸåˆ™ä¹Ÿé€‚ç”¨äº CPU å†…å­˜ã€‚</span><br><span class="line"></span><br><span class="line">æˆ‘ä»¬å¯ä»¥æŠŠå®ƒæ‹†æˆå‡ éƒ¨åˆ†ï¼š</span><br><span class="line"></span><br><span class="line">âœ… 1. æ¨¡å‹å‚æ•°ï¼ˆparametersï¼‰</span><br><span class="line">åŒ…å«æƒé‡ã€åç½®ï¼ˆweights, biasesï¼‰ï¼Œæ¯ä¸ªå‚æ•°é€šå¸¸ç”¨ float32ï¼ˆ4å­—èŠ‚ï¼‰ã€float16ï¼ˆ2å­—èŠ‚ï¼‰ç­‰å­˜å‚¨ã€‚</span><br><span class="line"></span><br><span class="line">åªè¦æ¨¡å‹åŠ è½½åˆ° GPUï¼Œå°±å ç”¨å›ºå®šæ˜¾å­˜ã€‚</span><br><span class="line"></span><br><span class="line">ä¾‹å­ï¼š</span><br><span class="line"></span><br><span class="line">YOLOv8n â†’ ~3M å‚æ•°ï¼Œçº¦ 12MB (float32)</span><br><span class="line"></span><br><span class="line">YOLOv8x â†’ ~70M å‚æ•°ï¼Œçº¦ 280MB (float32)</span><br><span class="line"></span><br><span class="line">â†’ å’Œæ¨¡å‹è§„æ¨¡ç›´æ¥ç›¸å…³ï¼Œå å›ºå®šéƒ¨åˆ†æ˜¾å­˜ã€‚</span><br><span class="line"></span><br><span class="line">âœ… 2. ä¸­é—´ç‰¹å¾å›¾ï¼ˆfeature maps / activationsï¼‰</span><br><span class="line">ç½‘ç»œå‰å‘æ¨ç†ä¸­æ¯å±‚äº§ç”Ÿçš„è¾“å‡ºå¼ é‡ã€‚</span><br><span class="line"></span><br><span class="line">åœ¨è®­ç»ƒä¸­éœ€è¦ä¿å­˜è¿™äº›ç‰¹å¾å›¾æ¥åšåå‘ä¼ æ’­ï¼Œå› æ­¤è®­ç»ƒæ˜¾å­˜éœ€æ±‚å¤§çº¦æ˜¯æ¨ç†çš„ 2~3 å€ã€‚</span><br><span class="line"></span><br><span class="line">è¿™æ˜¯è®­ç»ƒä¸­ä¸»è¦åƒæ˜¾å­˜çš„éƒ¨åˆ†ã€‚</span><br><span class="line"></span><br><span class="line">å½±å“å› ç´ ï¼š</span><br><span class="line"></span><br><span class="line">è¾“å…¥å›¾åƒå¤§å°ï¼ˆH Ã— Wï¼‰</span><br><span class="line"></span><br><span class="line">batch size</span><br><span class="line"></span><br><span class="line">æ¨¡å‹çš„é€šé“æ•°ã€åˆ†è¾¨ç‡ã€å±‚æ•°</span><br><span class="line"></span><br><span class="line">ä¾‹å­ï¼š</span><br><span class="line">640Ã—640 å›¾åƒï¼Œbatch=1ï¼ŒYOLOv8n å ç”¨ â‰ˆ12GB</span><br><span class="line">640Ã—640 å›¾åƒï¼Œbatch=8ï¼ŒYOLOv8n å ç”¨ â‰ˆ810GB</span><br><span class="line"></span><br><span class="line">âœ… 3. æ¢¯åº¦ï¼ˆgradientsï¼‰</span><br><span class="line">è®­ç»ƒæ—¶éœ€è¦ä¸ºæ¯ä¸ªå‚æ•°å­˜å‚¨æ¢¯åº¦ï¼Œç”¨äºä¼˜åŒ–å™¨æ›´æ–°æƒé‡ã€‚</span><br><span class="line"></span><br><span class="line">é€šå¸¸å¤§å° â‰ˆ å‚æ•°å¤§å°ã€‚</span><br><span class="line"></span><br><span class="line">æ¨ç†æ—¶ä¸éœ€è¦ã€‚</span><br><span class="line"></span><br><span class="line">ä¾‹å­ï¼š</span><br><span class="line"></span><br><span class="line">å‚æ•° 100MB â†’ æ¢¯åº¦ä¹Ÿå¤§çº¦ 100MB</span><br><span class="line"></span><br><span class="line">âœ… 4. ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆoptimizer stateï¼‰</span><br><span class="line">åªæœ‰è®­ç»ƒæ—¶æ‰æœ‰ï¼Œä¾‹å¦‚ Adam ä¼˜åŒ–å™¨è¦å­˜åŠ¨é‡å’Œæ–¹å·®ã€‚</span><br><span class="line"></span><br><span class="line">é€šå¸¸æ˜¯å‚æ•°çš„ 2~4 å€å¤§å°ã€‚</span><br><span class="line"></span><br><span class="line">ä¾‹å­ï¼š</span><br><span class="line"></span><br><span class="line">Adam ä¼˜åŒ–å™¨ï¼Œ100MB å‚æ•° â†’ é¢å¤–çº¦ 200MB ä¼˜åŒ–å™¨çŠ¶æ€</span><br><span class="line"></span><br><span class="line">âœ… 5. è¾“å…¥æ•°æ®ç¼“å­˜ï¼ˆdata loading bufferï¼‰</span><br><span class="line">å¦‚æœç”¨ dataloader é¢„åŠ è½½æ•°æ®ï¼ˆæ¯”å¦‚ PyTorch DataLoader çš„ num_workers å¤§ã€pin_memory=Trueï¼‰ï¼Œå¯èƒ½å ç”¨æ¯”è¾ƒå¤š CPU å†…å­˜ã€‚</span><br><span class="line"></span><br><span class="line">å¯¹ GPU å†…å­˜å½±å“è¾ƒå°ï¼Œä½†éœ€è¦æ³¨æ„ã€‚</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å ç”¨æ¥æº	ä¸»è¦å’Œä»€ä¹ˆæœ‰å…³</span><br><span class="line">æ¨¡å‹æƒé‡	æ¨¡å‹è§„æ¨¡ï¼ˆnã€sã€mã€lã€xï¼‰</span><br><span class="line">è¾“å…¥æ•°æ®ç¼“å­˜	batch_size, num_workers, å›¾åƒåˆ†è¾¨ç‡</span><br><span class="line">æ•°æ®å¢å¼º	å¢å¼ºæ–¹å¼ã€å¤æ‚ç¨‹åº¦</span><br><span class="line">æ¨ç†è¾“å‡ºç¼“å­˜	æ¨ç†ä»»åŠ¡è§„æ¨¡ã€æ˜¯å¦åŠæ—¶è½ç›˜</span><br><span class="line">æ¡†æ¶å¼€é”€	æ¡†æ¶æœ¬èº«ï¼ˆPyTorch, TensorFlowï¼‰</span><br><span class="line">ç³»ç»Ÿå¤šè¿›ç¨‹/çº¿ç¨‹	ä»»åŠ¡æ•°ã€è¿›ç¨‹æ•°ã€çº¿ç¨‹æ•°</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>F.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shakewely.github.io/2025/05/05/2025%E5%B9%B45%E6%9C%885%E6%97%A5-torch%E6%B1%87%E6%80%BB/" data-id="cmanj8o28000wlcv4bsx0grzy" class="article-share-link">åˆ†äº«</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dl/" rel="tag">dl</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/05/07/2025%E5%B9%B45%E6%9C%887%E6%97%A5-ReID%E6%B1%87%E6%80%BB/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">ä¸Šä¸€ç¯‡</strong>
      <div class="article-nav-title">
        
          2025å¹´5æœˆ7æ—¥ ReIDæ±‡æ€»
        
      </div>
    </a>
  
  
    <a href="/2025/05/04/2025%E5%B9%B45%E6%9C%884%E6%97%A5-yolo%E6%B1%87%E6%80%BB/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">ä¸‹ä¸€ç¯‡</strong>
      <div class="article-nav-title">2025å¹´5æœˆ4æ—¥ yoloç»†èŠ‚è¯¦è§£</div>
    </a>
  
</nav>

  
</article>



</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <h1 class="blog-title">Weakliy_Blog</h1>
    <h2 class="blog-subtitle"></h2>
    <ul class="blog-link">
     
          <a href="/" title="Home">
            <li>ä¸»é¡µ</li>
          </a>
        
          <a href="/archives" title="Archives">
            <li>å½’æ¡£</li>
          </a>
        
          <a href="/categories" title="Categories">
            <li>åˆ†ç±»</li>
          </a>
        
          <a href="/tags" title="Tags">
            <li>æ ‡ç­¾</li>
          </a>
        
    </ul>
  </div>
</div>

  
    <div class="widget-wrap">
  <h3 class="widget-title"></h3>
  <div class="widget">
    <img class="avatar" src="https://raw.githubusercontent.com/ShakeWeLy/Weakliy.github.io/main/%E5%A4%B4%E5%83%8F/mmexport1683194148817.png">
    <h2 class="author">Weakliy</h2>
    <h3 class="description"></h3>
    <div class="count-box">
      <a href="/archives"><div><strong>102</strong><br>æ–‡ç« </div></a>
      <a href="/categories"><div><strong>0</strong><br>åˆ†ç±»</div></a>
      <a href="/tags"><div><strong>30</strong><br>æ ‡ç­¾</div></a>
    </div>



    <div class="social-link">
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="Github">
          Github
        </a>
      
    </div>

    <div class="friend-link">
      <h2>è”ç³»æˆ‘</h2>
      
        <a class="hvr-bounce-in" href="https://github.com/ShakeWeLy" target="_blank" title="ShanaMaid">
          ShanaMaid
        </a>
      
    </div>
  </div>
</div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy;2024 - 2025 Weakliy<br>
      ç”±<a href="http://hexo.io/" target="_blank">Hexo</a>å¼ºåŠ›é©±åŠ¨ | 
      ä¸»é¢˜-<a target="_blank" rel="noopener" href="https://github.com/ShanaMaid/hexo-theme-shana">Shana</a>
      
    </div>
    
  </div>
</footer>
    </div>
    

<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="//apps.bdimg.com/libs/wow/0.1.6/wow.min.js"></script>
<script>
new WOW().init();
</script>   


  
<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">

  
<script src="/plugin/fancybox/jquery.fancybox.pack.js"></script>




  
<link rel="stylesheet" href="/plugin/galmenu/GalMenu.css">

  
<script src="/plugin/galmenu/GalMenu.js"></script>

  <div class="GalMenu GalDropDown">
      <div class="circle" id="gal">
        <div class="ring">
          
            <a href="/" title="" class="menuItem">é¦–é¡µ</a>
          
            <a href="/tags" title="" class="menuItem">æ ‡ç­¾</a>
          
            <a href="/categories" title="" class="menuItem">åˆ†ç±»</a>
          
            <a href="/archives" title="" class="menuItem">æ€»è§ˆ</a>
          
            <a href="/xxxxxxxxx" title="" class="menuItem">xxx</a>
          
            <a href="/xxxxxxx" title="" class="menuItem">xxxx</a>
          
        </div>
        
          <audio id="audio" src="#"></audio>
        
      </div> 
</div>
<div id="overlay" style="opacity: 1; cursor: pointer;"></div>
  <script type="text/javascript">var items = document.querySelectorAll('.menuItem');
    for (var i = 0,
    l = items.length; i < l; i++) {
      items[i].style.left = (50 - 35 * Math.cos( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%";
      items[i].style.top = (50 + 35 * Math.sin( - 0.5 * Math.PI - 2 * (1 / l) * i * Math.PI)).toFixed(4) + "%"
    }</script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').GalMenu({
      'menu': 'GalDropDown'
    })
  });
</script>

  <section class="hidden-xs"> 
  <ul class="cb-slideshow"> 
    <li><span>è‹Ÿåˆ©</span></li> 
    <li><span>å›½å®¶</span></li> 
    <li><span>ç”Ÿæ­»ä»¥</span></li> 
    <li><span>å²‚èƒ½</span></li> 
    <li><span>ç¥¸ç¦</span></li> 
    <li><span>è¶‹é¿ä¹‹</span></li> 
  </ul>
</section>

<script src="/js/script.js"></script>




  </div>
</body>
</html>